{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5015827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:23:41.756211Z",
     "iopub.status.busy": "2025-12-12T09:23:41.755978Z",
     "iopub.status.idle": "2025-12-12T09:23:45.996946Z",
     "shell.execute_reply": "2025-12-12T09:23:45.995995Z"
    },
    "papermill": {
     "duration": 4.249188,
     "end_time": "2025-12-12T09:23:45.998413",
     "exception": false,
     "start_time": "2025-12-12T09:23:41.749225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vmdpy\r\n",
      "  Downloading vmdpy-0.2-py2.py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vmdpy) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->vmdpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->vmdpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->vmdpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->vmdpy) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->vmdpy) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->vmdpy) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vmdpy) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vmdpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->vmdpy) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->vmdpy) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->vmdpy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->vmdpy) (2024.2.0)\r\n",
      "Downloading vmdpy-0.2-py2.py3-none-any.whl (6.5 kB)\r\n",
      "Installing collected packages: vmdpy\r\n",
      "Successfully installed vmdpy-0.2\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vmdpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fcf7c",
   "metadata": {
    "papermill": {
     "duration": 0.004704,
     "end_time": "2025-12-12T09:23:46.008390",
     "exception": false,
     "start_time": "2025-12-12T09:23:46.003686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "true implement\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bee21ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:23:46.019402Z",
     "iopub.status.busy": "2025-12-12T09:23:46.019165Z",
     "iopub.status.idle": "2025-12-12T09:32:25.174634Z",
     "shell.execute_reply": "2025-12-12T09:32:25.173902Z"
    },
    "papermill": {
     "duration": 519.163026,
     "end_time": "2025-12-12T09:32:25.176055",
     "exception": false,
     "start_time": "2025-12-12T09:23:46.013029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Subject00_1.edf (rest) and Subject00_2.edf (task)...\n",
      "Loading Subject01_1.edf (rest) and Subject01_2.edf (task)...\n",
      "Loading Subject02_1.edf (rest) and Subject02_2.edf (task)...\n",
      "Loading Subject03_1.edf (rest) and Subject03_2.edf (task)...\n",
      "Loading Subject04_1.edf (rest) and Subject04_2.edf (task)...\n",
      "Loading Subject05_1.edf (rest) and Subject05_2.edf (task)...\n",
      "Loading Subject06_1.edf (rest) and Subject06_2.edf (task)...\n",
      "Loading Subject07_1.edf (rest) and Subject07_2.edf (task)...\n",
      "Loading Subject08_1.edf (rest) and Subject08_2.edf (task)...\n",
      "Loading Subject09_1.edf (rest) and Subject09_2.edf (task)...\n",
      "Loading Subject10_1.edf (rest) and Subject10_2.edf (task)...\n",
      "Loading Subject11_1.edf (rest) and Subject11_2.edf (task)...\n",
      "Loading Subject12_1.edf (rest) and Subject12_2.edf (task)...\n",
      "Loading Subject13_1.edf (rest) and Subject13_2.edf (task)...\n",
      "Loading Subject14_1.edf (rest) and Subject14_2.edf (task)...\n",
      "Loading Subject15_1.edf (rest) and Subject15_2.edf (task)...\n",
      "Loading Subject16_1.edf (rest) and Subject16_2.edf (task)...\n",
      "Loading Subject17_1.edf (rest) and Subject17_2.edf (task)...\n",
      "Loading Subject18_1.edf (rest) and Subject18_2.edf (task)...\n",
      "Loading Subject19_1.edf (rest) and Subject19_2.edf (task)...\n",
      "Loading Subject20_1.edf (rest) and Subject20_2.edf (task)...\n",
      "Loading Subject21_1.edf (rest) and Subject21_2.edf (task)...\n",
      "Loading Subject22_1.edf (rest) and Subject22_2.edf (task)...\n",
      "Loading Subject23_1.edf (rest) and Subject23_2.edf (task)...\n",
      "Loading Subject24_1.edf (rest) and Subject24_2.edf (task)...\n",
      "Loading Subject25_1.edf (rest) and Subject25_2.edf (task)...\n",
      "Loading Subject26_1.edf (rest) and Subject26_2.edf (task)...\n",
      "Loading Subject27_1.edf (rest) and Subject27_2.edf (task)...\n",
      "Loading Subject28_1.edf (rest) and Subject28_2.edf (task)...\n",
      "Loading Subject29_1.edf (rest) and Subject29_2.edf (task)...\n",
      "Loading Subject30_1.edf (rest) and Subject30_2.edf (task)...\n",
      "Loading Subject31_1.edf (rest) and Subject31_2.edf (task)...\n",
      "Loading Subject32_1.edf (rest) and Subject32_2.edf (task)...\n",
      "Loading Subject33_1.edf (rest) and Subject33_2.edf (task)...\n",
      "Loading Subject34_1.edf (rest) and Subject34_2.edf (task)...\n",
      "Loading Subject35_1.edf (rest) and Subject35_2.edf (task)...\n",
      "Final tensor X shape (N, C, T): (36, 21, 7936)\n",
      "Labels y shape: (36,)\n",
      "Segmented data shape (N_segments, C, T_seg): (4356, 21, 256)\n",
      "Feature matrix shape: (4356, 168)\n",
      "Unique subjects: ['Subject00' 'Subject01' 'Subject02' 'Subject03' 'Subject04' 'Subject05'\n",
      " 'Subject06' 'Subject07' 'Subject08' 'Subject09' 'Subject10' 'Subject11'\n",
      " 'Subject12' 'Subject13' 'Subject14' 'Subject15' 'Subject16' 'Subject17'\n",
      " 'Subject18' 'Subject19' 'Subject20' 'Subject21' 'Subject22' 'Subject23'\n",
      " 'Subject24' 'Subject25' 'Subject26' 'Subject27' 'Subject28' 'Subject29'\n",
      " 'Subject30' 'Subject31' 'Subject32' 'Subject33' 'Subject34' 'Subject35']\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject00\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.994623242647681\n",
      "Segment-level -> acc: 0.0165, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject01\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9940870328781368\n",
      "Segment-level -> acc: 0.9669, prec: 1.0000, rec: 0.9669, f1: 0.9832\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject02\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9940870328781368\n",
      "Segment-level -> acc: 0.9917, prec: 1.0000, rec: 0.9917, f1: 0.9959\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject03\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9942494879945316\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject04\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9949424218474336\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject05\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9940824467365559\n",
      "Segment-level -> acc: 0.6364, prec: 1.0000, rec: 0.6364, f1: 0.7778\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject06\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9954142471172862\n",
      "Segment-level -> acc: 0.0248, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject07\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9944122098680962\n",
      "Segment-level -> acc: 0.9008, prec: 1.0000, rec: 0.9008, f1: 0.9478\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject08\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9945776278047436\n",
      "Segment-level -> acc: 0.8843, prec: 1.0000, rec: 0.8843, f1: 0.9386\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject09\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9951045322261104\n",
      "Segment-level -> acc: 0.0661, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject10\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9958890587233771\n",
      "Segment-level -> acc: 0.1240, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject11\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9940808278645236\n",
      "Segment-level -> acc: 0.9669, prec: 1.0000, rec: 0.9669, f1: 0.9832\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject12\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9942494879945316\n",
      "Segment-level -> acc: 0.7851, prec: 1.0000, rec: 0.7851, f1: 0.8796\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject13\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939186447622582\n",
      "Segment-level -> acc: 0.9835, prec: 1.0000, rec: 0.9835, f1: 0.9917\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject14\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9946299355050258\n",
      "Segment-level -> acc: 0.1983, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject15\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939183726932834\n",
      "Segment-level -> acc: 0.5785, prec: 1.0000, rec: 0.5785, f1: 0.7330\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject16\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939156719595437\n",
      "Segment-level -> acc: 0.9917, prec: 1.0000, rec: 0.9917, f1: 0.9959\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject17\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9942467845724702\n",
      "Segment-level -> acc: 0.9917, prec: 1.0000, rec: 0.9917, f1: 0.9959\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject18\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9935872513601123\n",
      "Segment-level -> acc: 0.9421, prec: 1.0000, rec: 0.9421, f1: 0.9702\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject19\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9947858050850575\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject20\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939156632392988\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject21\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 1, 'clf__gamma': 0.01} | best f1 (cv): 0.9944710715966261\n",
      "Segment-level -> acc: 0.0744, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject22\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9954144818695776\n",
      "Segment-level -> acc: 0.6033, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject23\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939159204568002\n",
      "Segment-level -> acc: 0.8347, prec: 1.0000, rec: 0.8347, f1: 0.9099\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject24\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939148472548187\n",
      "Segment-level -> acc: 0.6364, prec: 1.0000, rec: 0.6364, f1: 0.7778\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject25\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9937494330946091\n",
      "Segment-level -> acc: 0.9504, prec: 1.0000, rec: 0.9504, f1: 0.9746\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject26\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.993915659920965\n",
      "Segment-level -> acc: 0.5620, prec: 1.0000, rec: 0.5620, f1: 0.7196\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject27\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9932577738416013\n",
      "Segment-level -> acc: 0.5124, prec: 1.0000, rec: 0.5124, f1: 0.6776\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject28\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9937524032288417\n",
      "Segment-level -> acc: 0.9917, prec: 1.0000, rec: 0.9917, f1: 0.9959\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject29\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9940816213358377\n",
      "Segment-level -> acc: 0.9587, prec: 1.0000, rec: 0.9587, f1: 0.9789\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject30\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1089 3146]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9952563848037922\n",
      "Segment-level -> acc: 0.0331, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject31\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9940805463716288\n",
      "Segment-level -> acc: 0.9008, prec: 1.0000, rec: 0.9008, f1: 0.9478\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject32\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9937532141108786\n",
      "Segment-level -> acc: 0.9008, prec: 1.0000, rec: 0.9008, f1: 0.9478\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject33\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939162033991902\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject34\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939180877034808\n",
      "Segment-level -> acc: 0.8347, prec: 1.0000, rec: 0.8347, f1: 0.9099\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject35\n",
      "Train segments: 4235  | Test segments: 121\n",
      "Train label distribution: [1210 3025]\n",
      "Best params: {'clf__C': 10, 'clf__gamma': 0.01} | best f1 (cv): 0.9939178244980642\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Average SEGMENT-level (LOSO):\n",
      "Accuracy : 0.6623\n",
      "Precision: 0.7222\n",
      "Recall   : 0.6306\n",
      "F1-score : 0.6676\n",
      "\n",
      "============================================================\n",
      "Average SUBJECT-level (LOSO, majority vote):\n",
      "Accuracy : 0.7500\n",
      "Precision: 0.7500\n",
      "Recall   : 0.7500\n",
      "F1-score : 0.7500\n",
      "\n",
      "============================================================\n",
      "10-fold CV over all segments (subject-dependent, شبیه اکثر مقاله‌ها)\n",
      "Fold 1: acc=0.9931, f1=0.9953\n",
      "Fold 2: acc=0.9977, f1=0.9984\n",
      "Fold 3: acc=0.9931, f1=0.9953\n",
      "Fold 4: acc=0.9885, f1=0.9921\n",
      "Fold 5: acc=0.9954, f1=0.9968\n",
      "Fold 6: acc=0.9977, f1=0.9984\n",
      "Fold 7: acc=0.9931, f1=0.9952\n",
      "Fold 8: acc=0.9885, f1=0.9921\n",
      "Fold 9: acc=0.9908, f1=0.9937\n",
      "Fold 10: acc=0.9908, f1=0.9937\n",
      "\n",
      "Average (10-fold CV, segment-level):\n",
      "Accuracy: 0.9929 ± 0.0032\n",
      "F1-score: 0.9951 ± 0.0022\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import psd_array_welch\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ======================\n",
    "# تنظیمات کلی\n",
    "# ======================\n",
    "DATA_FOLDER = \"/kaggle/input/ahmadi-dataset\"\n",
    "INFO_CSV = f\"{DATA_FOLDER}/subject-info.csv\"\n",
    "\n",
    "RESAMPLE_TO = 128        # می‌تونی 500 هم بذاری ولی کندتر می‌شه\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "WINDOW_SEC = 2.0         # طول سگمنت (ثانیه)\n",
    "OVERLAP_RATIO = 0.75     # ۷۵٪ overlap  → step = 0.5s\n",
    "\n",
    "USE_BASELINE = True      # از EEG استراحت برای baseline correction استفاده کن\n",
    "\n",
    "\n",
    "# ======================\n",
    "# لود داده + baseline correction (اختیاری)\n",
    "# ======================\n",
    "def load_task_edf_with_baseline(folder_path, info_csv_path, resample_to=None,\n",
    "                                use_baseline=True):\n",
    "    \"\"\"\n",
    "    برای هر سوژه:\n",
    "      - SubjectXX_1.edf (استراحت) و SubjectXX_2.edf (تسک) را می‌خوانیم\n",
    "      - اگر use_baseline=True:\n",
    "            task_data_bc = task_data - mean(rest_data, axis=time)\n",
    "      - در نهایت، داده‌ی baseline-corrected حالت تسک را برمی‌گردانیم\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    if not folder.is_dir():\n",
    "        raise NotADirectoryError(f\"{folder_path} is not a valid directory\")\n",
    "\n",
    "    info_df = pd.read_csv(info_csv_path)\n",
    "    label_map = dict(zip(info_df[\"Subject\"], info_df[\"Count quality\"]))\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    subjects = []\n",
    "    sfreq = None\n",
    "\n",
    "    for subj_row in info_df[\"Subject\"]:\n",
    "        subj_name = subj_row  # مثل Subject00, Subject01, ...\n",
    "        task_file = folder / f\"{subj_name}_2.edf\"\n",
    "        rest_file = folder / f\"{subj_name}_1.edf\"\n",
    "\n",
    "        if not task_file.is_file():\n",
    "            print(f\"Task file not found for {subj_name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if subj_name not in label_map:\n",
    "            print(f\"Warning: {subj_name} not in subject-info, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Loading {subj_name}_1.edf (rest) and {subj_name}_2.edf (task)...\")\n",
    "\n",
    "        # --- read rest and task\n",
    "        raw_task = mne.io.read_raw_edf(task_file, preload=True, verbose=False)\n",
    "\n",
    "        if use_baseline:\n",
    "            if rest_file.is_file():\n",
    "                raw_rest = mne.io.read_raw_edf(rest_file, preload=True, verbose=False)\n",
    "            else:\n",
    "                print(f\"Rest file not found for {subj_name}, baseline skipped for this subject.\")\n",
    "                raw_rest = None\n",
    "        else:\n",
    "            raw_rest = None\n",
    "\n",
    "        # --- resample\n",
    "        if resample_to is not None:\n",
    "            raw_task.resample(resample_to)\n",
    "            if raw_rest is not None:\n",
    "                raw_rest.resample(resample_to)\n",
    "\n",
    "        if sfreq is None:\n",
    "            sfreq = raw_task.info[\"sfreq\"]\n",
    "\n",
    "        task_data = raw_task.get_data()  # (C, T_task)\n",
    "\n",
    "        if use_baseline and raw_rest is not None:\n",
    "            rest_data = raw_rest.get_data()  # (C, T_rest)\n",
    "            # مطابق توضیح Oran & Yildirim: میانگین ولتاژ resting را کم می‌کنیم\n",
    "            # Baseline Correction: average voltage in rest is subtracted from task. \n",
    "            baseline = rest_data.mean(axis=1, keepdims=True)\n",
    "            task_data = task_data - baseline\n",
    "\n",
    "        X_list.append(task_data)\n",
    "        y_list.append(int(label_map[subj_name]))\n",
    "        subjects.append(subj_name)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No task files loaded. Check folder path and file naming.\")\n",
    "\n",
    "    # همه سوژه‌ها را تا کوتاه‌ترین طول برش می‌دهیم\n",
    "    lengths = [d.shape[1] for d in X_list]\n",
    "    min_len = min(lengths)\n",
    "\n",
    "    X = np.stack([d[:, :min_len] for d in X_list], axis=0)  # (N, C, T)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    subjects = np.array(subjects)\n",
    "\n",
    "    print(\"Final tensor X shape (N, C, T):\", X.shape)\n",
    "    print(\"Labels y shape:\", y.shape)\n",
    "\n",
    "    return X, y, subjects, sfreq\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Segment کردن با overlap درصدی\n",
    "# ======================\n",
    "def make_segments(X, y, subjects, sfreq, window_sec=2.0, overlap_ratio=0.75):\n",
    "    \"\"\"\n",
    "    X: (N_subjects, C, T)\n",
    "    خروجی:\n",
    "      seg_X: (N_segments, C, T_seg)\n",
    "      seg_y: (N_segments,)\n",
    "      seg_subjects: (N_segments,)\n",
    "    \"\"\"\n",
    "    N, C, T = X.shape\n",
    "    win_size = int(window_sec * sfreq)\n",
    "    step_sec = window_sec * (1.0 - overlap_ratio)\n",
    "    step = max(1, int(step_sec * sfreq))\n",
    "\n",
    "    seg_X_list = []\n",
    "    seg_y_list = []\n",
    "    seg_subj_list = []\n",
    "\n",
    "    for i in range(N):\n",
    "        data = X[i]          # (C, T)\n",
    "        subj_label = y[i]\n",
    "        subj_id = subjects[i]\n",
    "\n",
    "        start = 0\n",
    "        while start + win_size <= T:\n",
    "            seg = data[:, start:start+win_size]  # (C, win_size)\n",
    "            seg_X_list.append(seg)\n",
    "            seg_y_list.append(subj_label)\n",
    "            seg_subj_list.append(subj_id)\n",
    "            start += step\n",
    "\n",
    "    seg_X = np.stack(seg_X_list, axis=0)\n",
    "    seg_y = np.array(seg_y_list, dtype=int)\n",
    "    seg_subjects = np.array(seg_subj_list)\n",
    "\n",
    "    print(\"Segmented data shape (N_segments, C, T_seg):\", seg_X.shape)\n",
    "    return seg_X, seg_y, seg_subjects\n",
    "\n",
    "\n",
    "# ======================\n",
    "# log-bandpower (absolute + relative) مثل قبل\n",
    "# ======================\n",
    "def compute_bandpower_features(seg_X, sfreq):\n",
    "    \"\"\"\n",
    "    seg_X: (N_segments, C, T_seg)\n",
    "    خروجی:\n",
    "      feats: (N_segments, C * n_bands * 2)\n",
    "    \"\"\"\n",
    "    band_defs = {\n",
    "        \"delta\": (0.5, 4),\n",
    "        \"theta\": (4, 8),\n",
    "        \"alpha\": (8, 13),\n",
    "        \"beta\":  (13, 30),\n",
    "    }\n",
    "\n",
    "    n_segments, C, T_seg = seg_X.shape\n",
    "    feats_list = []\n",
    "\n",
    "    for i in range(n_segments):\n",
    "        data = seg_X[i]  # (C, T_seg)\n",
    "\n",
    "        psd, freqs = psd_array_welch(\n",
    "            data[np.newaxis, :, :],\n",
    "            sfreq=sfreq,\n",
    "            fmin=0.5,\n",
    "            fmax=40,\n",
    "            n_fft=T_seg,\n",
    "            verbose=False\n",
    "        )  # (1, C, n_freqs)\n",
    "\n",
    "        psd = psd[0]  # (C, n_freqs)\n",
    "        total_power = psd.sum(axis=1, keepdims=True) + 1e-12\n",
    "\n",
    "        feat_abs = []\n",
    "        feat_rel = []\n",
    "\n",
    "        for (fmin, fmax) in band_defs.values():\n",
    "            band_mask = (freqs >= fmin) & (freqs < fmax)\n",
    "            band_power = psd[:, band_mask].mean(axis=1)        # absolute\n",
    "            band_power_rel = band_power[:, None] / total_power  # relative\n",
    "\n",
    "            feat_abs.append(band_power)\n",
    "            feat_rel.append(band_power_rel[:, 0])\n",
    "\n",
    "        feat_abs = np.concatenate(feat_abs, axis=0)  # (C * n_bands,)\n",
    "        feat_rel = np.concatenate(feat_rel, axis=0)\n",
    "\n",
    "        feat_seg = np.concatenate(\n",
    "            [np.log10(feat_abs + 1e-12),\n",
    "             np.log10(feat_rel + 1e-12)],\n",
    "            axis=0\n",
    "        )\n",
    "        feats_list.append(feat_seg)\n",
    "\n",
    "    feats = np.stack(feats_list, axis=0)\n",
    "    print(\"Feature matrix shape:\", feats.shape)\n",
    "    return feats\n",
    "\n",
    "\n",
    "# ======================\n",
    "# ارزیابی ۱: LOSO روی سوژه‌ها (واقعی)\n",
    "# ======================\n",
    "def evaluate_loso(feats_all, seg_y, seg_subjects):\n",
    "    unique_subjects = np.unique(seg_subjects)\n",
    "    print(\"Unique subjects:\", unique_subjects)\n",
    "\n",
    "    seg_metrics = []\n",
    "    subj_metrics = []\n",
    "\n",
    "    for test_subj in unique_subjects:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Test subject: {test_subj}\")\n",
    "\n",
    "        test_mask = (seg_subjects == test_subj)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        X_train = feats_all[train_mask]\n",
    "        y_train = seg_y[train_mask]\n",
    "        X_test = feats_all[test_mask]\n",
    "        y_test = seg_y[test_mask]\n",
    "\n",
    "        print(\"Train segments:\", X_train.shape[0], \" | Test segments:\", X_test.shape[0])\n",
    "        print(\"Train label distribution:\", np.bincount(y_train))\n",
    "\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", SVC(kernel=\"rbf\",\n",
    "                        class_weight=\"balanced\",\n",
    "                        probability=False,\n",
    "                        random_state=RANDOM_STATE))\n",
    "        ])\n",
    "\n",
    "        param_grid = {\n",
    "            \"clf__C\": [1, 10],\n",
    "            \"clf__gamma\": [0.01, 0.1]\n",
    "        }\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "        grid = GridSearchCV(\n",
    "            pipe,\n",
    "            param_grid=param_grid,\n",
    "            scoring=\"f1\",\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        grid.fit(X_train, y_train)\n",
    "        print(\"Best params:\", grid.best_params_, \"| best f1 (cv):\", grid.best_score_)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "\n",
    "        # segment-level\n",
    "        y_pred_seg = best_model.predict(X_test)\n",
    "        acc_s = accuracy_score(y_test, y_pred_seg)\n",
    "        prec_s = precision_score(y_test, y_pred_seg, zero_division=0)\n",
    "        rec_s = recall_score(y_test, y_pred_seg, zero_division=0)\n",
    "        f1_s = f1_score(y_test, y_pred_seg, zero_division=0)\n",
    "        print(f\"Segment-level -> acc: {acc_s:.4f}, prec: {prec_s:.4f}, rec: {rec_s:.4f}, f1: {f1_s:.4f}\")\n",
    "        seg_metrics.append([acc_s, prec_s, rec_s, f1_s])\n",
    "\n",
    "        # subject-level (majority vote)\n",
    "        true_label = y_test[0]\n",
    "        pred_counts = np.bincount(y_pred_seg)\n",
    "        pred_label = np.argmax(pred_counts)\n",
    "\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level -> true: {true_label}, pred: {pred_label}, acc: {acc_subj:.4f}\")\n",
    "\n",
    "        subj_metrics.append([acc_subj, acc_subj, acc_subj, acc_subj])\n",
    "\n",
    "    seg_metrics = np.array(seg_metrics)\n",
    "    subj_metrics = np.array(subj_metrics)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Average SEGMENT-level (LOSO):\")\n",
    "    print(f\"Accuracy : {seg_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {seg_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {seg_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {seg_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Average SUBJECT-level (LOSO, majority vote):\")\n",
    "    print(f\"Accuracy : {subj_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {subj_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {subj_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {subj_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# ارزیابی ۲: 10-fold CV روی همه‌ی سگمنت‌ها (مثل مقاله‌ها – subject-dependent)\n",
    "# ======================\n",
    "def evaluate_segment_cv(feats_all, seg_y):\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(kernel=\"rbf\",\n",
    "                    class_weight=\"balanced\",\n",
    "                    probability=False,\n",
    "                    random_state=RANDOM_STATE))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        \"clf__C\": [1, 10],\n",
    "        \"clf__gamma\": [0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    grid = GridSearchCV(\n",
    "        pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"f1\",\n",
    "        cv=cv_inner,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    scores_acc = []\n",
    "    scores_f1 = []\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"10-fold CV over all segments (subject-dependent, شبیه اکثر مقاله‌ها)\")\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv_outer.split(feats_all, seg_y), start=1):\n",
    "        X_train, X_test = feats_all[train_idx], feats_all[test_idx]\n",
    "        y_train, y_test = seg_y[train_idx], seg_y[test_idx]\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_model = grid.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        print(f\"Fold {fold_idx}: acc={acc:.4f}, f1={f1:.4f}\")\n",
    "        scores_acc.append(acc)\n",
    "        scores_f1.append(f1)\n",
    "\n",
    "    print(\"\\nAverage (10-fold CV, segment-level):\")\n",
    "    print(f\"Accuracy: {np.mean(scores_acc):.4f} ± {np.std(scores_acc):.4f}\")\n",
    "    print(f\"F1-score: {np.mean(scores_f1):.4f} ± {np.std(scores_f1):.4f}\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# main\n",
    "# ======================\n",
    "def main():\n",
    "    # 1) لود داده + baseline correction\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline(\n",
    "        DATA_FOLDER,\n",
    "        INFO_CSV,\n",
    "        resample_to=RESAMPLE_TO,\n",
    "        use_baseline=USE_BASELINE\n",
    "    )\n",
    "\n",
    "    # 2) سگمنت‌ها\n",
    "    seg_X, seg_y, seg_subjects = make_segments(\n",
    "        X, y, subjects,\n",
    "        sfreq=sfreq,\n",
    "        window_sec=WINDOW_SEC,\n",
    "        overlap_ratio=OVERLAP_RATIO\n",
    "    )\n",
    "\n",
    "    # 3) فیچرها\n",
    "    feats_all = compute_bandpower_features(seg_X, sfreq)\n",
    "\n",
    "    # 4) ارزیابی واقعی (LOSO)\n",
    "    evaluate_loso(feats_all, seg_y, seg_subjects)\n",
    "\n",
    "    # 5) ارزیابی شبیه مقاله‌ها (10-fold CV روی سگمنت‌ها)\n",
    "    evaluate_segment_cv(feats_all, seg_y)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc1fa4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:32:25.194230Z",
     "iopub.status.busy": "2025-12-12T09:32:25.193601Z",
     "iopub.status.idle": "2025-12-12T09:32:25.205416Z",
     "shell.execute_reply": "2025-12-12T09:32:25.204852Z"
    },
    "papermill": {
     "duration": 0.021554,
     "end_time": "2025-12-12T09:32:25.206414",
     "exception": false,
     "start_time": "2025-12-12T09:32:25.184860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eegmat_data.py\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_FOLDER = \"/kaggle/input/ahmadi-dataset\"\n",
    "INFO_CSV = f\"{DATA_FOLDER}/subject-info.csv\"\n",
    "\n",
    "RESAMPLE_TO = 128\n",
    "WINDOW_SEC = 2.0\n",
    "OVERLAP_RATIO = 0.75  # 75%\n",
    "\n",
    "def load_task_edf_with_baseline(folder_path=DATA_FOLDER,\n",
    "                                info_csv_path=INFO_CSV,\n",
    "                                resample_to=RESAMPLE_TO,\n",
    "                                use_baseline=True):\n",
    "    folder = Path(folder_path)\n",
    "    info_df = pd.read_csv(info_csv_path)\n",
    "    label_map = dict(zip(info_df[\"Subject\"], info_df[\"Count quality\"]))\n",
    "\n",
    "    X_list, y_list, subjects = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for subj_name in info_df[\"Subject\"]:\n",
    "        task_file = folder / f\"{subj_name}_2.edf\"\n",
    "        rest_file = folder / f\"{subj_name}_1.edf\"\n",
    "\n",
    "        if not task_file.is_file():\n",
    "            print(f\"Task file not found for {subj_name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if subj_name not in label_map:\n",
    "            print(f\"{subj_name} not in subject-info, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Loading {subj_name}_1.edf (rest) and {subj_name}_2.edf (task)...\")\n",
    "        raw_task = mne.io.read_raw_edf(task_file, preload=True, verbose=False)\n",
    "\n",
    "        raw_rest = None\n",
    "        if use_baseline and rest_file.is_file():\n",
    "            raw_rest = mne.io.read_raw_edf(rest_file, preload=True, verbose=False)\n",
    "\n",
    "        if resample_to is not None:\n",
    "            raw_task.resample(resample_to)\n",
    "            if raw_rest is not None:\n",
    "                raw_rest.resample(resample_to)\n",
    "\n",
    "        if sfreq is None:\n",
    "            sfreq = raw_task.info[\"sfreq\"]\n",
    "\n",
    "        task_data = raw_task.get_data()  # (C, T)\n",
    "        if use_baseline and raw_rest is not None:\n",
    "            rest_data = raw_rest.get_data()\n",
    "            baseline = rest_data.mean(axis=1, keepdims=True)\n",
    "            task_data = task_data - baseline\n",
    "\n",
    "        X_list.append(task_data)\n",
    "        y_list.append(int(label_map[subj_name]))\n",
    "        subjects.append(subj_name)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No task files loaded.\")\n",
    "\n",
    "    lengths = [d.shape[1] for d in X_list]\n",
    "    min_len = min(lengths)\n",
    "    X = np.stack([d[:, :min_len] for d in X_list], axis=0)  # (N, C, T)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    subjects = np.array(subjects)\n",
    "\n",
    "    print(\"Final tensor X shape (N, C, T):\", X.shape)\n",
    "    print(\"Labels y shape:\", y.shape)\n",
    "\n",
    "    return X, y, subjects, sfreq\n",
    "\n",
    "\n",
    "def make_segments(X, y, subjects, sfreq, window_sec=WINDOW_SEC, overlap_ratio=OVERLAP_RATIO):\n",
    "    N, C, T = X.shape\n",
    "    win_size = int(window_sec * sfreq)\n",
    "    step_sec = window_sec * (1.0 - overlap_ratio)\n",
    "    step = max(1, int(step_sec * sfreq))\n",
    "\n",
    "    seg_X_list, seg_y_list, seg_subj_list = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        data = X[i]\n",
    "        subj_label = y[i]\n",
    "        subj_id = subjects[i]\n",
    "\n",
    "        start = 0\n",
    "        while start + win_size <= T:\n",
    "            seg = data[:, start:start+win_size]\n",
    "            seg_X_list.append(seg)\n",
    "            seg_y_list.append(subj_label)\n",
    "            seg_subj_list.append(subj_id)\n",
    "            start += step\n",
    "\n",
    "    seg_X = np.stack(seg_X_list, axis=0)\n",
    "    seg_y = np.array(seg_y_list, dtype=int)\n",
    "    seg_subjects = np.array(seg_subj_list)\n",
    "\n",
    "    print(\"Segmented data shape:\", seg_X.shape)\n",
    "    return seg_X, seg_y, seg_subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed59c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:32:25.222944Z",
     "iopub.status.busy": "2025-12-12T09:32:25.222757Z",
     "iopub.status.idle": "2025-12-12T09:32:32.015126Z",
     "shell.execute_reply": "2025-12-12T09:32:32.014252Z"
    },
    "papermill": {
     "duration": 6.802097,
     "end_time": "2025-12-12T09:32:32.016448",
     "exception": false,
     "start_time": "2025-12-12T09:32:25.214351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyriemann\r\n",
      "  Downloading pyriemann-0.9-py2.py3-none-any.whl.metadata (9.3 kB)\r\n",
      "Collecting numpy>=2.0.0 (from pyriemann)\r\n",
      "  Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyriemann) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.11/dist-packages (from pyriemann) (1.2.2)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pyriemann) (1.5.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pyriemann) (3.7.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24->pyriemann) (3.6.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (25.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyriemann) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pyriemann) (1.17.0)\r\n",
      "Downloading pyriemann-0.9-py2.py3-none-any.whl (127 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.7/127.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy, pyriemann\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.5 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.5 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.5 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-2.3.5 pyriemann-0.9\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyriemann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260fae0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:32:32.035928Z",
     "iopub.status.busy": "2025-12-12T09:32:32.035647Z",
     "iopub.status.idle": "2025-12-12T09:34:15.095865Z",
     "shell.execute_reply": "2025-12-12T09:34:15.095062Z"
    },
    "papermill": {
     "duration": 103.071638,
     "end_time": "2025-12-12T09:34:15.097040",
     "exception": false,
     "start_time": "2025-12-12T09:32:32.025402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Riemannian (no alignment) ===\n",
      "Loading Subject00_1.edf (rest) and Subject00_2.edf (task)...\n",
      "Loading Subject01_1.edf (rest) and Subject01_2.edf (task)...\n",
      "Loading Subject02_1.edf (rest) and Subject02_2.edf (task)...\n",
      "Loading Subject03_1.edf (rest) and Subject03_2.edf (task)...\n",
      "Loading Subject04_1.edf (rest) and Subject04_2.edf (task)...\n",
      "Loading Subject05_1.edf (rest) and Subject05_2.edf (task)...\n",
      "Loading Subject06_1.edf (rest) and Subject06_2.edf (task)...\n",
      "Loading Subject07_1.edf (rest) and Subject07_2.edf (task)...\n",
      "Loading Subject08_1.edf (rest) and Subject08_2.edf (task)...\n",
      "Loading Subject09_1.edf (rest) and Subject09_2.edf (task)...\n",
      "Loading Subject10_1.edf (rest) and Subject10_2.edf (task)...\n",
      "Loading Subject11_1.edf (rest) and Subject11_2.edf (task)...\n",
      "Loading Subject12_1.edf (rest) and Subject12_2.edf (task)...\n",
      "Loading Subject13_1.edf (rest) and Subject13_2.edf (task)...\n",
      "Loading Subject14_1.edf (rest) and Subject14_2.edf (task)...\n",
      "Loading Subject15_1.edf (rest) and Subject15_2.edf (task)...\n",
      "Loading Subject16_1.edf (rest) and Subject16_2.edf (task)...\n",
      "Loading Subject17_1.edf (rest) and Subject17_2.edf (task)...\n",
      "Loading Subject18_1.edf (rest) and Subject18_2.edf (task)...\n",
      "Loading Subject19_1.edf (rest) and Subject19_2.edf (task)...\n",
      "Loading Subject20_1.edf (rest) and Subject20_2.edf (task)...\n",
      "Loading Subject21_1.edf (rest) and Subject21_2.edf (task)...\n",
      "Loading Subject22_1.edf (rest) and Subject22_2.edf (task)...\n",
      "Loading Subject23_1.edf (rest) and Subject23_2.edf (task)...\n",
      "Loading Subject24_1.edf (rest) and Subject24_2.edf (task)...\n",
      "Loading Subject25_1.edf (rest) and Subject25_2.edf (task)...\n",
      "Loading Subject26_1.edf (rest) and Subject26_2.edf (task)...\n",
      "Loading Subject27_1.edf (rest) and Subject27_2.edf (task)...\n",
      "Loading Subject28_1.edf (rest) and Subject28_2.edf (task)...\n",
      "Loading Subject29_1.edf (rest) and Subject29_2.edf (task)...\n",
      "Loading Subject30_1.edf (rest) and Subject30_2.edf (task)...\n",
      "Loading Subject31_1.edf (rest) and Subject31_2.edf (task)...\n",
      "Loading Subject32_1.edf (rest) and Subject32_2.edf (task)...\n",
      "Loading Subject33_1.edf (rest) and Subject33_2.edf (task)...\n",
      "Loading Subject34_1.edf (rest) and Subject34_2.edf (task)...\n",
      "Loading Subject35_1.edf (rest) and Subject35_2.edf (task)...\n",
      "Final tensor X shape (N, C, T): (36, 21, 7936)\n",
      "Labels y shape: (36,)\n",
      "Segmented data shape: (4356, 21, 256)\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject00\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject01\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9587, prec: 1.0000, rec: 0.9587, f1: 0.9789\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject02\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject03\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject04\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0331, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject05\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9917, prec: 1.0000, rec: 0.9917, f1: 0.9959\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject06\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject07\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9587, prec: 1.0000, rec: 0.9587, f1: 0.9789\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject08\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8843, prec: 1.0000, rec: 0.8843, f1: 0.9386\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject09\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0496, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject10\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject11\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject12\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.2314, prec: 1.0000, rec: 0.2314, f1: 0.3758\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject13\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8182, prec: 1.0000, rec: 0.8182, f1: 0.9000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject14\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.2893, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject15\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8595, prec: 1.0000, rec: 0.8595, f1: 0.9244\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject16\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.6033, prec: 1.0000, rec: 0.6033, f1: 0.7526\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject17\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject18\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.2397, prec: 1.0000, rec: 0.2397, f1: 0.3867\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject19\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject20\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject21\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.6860, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject22\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject23\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9835, prec: 1.0000, rec: 0.9835, f1: 0.9917\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject24\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9669, prec: 1.0000, rec: 0.9669, f1: 0.9832\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject25\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8430, prec: 1.0000, rec: 0.8430, f1: 0.9148\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject26\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8512, prec: 1.0000, rec: 0.8512, f1: 0.9196\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject27\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0909, prec: 1.0000, rec: 0.0909, f1: 0.1667\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject28\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject29\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9421, prec: 1.0000, rec: 0.9421, f1: 0.9702\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject30\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject31\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.4463, prec: 1.0000, rec: 0.4463, f1: 0.6171\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject32\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8430, prec: 1.0000, rec: 0.8430, f1: 0.9148\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject33\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject34\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9587, prec: 1.0000, rec: 0.9587, f1: 0.9789\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject35\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Average SEGMENT-level (LOSO):\n",
      "Accuracy : 0.625803489439853\n",
      "Precision: 0.7222222222222222\n",
      "Recall   : 0.5964187327823691\n",
      "F1-score : 0.6302445787419698\n",
      "\n",
      "Average SUBJECT-level (LOSO, majority vote):\n",
      "Accuracy : 0.6388888888888888\n",
      "\n",
      "\n",
      "=== Riemannian + per-subject alignment ===\n",
      "Loading Subject00_1.edf (rest) and Subject00_2.edf (task)...\n",
      "Loading Subject01_1.edf (rest) and Subject01_2.edf (task)...\n",
      "Loading Subject02_1.edf (rest) and Subject02_2.edf (task)...\n",
      "Loading Subject03_1.edf (rest) and Subject03_2.edf (task)...\n",
      "Loading Subject04_1.edf (rest) and Subject04_2.edf (task)...\n",
      "Loading Subject05_1.edf (rest) and Subject05_2.edf (task)...\n",
      "Loading Subject06_1.edf (rest) and Subject06_2.edf (task)...\n",
      "Loading Subject07_1.edf (rest) and Subject07_2.edf (task)...\n",
      "Loading Subject08_1.edf (rest) and Subject08_2.edf (task)...\n",
      "Loading Subject09_1.edf (rest) and Subject09_2.edf (task)...\n",
      "Loading Subject10_1.edf (rest) and Subject10_2.edf (task)...\n",
      "Loading Subject11_1.edf (rest) and Subject11_2.edf (task)...\n",
      "Loading Subject12_1.edf (rest) and Subject12_2.edf (task)...\n",
      "Loading Subject13_1.edf (rest) and Subject13_2.edf (task)...\n",
      "Loading Subject14_1.edf (rest) and Subject14_2.edf (task)...\n",
      "Loading Subject15_1.edf (rest) and Subject15_2.edf (task)...\n",
      "Loading Subject16_1.edf (rest) and Subject16_2.edf (task)...\n",
      "Loading Subject17_1.edf (rest) and Subject17_2.edf (task)...\n",
      "Loading Subject18_1.edf (rest) and Subject18_2.edf (task)...\n",
      "Loading Subject19_1.edf (rest) and Subject19_2.edf (task)...\n",
      "Loading Subject20_1.edf (rest) and Subject20_2.edf (task)...\n",
      "Loading Subject21_1.edf (rest) and Subject21_2.edf (task)...\n",
      "Loading Subject22_1.edf (rest) and Subject22_2.edf (task)...\n",
      "Loading Subject23_1.edf (rest) and Subject23_2.edf (task)...\n",
      "Loading Subject24_1.edf (rest) and Subject24_2.edf (task)...\n",
      "Loading Subject25_1.edf (rest) and Subject25_2.edf (task)...\n",
      "Loading Subject26_1.edf (rest) and Subject26_2.edf (task)...\n",
      "Loading Subject27_1.edf (rest) and Subject27_2.edf (task)...\n",
      "Loading Subject28_1.edf (rest) and Subject28_2.edf (task)...\n",
      "Loading Subject29_1.edf (rest) and Subject29_2.edf (task)...\n",
      "Loading Subject30_1.edf (rest) and Subject30_2.edf (task)...\n",
      "Loading Subject31_1.edf (rest) and Subject31_2.edf (task)...\n",
      "Loading Subject32_1.edf (rest) and Subject32_2.edf (task)...\n",
      "Loading Subject33_1.edf (rest) and Subject33_2.edf (task)...\n",
      "Loading Subject34_1.edf (rest) and Subject34_2.edf (task)...\n",
      "Loading Subject35_1.edf (rest) and Subject35_2.edf (task)...\n",
      "Final tensor X shape (N, C, T): (36, 21, 7936)\n",
      "Labels y shape: (36,)\n",
      "Segmented data shape: (4356, 21, 256)\n",
      "Applying per-subject Riemannian alignment...\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject00\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0826, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject01\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9752, prec: 1.0000, rec: 0.9752, f1: 0.9874\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject02\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9091, prec: 1.0000, rec: 0.9091, f1: 0.9524\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject03\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9174, prec: 1.0000, rec: 0.9174, f1: 0.9569\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject04\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0083, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject05\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8347, prec: 1.0000, rec: 0.8347, f1: 0.9099\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject06\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.1570, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject07\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9256, prec: 1.0000, rec: 0.9256, f1: 0.9614\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject08\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.7438, prec: 1.0000, rec: 0.7438, f1: 0.8531\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject09\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0992, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject10\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.2066, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject11\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.7603, prec: 1.0000, rec: 0.7603, f1: 0.8638\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject12\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8264, prec: 1.0000, rec: 0.8264, f1: 0.9050\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject13\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject14\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0992, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject15\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.7851, prec: 1.0000, rec: 0.7851, f1: 0.8796\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject16\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8430, prec: 1.0000, rec: 0.8430, f1: 0.9148\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject17\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.7438, prec: 1.0000, rec: 0.7438, f1: 0.8531\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject18\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.4215, prec: 1.0000, rec: 0.4215, f1: 0.5930\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject19\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.0165, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject20\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject21\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.1818, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject22\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.4050, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject23\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8843, prec: 1.0000, rec: 0.8843, f1: 0.9386\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject24\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9835, prec: 1.0000, rec: 0.9835, f1: 0.9917\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject25\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8926, prec: 1.0000, rec: 0.8926, f1: 0.9432\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject26\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.6364, prec: 1.0000, rec: 0.6364, f1: 0.7778\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject27\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.6281, prec: 1.0000, rec: 0.6281, f1: 0.7716\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject28\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9091, prec: 1.0000, rec: 0.9091, f1: 0.9524\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject29\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8182, prec: 1.0000, rec: 0.8182, f1: 0.9000\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject30\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.1570, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject31\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9339, prec: 1.0000, rec: 0.9339, f1: 0.9658\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject32\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.6446, prec: 1.0000, rec: 0.6446, f1: 0.7839\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject33\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.7686, prec: 1.0000, rec: 0.7686, f1: 0.8692\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject34\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.8512, prec: 1.0000, rec: 0.8512, f1: 0.9196\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject35\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Segment-level -> acc: 0.9917, prec: 1.0000, rec: 0.9917, f1: 0.9959\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Average SEGMENT-level (LOSO):\n",
      "Accuracy : 0.6400367309458218\n",
      "Precision: 0.7222222222222222\n",
      "Recall   : 0.6007805325987143\n",
      "F1-score : 0.6511127424534001\n",
      "\n",
      "Average SUBJECT-level (LOSO, majority vote):\n",
      "Accuracy : 0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "# riemann_loso.py\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.utils.mean import mean_riemann\n",
    "\n",
    "# from eegmat_data import load_task_edf_with_baseline, make_segments\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "def compute_covariances(seg_X):\n",
    "    \"\"\"\n",
    "    seg_X: (N_segments, C, T)\n",
    "    returns: covs (N_segments, C, C)\n",
    "    \"\"\"\n",
    "    cov_est = Covariances(estimator='oas')\n",
    "    covs = cov_est.fit_transform(seg_X)\n",
    "    return covs\n",
    "\n",
    "\n",
    "def align_per_subject(covs, seg_subjects):\n",
    "    \"\"\"\n",
    "    Riemannian centering per subject:\n",
    "    cov_aligned = M_s^{-1/2} * C * M_s^{-1/2}\n",
    "    \"\"\"\n",
    "    from scipy.linalg import fractional_matrix_power\n",
    "\n",
    "    covs_aligned = np.zeros_like(covs)\n",
    "    unique_subj = np.unique(seg_subjects)\n",
    "\n",
    "    for subj in unique_subj:\n",
    "        mask = (seg_subjects == subj)\n",
    "        cov_subj = covs[mask]  # (N_subj, C, C)\n",
    "        M = mean_riemann(cov_subj)  # (C, C)\n",
    "        Minv_half = fractional_matrix_power(M, -0.5)\n",
    "        for i_idx, c in zip(np.where(mask)[0], cov_subj):\n",
    "            covs_aligned[i_idx] = Minv_half @ c @ Minv_half.T\n",
    "\n",
    "    return covs_aligned\n",
    "\n",
    "\n",
    "def evaluate_riemann_loso(use_alignment=False, clf_type=\"svm\"):\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline()\n",
    "    seg_X, seg_y, seg_subjects = make_segments(X, y, subjects, sfreq)\n",
    "\n",
    "    covs = compute_covariances(seg_X)\n",
    "    if use_alignment:\n",
    "        print(\"Applying per-subject Riemannian alignment...\")\n",
    "        covs = align_per_subject(covs, seg_subjects)\n",
    "\n",
    "    ts = TangentSpace()\n",
    "    feats_all = ts.fit_transform(covs)  # (N_segments, n_features)\n",
    "\n",
    "    unique_subjects = np.unique(seg_subjects)\n",
    "    seg_metrics = []\n",
    "    subj_metrics = []\n",
    "\n",
    "    for test_subj in unique_subjects:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"Test subject:\", test_subj)\n",
    "\n",
    "        test_mask = (seg_subjects == test_subj)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        X_train = feats_all[train_mask]\n",
    "        y_train = seg_y[train_mask]\n",
    "        X_test = feats_all[test_mask]\n",
    "        y_test = seg_y[test_mask]\n",
    "\n",
    "        print(\"Train segments:\", X_train.shape[0], \"| Test segments:\", X_test.shape[0])\n",
    "\n",
    "        if clf_type == \"svm\":\n",
    "            clf = SVC(kernel=\"rbf\", class_weight=\"balanced\", probability=False, random_state=RANDOM_STATE)\n",
    "        else:\n",
    "            clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_seg = clf.predict(X_test)\n",
    "\n",
    "        acc_s = accuracy_score(y_test, y_pred_seg)\n",
    "        prec_s = precision_score(y_test, y_pred_seg, zero_division=0)\n",
    "        rec_s = recall_score(y_test, y_pred_seg, zero_division=0)\n",
    "        f1_s = f1_score(y_test, y_pred_seg, zero_division=0)\n",
    "        print(f\"Segment-level -> acc: {acc_s:.4f}, prec: {prec_s:.4f}, rec: {rec_s:.4f}, f1: {f1_s:.4f}\")\n",
    "        seg_metrics.append([acc_s, prec_s, rec_s, f1_s])\n",
    "\n",
    "        # subject-level majority vote\n",
    "        true_label = y_test[0]\n",
    "        counts = np.bincount(y_pred_seg)\n",
    "        pred_label = np.argmax(counts)\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level -> true: {true_label}, pred: {pred_label}, acc: {acc_subj:.4f}\")\n",
    "        subj_metrics.append([acc_subj, acc_subj, acc_subj, acc_subj])\n",
    "\n",
    "    seg_metrics = np.array(seg_metrics)\n",
    "    subj_metrics = np.array(subj_metrics)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Average SEGMENT-level (LOSO):\")\n",
    "    print(\"Accuracy :\", seg_metrics[:, 0].mean())\n",
    "    print(\"Precision:\", seg_metrics[:, 1].mean())\n",
    "    print(\"Recall   :\", seg_metrics[:, 2].mean())\n",
    "    print(\"F1-score :\", seg_metrics[:, 3].mean())\n",
    "\n",
    "    print(\"\\nAverage SUBJECT-level (LOSO, majority vote):\")\n",
    "    print(\"Accuracy :\", subj_metrics[:, 0].mean())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Riemannian (no alignment) ===\")\n",
    "    evaluate_riemann_loso(use_alignment=False, clf_type=\"svm\")\n",
    "\n",
    "    print(\"\\n\\n=== Riemannian + per-subject alignment ===\")\n",
    "    evaluate_riemann_loso(use_alignment=True, clf_type=\"svm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f182a5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:34:15.124198Z",
     "iopub.status.busy": "2025-12-12T09:34:15.123969Z",
     "iopub.status.idle": "2025-12-12T09:35:22.122971Z",
     "shell.execute_reply": "2025-12-12T09:35:22.122086Z"
    },
    "papermill": {
     "duration": 67.014033,
     "end_time": "2025-12-12T09:35:22.124253",
     "exception": false,
     "start_time": "2025-12-12T09:34:15.110220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.3.5)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2dbb92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:35:22.187862Z",
     "iopub.status.busy": "2025-12-12T09:35:22.187389Z",
     "iopub.status.idle": "2025-12-12T09:39:24.100787Z",
     "shell.execute_reply": "2025-12-12T09:39:24.099969Z"
    },
    "papermill": {
     "duration": 241.946572,
     "end_time": "2025-12-12T09:39:24.102102",
     "exception": false,
     "start_time": "2025-12-12T09:35:22.155530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Subject00_1.edf (rest) and Subject00_2.edf (task)...\n",
      "Loading Subject01_1.edf (rest) and Subject01_2.edf (task)...\n",
      "Loading Subject02_1.edf (rest) and Subject02_2.edf (task)...\n",
      "Loading Subject03_1.edf (rest) and Subject03_2.edf (task)...\n",
      "Loading Subject04_1.edf (rest) and Subject04_2.edf (task)...\n",
      "Loading Subject05_1.edf (rest) and Subject05_2.edf (task)...\n",
      "Loading Subject06_1.edf (rest) and Subject06_2.edf (task)...\n",
      "Loading Subject07_1.edf (rest) and Subject07_2.edf (task)...\n",
      "Loading Subject08_1.edf (rest) and Subject08_2.edf (task)...\n",
      "Loading Subject09_1.edf (rest) and Subject09_2.edf (task)...\n",
      "Loading Subject10_1.edf (rest) and Subject10_2.edf (task)...\n",
      "Loading Subject11_1.edf (rest) and Subject11_2.edf (task)...\n",
      "Loading Subject12_1.edf (rest) and Subject12_2.edf (task)...\n",
      "Loading Subject13_1.edf (rest) and Subject13_2.edf (task)...\n",
      "Loading Subject14_1.edf (rest) and Subject14_2.edf (task)...\n",
      "Loading Subject15_1.edf (rest) and Subject15_2.edf (task)...\n",
      "Loading Subject16_1.edf (rest) and Subject16_2.edf (task)...\n",
      "Loading Subject17_1.edf (rest) and Subject17_2.edf (task)...\n",
      "Loading Subject18_1.edf (rest) and Subject18_2.edf (task)...\n",
      "Loading Subject19_1.edf (rest) and Subject19_2.edf (task)...\n",
      "Loading Subject20_1.edf (rest) and Subject20_2.edf (task)...\n",
      "Loading Subject21_1.edf (rest) and Subject21_2.edf (task)...\n",
      "Loading Subject22_1.edf (rest) and Subject22_2.edf (task)...\n",
      "Loading Subject23_1.edf (rest) and Subject23_2.edf (task)...\n",
      "Loading Subject24_1.edf (rest) and Subject24_2.edf (task)...\n",
      "Loading Subject25_1.edf (rest) and Subject25_2.edf (task)...\n",
      "Loading Subject26_1.edf (rest) and Subject26_2.edf (task)...\n",
      "Loading Subject27_1.edf (rest) and Subject27_2.edf (task)...\n",
      "Loading Subject28_1.edf (rest) and Subject28_2.edf (task)...\n",
      "Loading Subject29_1.edf (rest) and Subject29_2.edf (task)...\n",
      "Loading Subject30_1.edf (rest) and Subject30_2.edf (task)...\n",
      "Loading Subject31_1.edf (rest) and Subject31_2.edf (task)...\n",
      "Loading Subject32_1.edf (rest) and Subject32_2.edf (task)...\n",
      "Loading Subject33_1.edf (rest) and Subject33_2.edf (task)...\n",
      "Loading Subject34_1.edf (rest) and Subject34_2.edf (task)...\n",
      "Loading Subject35_1.edf (rest) and Subject35_2.edf (task)...\n",
      "Final tensor X shape (N, C, T): (36, 21, 7936)\n",
      "Labels y shape: (36,)\n",
      "Segmented data shape: (4356, 21, 256)\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject00\n",
      "Epoch 1/10, val acc=0.7335\n",
      "Epoch 2/10, val acc=0.7335\n",
      "Epoch 3/10, val acc=0.2665\n",
      "Epoch 4/10, val acc=0.7335\n",
      "Epoch 5/10, val acc=0.7335\n",
      "Epoch 6/10, val acc=0.2665\n",
      "Epoch 7/10, val acc=0.7335\n",
      "Epoch 8/10, val acc=0.7335\n",
      "Epoch 9/10, val acc=0.7335\n",
      "Epoch 10/10, val acc=0.2665\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject01\n",
      "Epoch 1/10, val acc=0.2759\n",
      "Epoch 2/10, val acc=0.2759\n",
      "Epoch 3/10, val acc=0.2759\n",
      "Epoch 4/10, val acc=0.2759\n",
      "Epoch 5/10, val acc=0.2759\n",
      "Epoch 6/10, val acc=0.2759\n",
      "Epoch 7/10, val acc=0.2759\n",
      "Epoch 8/10, val acc=0.2759\n",
      "Epoch 9/10, val acc=0.7241\n",
      "Epoch 10/10, val acc=0.7241\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject02\n",
      "Epoch 1/10, val acc=0.7335\n",
      "Epoch 2/10, val acc=0.2665\n",
      "Epoch 3/10, val acc=0.7335\n",
      "Epoch 4/10, val acc=0.7335\n",
      "Epoch 5/10, val acc=0.7335\n",
      "Epoch 6/10, val acc=0.2665\n",
      "Epoch 7/10, val acc=0.7358\n",
      "Epoch 8/10, val acc=0.7335\n",
      "Epoch 9/10, val acc=0.2665\n",
      "Epoch 10/10, val acc=0.7335\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject03\n",
      "Epoch 1/10, val acc=0.6981\n",
      "Epoch 2/10, val acc=0.3019\n",
      "Epoch 3/10, val acc=0.6981\n",
      "Epoch 4/10, val acc=0.6981\n",
      "Epoch 5/10, val acc=0.3019\n",
      "Epoch 6/10, val acc=0.6981\n",
      "Epoch 7/10, val acc=0.6981\n",
      "Epoch 8/10, val acc=0.6981\n",
      "Epoch 9/10, val acc=0.6981\n",
      "Epoch 10/10, val acc=0.6981\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject04\n",
      "Epoch 1/10, val acc=0.7358\n",
      "Epoch 2/10, val acc=0.7358\n",
      "Epoch 3/10, val acc=0.2642\n",
      "Epoch 4/10, val acc=0.7358\n",
      "Epoch 5/10, val acc=0.2642\n",
      "Epoch 6/10, val acc=0.7358\n",
      "Epoch 7/10, val acc=0.7358\n",
      "Epoch 8/10, val acc=0.7358\n",
      "Epoch 9/10, val acc=0.7358\n",
      "Epoch 10/10, val acc=0.7358\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject05\n",
      "Epoch 1/10, val acc=0.7005\n",
      "Epoch 2/10, val acc=0.7005\n",
      "Epoch 3/10, val acc=0.7005\n",
      "Epoch 4/10, val acc=0.7005\n",
      "Epoch 5/10, val acc=0.2995\n",
      "Epoch 6/10, val acc=0.2995\n",
      "Epoch 7/10, val acc=0.7005\n",
      "Epoch 8/10, val acc=0.2995\n",
      "Epoch 9/10, val acc=0.7005\n",
      "Epoch 10/10, val acc=0.7005\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject06\n",
      "Epoch 1/10, val acc=0.7476\n",
      "Epoch 2/10, val acc=0.7476\n",
      "Epoch 3/10, val acc=0.2524\n",
      "Epoch 4/10, val acc=0.2524\n",
      "Epoch 5/10, val acc=0.2524\n",
      "Epoch 6/10, val acc=0.2524\n",
      "Epoch 7/10, val acc=0.2524\n",
      "Epoch 8/10, val acc=0.7476\n",
      "Epoch 9/10, val acc=0.2524\n",
      "Epoch 10/10, val acc=0.7476\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject07\n",
      "Epoch 1/10, val acc=0.6840\n",
      "Epoch 2/10, val acc=0.3231\n",
      "Epoch 3/10, val acc=0.3231\n",
      "Epoch 4/10, val acc=0.6769\n",
      "Epoch 5/10, val acc=0.3231\n",
      "Epoch 6/10, val acc=0.6769\n",
      "Epoch 7/10, val acc=0.6769\n",
      "Epoch 8/10, val acc=0.6769\n",
      "Epoch 9/10, val acc=0.3231\n",
      "Epoch 10/10, val acc=0.6769\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject08\n",
      "Epoch 1/10, val acc=0.6863\n",
      "Epoch 2/10, val acc=0.6863\n",
      "Epoch 3/10, val acc=0.6863\n",
      "Epoch 4/10, val acc=0.3137\n",
      "Epoch 5/10, val acc=0.6863\n",
      "Epoch 6/10, val acc=0.6863\n",
      "Epoch 7/10, val acc=0.3137\n",
      "Epoch 8/10, val acc=0.6863\n",
      "Epoch 9/10, val acc=0.3137\n",
      "Epoch 10/10, val acc=0.6863\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject09\n",
      "Epoch 1/10, val acc=0.7335\n",
      "Epoch 2/10, val acc=0.2665\n",
      "Epoch 3/10, val acc=0.2665\n",
      "Epoch 4/10, val acc=0.7335\n",
      "Epoch 5/10, val acc=0.7335\n",
      "Epoch 6/10, val acc=0.7335\n",
      "Epoch 7/10, val acc=0.7335\n",
      "Epoch 8/10, val acc=0.7335\n",
      "Epoch 9/10, val acc=0.7335\n",
      "Epoch 10/10, val acc=0.7335\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject10\n",
      "Epoch 1/10, val acc=0.2476\n",
      "Epoch 2/10, val acc=0.7524\n",
      "Epoch 3/10, val acc=0.7524\n",
      "Epoch 4/10, val acc=0.2476\n",
      "Epoch 5/10, val acc=0.7524\n",
      "Epoch 6/10, val acc=0.7524\n",
      "Epoch 7/10, val acc=0.2476\n",
      "Epoch 8/10, val acc=0.7524\n",
      "Epoch 9/10, val acc=0.2476\n",
      "Epoch 10/10, val acc=0.7524\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject11\n",
      "Epoch 1/10, val acc=0.7311\n",
      "Epoch 2/10, val acc=0.7311\n",
      "Epoch 3/10, val acc=0.2689\n",
      "Epoch 4/10, val acc=0.7311\n",
      "Epoch 5/10, val acc=0.2689\n",
      "Epoch 6/10, val acc=0.7311\n",
      "Epoch 7/10, val acc=0.7311\n",
      "Epoch 8/10, val acc=0.7311\n",
      "Epoch 9/10, val acc=0.7311\n",
      "Epoch 10/10, val acc=0.7311\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject12\n",
      "Epoch 1/10, val acc=0.3184\n",
      "Epoch 2/10, val acc=0.6816\n",
      "Epoch 3/10, val acc=0.6816\n",
      "Epoch 4/10, val acc=0.6816\n",
      "Epoch 5/10, val acc=0.6816\n",
      "Epoch 6/10, val acc=0.6816\n",
      "Epoch 7/10, val acc=0.6816\n",
      "Epoch 8/10, val acc=0.6816\n",
      "Epoch 9/10, val acc=0.3184\n",
      "Epoch 10/10, val acc=0.6816\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject13\n",
      "Epoch 1/10, val acc=0.3160\n",
      "Epoch 2/10, val acc=0.6840\n",
      "Epoch 3/10, val acc=0.3514\n",
      "Epoch 4/10, val acc=0.6840\n",
      "Epoch 5/10, val acc=0.3160\n",
      "Epoch 6/10, val acc=0.3160\n",
      "Epoch 7/10, val acc=0.6840\n",
      "Epoch 8/10, val acc=0.6840\n",
      "Epoch 9/10, val acc=0.6840\n",
      "Epoch 10/10, val acc=0.6840\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject14\n",
      "Epoch 1/10, val acc=0.7429\n",
      "Epoch 2/10, val acc=0.2571\n",
      "Epoch 3/10, val acc=0.7429\n",
      "Epoch 4/10, val acc=0.7429\n",
      "Epoch 5/10, val acc=0.7429\n",
      "Epoch 6/10, val acc=0.7429\n",
      "Epoch 7/10, val acc=0.7429\n",
      "Epoch 8/10, val acc=0.7429\n",
      "Epoch 9/10, val acc=0.7429\n",
      "Epoch 10/10, val acc=0.2571\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject15\n",
      "Epoch 1/10, val acc=0.7241\n",
      "Epoch 2/10, val acc=0.7241\n",
      "Epoch 3/10, val acc=0.7241\n",
      "Epoch 4/10, val acc=0.7241\n",
      "Epoch 5/10, val acc=0.7241\n",
      "Epoch 6/10, val acc=0.2759\n",
      "Epoch 7/10, val acc=0.2759\n",
      "Epoch 8/10, val acc=0.7241\n",
      "Epoch 9/10, val acc=0.7241\n",
      "Epoch 10/10, val acc=0.7241\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject16\n",
      "Epoch 1/10, val acc=0.7028\n",
      "Epoch 2/10, val acc=0.7028\n",
      "Epoch 3/10, val acc=0.7028\n",
      "Epoch 4/10, val acc=0.7028\n",
      "Epoch 5/10, val acc=0.7028\n",
      "Epoch 6/10, val acc=0.7028\n",
      "Epoch 7/10, val acc=0.7028\n",
      "Epoch 8/10, val acc=0.7028\n",
      "Epoch 9/10, val acc=0.7028\n",
      "Epoch 10/10, val acc=0.2972\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject17\n",
      "Epoch 1/10, val acc=0.7170\n",
      "Epoch 2/10, val acc=0.7170\n",
      "Epoch 3/10, val acc=0.7170\n",
      "Epoch 4/10, val acc=0.2830\n",
      "Epoch 5/10, val acc=0.7170\n",
      "Epoch 6/10, val acc=0.2830\n",
      "Epoch 7/10, val acc=0.7170\n",
      "Epoch 8/10, val acc=0.2830\n",
      "Epoch 9/10, val acc=0.7170\n",
      "Epoch 10/10, val acc=0.7170\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject18\n",
      "Epoch 1/10, val acc=0.6769\n",
      "Epoch 2/10, val acc=0.3231\n",
      "Epoch 3/10, val acc=0.3231\n",
      "Epoch 4/10, val acc=0.3231\n",
      "Epoch 5/10, val acc=0.6769\n",
      "Epoch 6/10, val acc=0.6769\n",
      "Epoch 7/10, val acc=0.6769\n",
      "Epoch 8/10, val acc=0.3231\n",
      "Epoch 9/10, val acc=0.6769\n",
      "Epoch 10/10, val acc=0.3231\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject19\n",
      "Epoch 1/10, val acc=0.7382\n",
      "Epoch 2/10, val acc=0.7382\n",
      "Epoch 3/10, val acc=0.7382\n",
      "Epoch 4/10, val acc=0.7382\n",
      "Epoch 5/10, val acc=0.7382\n",
      "Epoch 6/10, val acc=0.7382\n",
      "Epoch 7/10, val acc=0.2618\n",
      "Epoch 8/10, val acc=0.2618\n",
      "Epoch 9/10, val acc=0.7382\n",
      "Epoch 10/10, val acc=0.7382\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject20\n",
      "Epoch 1/10, val acc=0.7075\n",
      "Epoch 2/10, val acc=0.7075\n",
      "Epoch 3/10, val acc=0.7075\n",
      "Epoch 4/10, val acc=0.2925\n",
      "Epoch 5/10, val acc=0.2925\n",
      "Epoch 6/10, val acc=0.7075\n",
      "Epoch 7/10, val acc=0.7075\n",
      "Epoch 8/10, val acc=0.7075\n",
      "Epoch 9/10, val acc=0.2925\n",
      "Epoch 10/10, val acc=0.7075\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject21\n",
      "Epoch 1/10, val acc=0.7335\n",
      "Epoch 2/10, val acc=0.7335\n",
      "Epoch 3/10, val acc=0.7335\n",
      "Epoch 4/10, val acc=0.7335\n",
      "Epoch 5/10, val acc=0.7335\n",
      "Epoch 6/10, val acc=0.7335\n",
      "Epoch 7/10, val acc=0.7335\n",
      "Epoch 8/10, val acc=0.2665\n",
      "Epoch 9/10, val acc=0.7335\n",
      "Epoch 10/10, val acc=0.7335\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject22\n",
      "Epoch 1/10, val acc=0.7665\n",
      "Epoch 2/10, val acc=0.7665\n",
      "Epoch 3/10, val acc=0.2335\n",
      "Epoch 4/10, val acc=0.7665\n",
      "Epoch 5/10, val acc=0.7665\n",
      "Epoch 6/10, val acc=0.7665\n",
      "Epoch 7/10, val acc=0.2335\n",
      "Epoch 8/10, val acc=0.7665\n",
      "Epoch 9/10, val acc=0.7665\n",
      "Epoch 10/10, val acc=0.2335\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject23\n",
      "Epoch 1/10, val acc=0.3019\n",
      "Epoch 2/10, val acc=0.6981\n",
      "Epoch 3/10, val acc=0.3019\n",
      "Epoch 4/10, val acc=0.3019\n",
      "Epoch 5/10, val acc=0.3019\n",
      "Epoch 6/10, val acc=0.6981\n",
      "Epoch 7/10, val acc=0.3019\n",
      "Epoch 8/10, val acc=0.3019\n",
      "Epoch 9/10, val acc=0.6981\n",
      "Epoch 10/10, val acc=0.6981\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject24\n",
      "Epoch 1/10, val acc=0.6698\n",
      "Epoch 2/10, val acc=0.6698\n",
      "Epoch 3/10, val acc=0.3302\n",
      "Epoch 4/10, val acc=0.6698\n",
      "Epoch 5/10, val acc=0.6698\n",
      "Epoch 6/10, val acc=0.6698\n",
      "Epoch 7/10, val acc=0.6698\n",
      "Epoch 8/10, val acc=0.6698\n",
      "Epoch 9/10, val acc=0.6698\n",
      "Epoch 10/10, val acc=0.6698\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject25\n",
      "Epoch 1/10, val acc=0.7217\n",
      "Epoch 2/10, val acc=0.7217\n",
      "Epoch 3/10, val acc=0.7217\n",
      "Epoch 4/10, val acc=0.2783\n",
      "Epoch 5/10, val acc=0.7217\n",
      "Epoch 6/10, val acc=0.2783\n",
      "Epoch 7/10, val acc=0.7217\n",
      "Epoch 8/10, val acc=0.7217\n",
      "Epoch 9/10, val acc=0.7217\n",
      "Epoch 10/10, val acc=0.7217\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject26\n",
      "Epoch 1/10, val acc=0.7075\n",
      "Epoch 2/10, val acc=0.7075\n",
      "Epoch 3/10, val acc=0.7075\n",
      "Epoch 4/10, val acc=0.7075\n",
      "Epoch 5/10, val acc=0.2925\n",
      "Epoch 6/10, val acc=0.7075\n",
      "Epoch 7/10, val acc=0.7075\n",
      "Epoch 8/10, val acc=0.7075\n",
      "Epoch 9/10, val acc=0.7075\n",
      "Epoch 10/10, val acc=0.7075\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject27\n",
      "Epoch 1/10, val acc=0.6698\n",
      "Epoch 2/10, val acc=0.6698\n",
      "Epoch 3/10, val acc=0.3302\n",
      "Epoch 4/10, val acc=0.3302\n",
      "Epoch 5/10, val acc=0.6698\n",
      "Epoch 6/10, val acc=0.3302\n",
      "Epoch 7/10, val acc=0.3302\n",
      "Epoch 8/10, val acc=0.3302\n",
      "Epoch 9/10, val acc=0.3302\n",
      "Epoch 10/10, val acc=0.6698\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject28\n",
      "Epoch 1/10, val acc=0.2948\n",
      "Epoch 2/10, val acc=0.7052\n",
      "Epoch 3/10, val acc=0.2948\n",
      "Epoch 4/10, val acc=0.3066\n",
      "Epoch 5/10, val acc=0.7052\n",
      "Epoch 6/10, val acc=0.2948\n",
      "Epoch 7/10, val acc=0.7052\n",
      "Epoch 8/10, val acc=0.7052\n",
      "Epoch 9/10, val acc=0.2948\n",
      "Epoch 10/10, val acc=0.2948\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject29\n",
      "Epoch 1/10, val acc=0.6887\n",
      "Epoch 2/10, val acc=0.6887\n",
      "Epoch 3/10, val acc=0.3113\n",
      "Epoch 4/10, val acc=0.6887\n",
      "Epoch 5/10, val acc=0.6887\n",
      "Epoch 6/10, val acc=0.6887\n",
      "Epoch 7/10, val acc=0.3113\n",
      "Epoch 8/10, val acc=0.3113\n",
      "Epoch 9/10, val acc=0.6887\n",
      "Epoch 10/10, val acc=0.3113\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject30\n",
      "Epoch 1/10, val acc=0.2830\n",
      "Epoch 2/10, val acc=0.2830\n",
      "Epoch 3/10, val acc=0.7170\n",
      "Epoch 4/10, val acc=0.2830\n",
      "Epoch 5/10, val acc=0.7170\n",
      "Epoch 6/10, val acc=0.7170\n",
      "Epoch 7/10, val acc=0.2830\n",
      "Epoch 8/10, val acc=0.2830\n",
      "Epoch 9/10, val acc=0.2830\n",
      "Epoch 10/10, val acc=0.2830\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject31\n",
      "Epoch 1/10, val acc=0.2618\n",
      "Epoch 2/10, val acc=0.2618\n",
      "Epoch 3/10, val acc=0.2618\n",
      "Epoch 4/10, val acc=0.7382\n",
      "Epoch 5/10, val acc=0.2618\n",
      "Epoch 6/10, val acc=0.7382\n",
      "Epoch 7/10, val acc=0.7382\n",
      "Epoch 8/10, val acc=0.7382\n",
      "Epoch 9/10, val acc=0.2618\n",
      "Epoch 10/10, val acc=0.7382\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject32\n",
      "Epoch 1/10, val acc=0.7288\n",
      "Epoch 2/10, val acc=0.2712\n",
      "Epoch 3/10, val acc=0.7288\n",
      "Epoch 4/10, val acc=0.2712\n",
      "Epoch 5/10, val acc=0.7288\n",
      "Epoch 6/10, val acc=0.7288\n",
      "Epoch 7/10, val acc=0.7288\n",
      "Epoch 8/10, val acc=0.7288\n",
      "Epoch 9/10, val acc=0.2712\n",
      "Epoch 10/10, val acc=0.7288\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject33\n",
      "Epoch 1/10, val acc=0.7052\n",
      "Epoch 2/10, val acc=0.7052\n",
      "Epoch 3/10, val acc=0.2948\n",
      "Epoch 4/10, val acc=0.7052\n",
      "Epoch 5/10, val acc=0.2948\n",
      "Epoch 6/10, val acc=0.2948\n",
      "Epoch 7/10, val acc=0.7052\n",
      "Epoch 8/10, val acc=0.2948\n",
      "Epoch 9/10, val acc=0.2948\n",
      "Epoch 10/10, val acc=0.4623\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject34\n",
      "Epoch 1/10, val acc=0.7311\n",
      "Epoch 2/10, val acc=0.7311\n",
      "Epoch 3/10, val acc=0.7311\n",
      "Epoch 4/10, val acc=0.7311\n",
      "Epoch 5/10, val acc=0.2689\n",
      "Epoch 6/10, val acc=0.7311\n",
      "Epoch 7/10, val acc=0.7311\n",
      "Epoch 8/10, val acc=0.7311\n",
      "Epoch 9/10, val acc=0.2689\n",
      "Epoch 10/10, val acc=0.2689\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject35\n",
      "Epoch 1/10, val acc=0.7075\n",
      "Epoch 2/10, val acc=0.2925\n",
      "Epoch 3/10, val acc=0.2925\n",
      "Epoch 4/10, val acc=0.7075\n",
      "Epoch 5/10, val acc=0.7075\n",
      "Epoch 6/10, val acc=0.2925\n",
      "Epoch 7/10, val acc=0.7075\n",
      "Epoch 8/10, val acc=0.2925\n",
      "Epoch 9/10, val acc=0.2925\n",
      "Epoch 10/10, val acc=0.7075\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Average SUBJECT-level (LOSO, DANN): 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# dann_eegmat.py\n",
    "import numpy as np\n",
    "# from eegmat_data import load_task_edf_with_baseline, make_segments\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class EEGSegmentDataset(Dataset):\n",
    "    def __init__(self, X, y, subj_ids):\n",
    "        # X: (N, C, T)\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "        # subj_ids: mapping string -> int باید قبلش انجام بشه\n",
    "        self.subj_ids = torch.from_numpy(subj_ids).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.subj_ids[idx]\n",
    "\n",
    "\n",
    "# ---------- Gradient Reversal Layer ----------\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambd):\n",
    "        ctx.lambd = lambd\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.lambd * grad_output, None\n",
    "\n",
    "\n",
    "def grad_reverse(x, lambd=1.0):\n",
    "    return GradReverse.apply(x, lambd)\n",
    "\n",
    "\n",
    "# ---------- Model ----------\n",
    "class DANN_EEG(nn.Module):\n",
    "    def __init__(self, n_channels, input_len, n_domains, feat_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, 32, kernel_size=7, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),  # -> (B, 128, 1)\n",
    "        )\n",
    "        self.feat = nn.Linear(128, feat_dim)\n",
    "\n",
    "        self.label_head = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feat_dim, 1)\n",
    "        )\n",
    "\n",
    "        self.domain_head = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feat_dim, n_domains)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lambd=0.0):\n",
    "        # x: (B, C, T)\n",
    "        h = self.conv(x)          # (B, 128, 1)\n",
    "        h = h.squeeze(-1)         # (B, 128)\n",
    "        h = self.feat(h)          # (B, feat_dim)\n",
    "\n",
    "        # label prediction\n",
    "        logits_label = self.label_head(h).squeeze(-1)  # (B,)\n",
    "\n",
    "        # domain prediction with GRL\n",
    "        h_rev = grad_reverse(h, lambd)\n",
    "        logits_domain = self.domain_head(h_rev)        # (B, n_domains)\n",
    "\n",
    "        return logits_label, logits_domain\n",
    "\n",
    "\n",
    "# ---------- Helper: subject mapping ----------\n",
    "def encode_subjects(subj_array, train_subjects):\n",
    "    \"\"\"\n",
    "    subj_array: (N_segments,) with string IDs\n",
    "    train_subjects: unique strings used in this fold\n",
    "    returns: domain_ids (int) for each segment, domain_label_map dict\n",
    "    \"\"\"\n",
    "    subj_to_idx = {s: i for i, s in enumerate(train_subjects)}\n",
    "    domain_ids = np.array([subj_to_idx[s] for s in subj_array])\n",
    "    return domain_ids, subj_to_idx\n",
    "\n",
    "\n",
    "# ---------- Training Loop ----------\n",
    "def train_dann_for_fold(X_train, y_train, subj_train, X_val, y_val, subj_val,\n",
    "                        num_epochs=15, batch_size=64):\n",
    "    # Map subject strings to domain ids (only train subjects)\n",
    "    unique_train_subj = np.unique(subj_train)\n",
    "    train_domain_ids, subj_to_idx = encode_subjects(subj_train, unique_train_subj)\n",
    "\n",
    "    # For validation segments, if subj not in train (shouldn't happen here for LOSO),\n",
    "    # we skip domain loss; ساده‌ترین حالت: domain id = 0 (ignored).\n",
    "    val_domain_ids = np.array([subj_to_idx.get(s, 0) for s in subj_val])\n",
    "\n",
    "    train_ds = EEGSegmentDataset(X_train, y_train, train_domain_ids)\n",
    "    val_ds = EEGSegmentDataset(X_val, y_val, val_domain_ids)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    n_channels = X_train.shape[1]\n",
    "    input_len = X_train.shape[2]\n",
    "    n_domains = len(unique_train_subj)\n",
    "\n",
    "    model = DANN_EEG(n_channels, input_len, n_domains).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_steps = num_epochs * len(train_loader)\n",
    "\n",
    "    def calc_lambda(p):\n",
    "        # p in [0,1], schedule از مقاله DANN\n",
    "        return 2.0 / (1.0 + np.exp(-10 * p)) - 1.0\n",
    "\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for xb, yb, db in train_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.float().to(DEVICE)\n",
    "            db = db.to(DEVICE)\n",
    "\n",
    "            p = step / total_steps\n",
    "            lambd = calc_lambda(p)\n",
    "\n",
    "            logits_label, logits_domain = model(xb, lambd=lambd)\n",
    "\n",
    "            loss_cls = bce(logits_label, yb)\n",
    "            loss_dom = ce(logits_domain, db)\n",
    "\n",
    "            loss = loss_cls + 0.1 * loss_dom  # وزن domain\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        # ساده: فقط یک پاس validation برای چاپ\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            all_logits = []\n",
    "            all_y = []\n",
    "            for xb, yb, db in val_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.float().to(DEVICE)\n",
    "                lg, _ = model(xb, lambd=0.0)\n",
    "                all_logits.append(lg.cpu())\n",
    "                all_y.append(yb.cpu())\n",
    "            if len(all_logits) > 0:\n",
    "                logits = torch.cat(all_logits)\n",
    "                ys = torch.cat(all_y)\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).long()\n",
    "                acc = (preds == ys.long()).float().mean().item()\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, val acc={acc:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_dann_loso(num_epochs=15):\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline()\n",
    "    seg_X, seg_y, seg_subjects = make_segments(X, y, subjects, sfreq)\n",
    "\n",
    "    unique_subjects = np.unique(seg_subjects)\n",
    "    subj_metrics = []\n",
    "\n",
    "    for test_subj in unique_subjects:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Test subject:\", test_subj)\n",
    "\n",
    "        test_mask = (seg_subjects == test_subj)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        X_train = seg_X[train_mask]\n",
    "        y_train = seg_y[train_mask]\n",
    "        subj_train = seg_subjects[train_mask]\n",
    "\n",
    "        X_test = seg_X[test_mask]\n",
    "        y_test = seg_y[test_mask]\n",
    "        subj_test = seg_subjects[test_mask]\n",
    "\n",
    "        # split train -> train/val (مثلاً 90/10)\n",
    "        n_train = X_train.shape[0]\n",
    "        idx = np.arange(n_train)\n",
    "        np.random.shuffle(idx)\n",
    "        split = int(0.9 * n_train)\n",
    "        tr_idx, val_idx = idx[:split], idx[split:]\n",
    "\n",
    "        X_tr, y_tr, subj_tr = X_train[tr_idx], y_train[tr_idx], subj_train[tr_idx]\n",
    "        X_val, y_val, subj_val = X_train[val_idx], y_train[val_idx], subj_train[val_idx]\n",
    "\n",
    "        model = train_dann_for_fold(X_tr, y_tr, subj_tr, X_val, y_val, subj_val,\n",
    "                                    num_epochs=num_epochs, batch_size=64)\n",
    "\n",
    "        # test\n",
    "        model.eval()\n",
    "        ds_test = EEGSegmentDataset(X_test, y_test,\n",
    "                                    np.zeros_like(y_test))  # domain ids irrelevant\n",
    "        dl_test = DataLoader(ds_test, batch_size=64, shuffle=False)\n",
    "\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb, db in dl_test:\n",
    "                xb = xb.to(DEVICE)\n",
    "                yb = yb.to(DEVICE)\n",
    "                logits, _ = model(xb, lambd=0.0)\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).long()\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_true.append(yb.cpu().numpy())\n",
    "\n",
    "        y_pred_seg = np.concatenate(all_preds)\n",
    "        y_true_seg = np.concatenate(all_true)\n",
    "\n",
    "        # majority vote subject-level\n",
    "        true_label = y_true_seg[0]\n",
    "        counts = np.bincount(y_pred_seg)\n",
    "        pred_label = np.argmax(counts)\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level -> true: {true_label}, pred: {pred_label}, acc: {acc_subj:.4f}\")\n",
    "        subj_metrics.append(acc_subj)\n",
    "\n",
    "    subj_metrics = np.array(subj_metrics)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Average SUBJECT-level (LOSO, DANN):\", subj_metrics.mean())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_dann_loso(num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a9ab845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:39:24.192446Z",
     "iopub.status.busy": "2025-12-12T09:39:24.192052Z",
     "iopub.status.idle": "2025-12-12T09:40:32.969484Z",
     "shell.execute_reply": "2025-12-12T09:40:32.968712Z"
    },
    "papermill": {
     "duration": 68.823748,
     "end_time": "2025-12-12T09:40:32.970616",
     "exception": false,
     "start_time": "2025-12-12T09:39:24.146868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading Subject00_1.edf (rest) and Subject00_2.edf (task)...\n",
      "Loading Subject01_1.edf (rest) and Subject01_2.edf (task)...\n",
      "Loading Subject02_1.edf (rest) and Subject02_2.edf (task)...\n",
      "Loading Subject03_1.edf (rest) and Subject03_2.edf (task)...\n",
      "Loading Subject04_1.edf (rest) and Subject04_2.edf (task)...\n",
      "Loading Subject05_1.edf (rest) and Subject05_2.edf (task)...\n",
      "Loading Subject06_1.edf (rest) and Subject06_2.edf (task)...\n",
      "Loading Subject07_1.edf (rest) and Subject07_2.edf (task)...\n",
      "Loading Subject08_1.edf (rest) and Subject08_2.edf (task)...\n",
      "Loading Subject09_1.edf (rest) and Subject09_2.edf (task)...\n",
      "Loading Subject10_1.edf (rest) and Subject10_2.edf (task)...\n",
      "Loading Subject11_1.edf (rest) and Subject11_2.edf (task)...\n",
      "Loading Subject12_1.edf (rest) and Subject12_2.edf (task)...\n",
      "Loading Subject13_1.edf (rest) and Subject13_2.edf (task)...\n",
      "Loading Subject14_1.edf (rest) and Subject14_2.edf (task)...\n",
      "Loading Subject15_1.edf (rest) and Subject15_2.edf (task)...\n",
      "Loading Subject16_1.edf (rest) and Subject16_2.edf (task)...\n",
      "Loading Subject17_1.edf (rest) and Subject17_2.edf (task)...\n",
      "Loading Subject18_1.edf (rest) and Subject18_2.edf (task)...\n",
      "Loading Subject19_1.edf (rest) and Subject19_2.edf (task)...\n",
      "Loading Subject20_1.edf (rest) and Subject20_2.edf (task)...\n",
      "Loading Subject21_1.edf (rest) and Subject21_2.edf (task)...\n",
      "Loading Subject22_1.edf (rest) and Subject22_2.edf (task)...\n",
      "Loading Subject23_1.edf (rest) and Subject23_2.edf (task)...\n",
      "Loading Subject24_1.edf (rest) and Subject24_2.edf (task)...\n",
      "Loading Subject25_1.edf (rest) and Subject25_2.edf (task)...\n",
      "Loading Subject26_1.edf (rest) and Subject26_2.edf (task)...\n",
      "Loading Subject27_1.edf (rest) and Subject27_2.edf (task)...\n",
      "Loading Subject28_1.edf (rest) and Subject28_2.edf (task)...\n",
      "Loading Subject29_1.edf (rest) and Subject29_2.edf (task)...\n",
      "Loading Subject30_1.edf (rest) and Subject30_2.edf (task)...\n",
      "Loading Subject31_1.edf (rest) and Subject31_2.edf (task)...\n",
      "Loading Subject32_1.edf (rest) and Subject32_2.edf (task)...\n",
      "Loading Subject33_1.edf (rest) and Subject33_2.edf (task)...\n",
      "Loading Subject34_1.edf (rest) and Subject34_2.edf (task)...\n",
      "Loading Subject35_1.edf (rest) and Subject35_2.edf (task)...\n",
      "Final tensor X shape (N, C, T): (36, 21, 7936)\n",
      "Labels y shape: (36,)\n",
      "Segmented data shape: (4356, 21, 256)\n",
      "Pretraining SimCLR-style SSL on all segments...\n",
      "[SSL] Epoch 1/20, loss=5.5421\n",
      "[SSL] Epoch 2/20, loss=5.5415\n",
      "[SSL] Epoch 3/20, loss=5.5416\n",
      "[SSL] Epoch 4/20, loss=5.5412\n",
      "[SSL] Epoch 5/20, loss=5.5413\n",
      "[SSL] Epoch 6/20, loss=5.5413\n",
      "[SSL] Epoch 7/20, loss=5.5410\n",
      "[SSL] Epoch 8/20, loss=5.5416\n",
      "[SSL] Epoch 9/20, loss=5.5414\n",
      "[SSL] Epoch 10/20, loss=5.5412\n",
      "[SSL] Epoch 11/20, loss=5.5416\n",
      "[SSL] Epoch 12/20, loss=5.5411\n",
      "[SSL] Epoch 13/20, loss=5.5413\n",
      "[SSL] Epoch 14/20, loss=5.5412\n",
      "[SSL] Epoch 15/20, loss=5.5414\n",
      "[SSL] Epoch 16/20, loss=5.5413\n",
      "[SSL] Epoch 17/20, loss=5.5413\n",
      "[SSL] Epoch 18/20, loss=5.5413\n",
      "[SSL] Epoch 19/20, loss=5.5415\n",
      "[SSL] Epoch 20/20, loss=5.5412\n",
      "Evaluating LOSO using frozen encoder + SVM...\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject00\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject01\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject02\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject03\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject04\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject05\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject06\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject07\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject08\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject09\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject10\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject11\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject12\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject13\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject14\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject15\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject16\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject17\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject18\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject19\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject20\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject21\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject22\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject23\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject24\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject25\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject26\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject27\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject28\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject29\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject30\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject31\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject32\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject33\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject34\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "==================================================\n",
      "Test subject: Subject35\n",
      "Train segments: 4235 | Test segments: 121\n",
      "Subject-level -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "==================================================\n",
      "Average SUBJECT-level (LOSO, SSL+SVM): 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "#   SimCLR-style SSL + LOSO + SVM\n",
    "#       روی EEGMAT - GPU if avail\n",
    "# ================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --------------------------------\n",
    "# تنظیمات دیتاست\n",
    "# --------------------------------\n",
    "DATA_FOLDER = \"/kaggle/input/ahmadi-dataset\"   # اگر مسیرت فرق دارد، این را عوض کن\n",
    "INFO_CSV = f\"{DATA_FOLDER}/subject-info.csv\"\n",
    "\n",
    "RESAMPLE_TO = 128\n",
    "WINDOW_SEC = 2.0\n",
    "OVERLAP_RATIO = 0.75  # 75% overlap\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# --------------------------------\n",
    "# ۱) لود دیتاست + baseline از rest\n",
    "# --------------------------------\n",
    "def load_task_edf_with_baseline(folder_path=DATA_FOLDER,\n",
    "                                info_csv_path=INFO_CSV,\n",
    "                                resample_to=RESAMPLE_TO,\n",
    "                                use_baseline=True):\n",
    "    folder = Path(folder_path)\n",
    "    info_df = pd.read_csv(info_csv_path)\n",
    "    label_map = dict(zip(info_df[\"Subject\"], info_df[\"Count quality\"]))\n",
    "\n",
    "    X_list, y_list, subjects = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for subj_name in info_df[\"Subject\"]:\n",
    "        task_file = folder / f\"{subj_name}_2.edf\"\n",
    "        rest_file = folder / f\"{subj_name}_1.edf\"\n",
    "\n",
    "        if not task_file.is_file():\n",
    "            print(f\"Task file not found for {subj_name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if subj_name not in label_map:\n",
    "            print(f\"{subj_name} not in subject-info, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Loading {subj_name}_1.edf (rest) and {subj_name}_2.edf (task)...\")\n",
    "        raw_task = mne.io.read_raw_edf(task_file, preload=True, verbose=False)\n",
    "\n",
    "        raw_rest = None\n",
    "        if use_baseline and rest_file.is_file():\n",
    "            raw_rest = mne.io.read_raw_edf(rest_file, preload=True, verbose=False)\n",
    "\n",
    "        # resample\n",
    "        if resample_to is not None:\n",
    "            raw_task.resample(resample_to)\n",
    "            if raw_rest is not None:\n",
    "                raw_rest.resample(resample_to)\n",
    "\n",
    "        if sfreq is None:\n",
    "            sfreq = raw_task.info[\"sfreq\"]\n",
    "\n",
    "        task_data = raw_task.get_data()  # (C, T)\n",
    "\n",
    "        if use_baseline and raw_rest is not None:\n",
    "            rest_data = raw_rest.get_data()\n",
    "            baseline = rest_data.mean(axis=1, keepdims=True)\n",
    "            task_data = task_data - baseline\n",
    "\n",
    "        X_list.append(task_data)\n",
    "        y_list.append(int(label_map[subj_name]))\n",
    "        subjects.append(subj_name)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No task files loaded.\")\n",
    "\n",
    "    lengths = [d.shape[1] for d in X_list]\n",
    "    min_len = min(lengths)\n",
    "    X = np.stack([d[:, :min_len] for d in X_list], axis=0)  # (N, C, T)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    subjects = np.array(subjects)\n",
    "\n",
    "    print(\"Final tensor X shape (N, C, T):\", X.shape)\n",
    "    print(\"Labels y shape:\", y.shape)\n",
    "\n",
    "    return X, y, subjects, sfreq\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# ۲) سگمنت‌کردن سیگنال‌ها\n",
    "# --------------------------------\n",
    "def make_segments(X, y, subjects, sfreq,\n",
    "                  window_sec=WINDOW_SEC,\n",
    "                  overlap_ratio=OVERLAP_RATIO):\n",
    "    N, C, T = X.shape\n",
    "    win_size = int(window_sec * sfreq)\n",
    "    step_sec = window_sec * (1.0 - overlap_ratio)\n",
    "    step = max(1, int(step_sec * sfreq))\n",
    "\n",
    "    seg_X_list, seg_y_list, seg_subj_list = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        data = X[i]\n",
    "        subj_label = y[i]\n",
    "        subj_id = subjects[i]\n",
    "\n",
    "        start = 0\n",
    "        while start + win_size <= T:\n",
    "            seg = data[:, start:start+win_size]\n",
    "            seg_X_list.append(seg)\n",
    "            seg_y_list.append(subj_label)\n",
    "            seg_subj_list.append(subj_id)\n",
    "            start += step\n",
    "\n",
    "    seg_X = np.stack(seg_X_list, axis=0)\n",
    "    seg_y = np.array(seg_y_list, dtype=int)\n",
    "    seg_subjects = np.array(seg_subj_list)\n",
    "\n",
    "    print(\"Segmented data shape:\", seg_X.shape)\n",
    "    return seg_X, seg_y, seg_subjects\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# ۳) بخش PyTorch (SSL + Encoder)\n",
    "# --------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# cuDNN را فعال می‌گذاریم (برای سرعت)، فقط TF32 را خاموش می‌کنیم برای پایداری\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# --------- Augmentations برای EEG (ملایم) ---------\n",
    "class EEGAugment:\n",
    "    def __init__(self, jitter_std=0.005, time_shift=0.05, dropout_p=0.05):\n",
    "        self.jitter_std = jitter_std\n",
    "        self.time_shift = time_shift\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # x: (C, T) tensor\n",
    "        x = self.jitter(x)\n",
    "        x = self.time_shift_aug(x)\n",
    "        x = self.channel_dropout(x)\n",
    "        return x\n",
    "\n",
    "    def jitter(self, x):\n",
    "        noise = torch.randn_like(x) * self.jitter_std\n",
    "        return x + noise\n",
    "\n",
    "    def time_shift_aug(self, x):\n",
    "        T = x.shape[1]\n",
    "        if T <= 1:\n",
    "            return x\n",
    "        shift = int(self.time_shift * T)\n",
    "        if shift == 0:\n",
    "            return x\n",
    "        k = np.random.randint(-shift, shift + 1)\n",
    "        return torch.roll(x, shifts=k, dims=1)\n",
    "\n",
    "    def channel_dropout(self, x):\n",
    "        # dropout روی کانال‌ها\n",
    "        mask = (torch.rand(x.shape[0], 1, device=x.device) > self.dropout_p).float()\n",
    "        return x * mask\n",
    "\n",
    "\n",
    "# --------- Dataset برای SSL ---------\n",
    "class EEGSSL_Dataset(Dataset):\n",
    "    def __init__(self, X, augment):\n",
    "        # X: (N, C, T)\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]  # (C, T)\n",
    "        v1 = self.augment(x)\n",
    "        v2 = self.augment(x)\n",
    "        return v1, v2\n",
    "\n",
    "\n",
    "# --------- Encoder CNN ---------\n",
    "class EEGEncoder(nn.Module):\n",
    "    def __init__(self, n_channels, input_len, feat_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(128, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        h = self.conv(x).squeeze(-1)  # (B, 128)\n",
    "        z = self.fc(h)                # (B, feat_dim)\n",
    "        return F.normalize(z, dim=1)  # نرمال‌سازی روی بردار embedding\n",
    "\n",
    "\n",
    "# --------- NT-Xent (SimCLR استاندارد) ---------\n",
    "def nt_xent_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"\n",
    "    z1, z2: (B, D), normalized embeddings\n",
    "    SimCLR NT-Xent: هر نمونه در view1 پارتنرش در view2 است و برعکس.\n",
    "    \"\"\"\n",
    "    B = z1.size(0)\n",
    "\n",
    "    # ۲B تا embedding پشت سر هم\n",
    "    z = torch.cat([z1, z2], dim=0)         # (2B, D)\n",
    "\n",
    "    # cosine similarity بین همه‌ی جفت‌ها: (2B, 2B)\n",
    "    sim = F.cosine_similarity(\n",
    "        z.unsqueeze(1),  # (2B, 1, D)\n",
    "        z.unsqueeze(0),  # (1, 2B, D)\n",
    "        dim=2\n",
    "    )  # -> (2B, 2B)\n",
    "\n",
    "    # positive index:\n",
    "    # view1[i] ↔ view2[i]  → برای i در [0..B-1]\n",
    "    labels = torch.arange(B, device=z.device)\n",
    "    labels = torch.cat([labels + B, labels], dim=0)   # (2B,)\n",
    "\n",
    "    # self-sim رو حذف می‌کنیم (قطر)\n",
    "    mask = torch.eye(2 * B, dtype=torch.bool, device=z.device)\n",
    "    sim = sim.masked_fill(mask, -1e9)\n",
    "\n",
    "    # scale by temperature و cross-entropy\n",
    "    sim = sim / temperature\n",
    "    loss = F.cross_entropy(sim, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --------- Pretraining SimCLR ---------\n",
    "def pretrain_simclr(seg_X, num_epochs=20, batch_size=128, feat_dim=128):\n",
    "    augment = EEGAugment()\n",
    "    ds_ssl = EEGSSL_Dataset(seg_X, augment)\n",
    "    dl_ssl = DataLoader(ds_ssl, batch_size=batch_size,\n",
    "                        shuffle=True, drop_last=True)\n",
    "\n",
    "    n_channels = seg_X.shape[1]\n",
    "    input_len = seg_X.shape[2]\n",
    "    encoder = EEGEncoder(n_channels, input_len,\n",
    "                         feat_dim=feat_dim).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(encoder.parameters(),\n",
    "                                 lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        encoder.train()\n",
    "        total_loss = 0.0\n",
    "        for v1, v2 in dl_ssl:\n",
    "            v1 = v1.to(DEVICE)\n",
    "            v2 = v2.to(DEVICE)\n",
    "\n",
    "            z1 = encoder(v1)\n",
    "            z2 = encoder(v2)\n",
    "\n",
    "            loss = nt_xent_loss(z1, z2, temperature=0.1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dl_ssl)\n",
    "        print(f\"[SSL] Epoch {epoch+1}/{num_epochs}, loss={avg_loss:.4f}\")\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "# --------- استخراج embedding ---------\n",
    "def extract_embeddings(encoder, seg_X, batch_size=256):\n",
    "    encoder.eval()\n",
    "    ds = torch.from_numpy(seg_X).float()\n",
    "    all_emb = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, ds.shape[0], batch_size):\n",
    "            xb = ds[i:i+batch_size].to(DEVICE)\n",
    "            z = encoder(xb)\n",
    "            all_emb.append(z.cpu().numpy())\n",
    "    return np.concatenate(all_emb, axis=0)\n",
    "\n",
    "\n",
    "# --------- LOSO Evaluation با SVM + StandardScaler ---------\n",
    "def evaluate_ssl_loso(encoder, seg_X, seg_y, seg_subjects):\n",
    "    feats_all = extract_embeddings(encoder, seg_X)\n",
    "    unique_subjects = np.unique(seg_subjects)\n",
    "    subj_accs = []\n",
    "\n",
    "    for test_subj in unique_subjects:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"Test subject:\", test_subj)\n",
    "\n",
    "        test_mask = (seg_subjects == test_subj)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        X_train = feats_all[train_mask]\n",
    "        y_train = seg_y[train_mask]\n",
    "        X_test = feats_all[test_mask]\n",
    "        y_test = seg_y[test_mask]\n",
    "\n",
    "        print(\"Train segments:\", X_train.shape[0],\n",
    "              \"| Test segments:\", X_test.shape[0])\n",
    "\n",
    "        clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            SVC(kernel=\"rbf\", class_weight=\"balanced\",\n",
    "                random_state=RANDOM_STATE)\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_seg = clf.predict(X_test)\n",
    "\n",
    "        # subject-level majority vote\n",
    "        true_label = y_test[0]\n",
    "        counts = np.bincount(y_pred_seg)\n",
    "        pred_label = np.argmax(counts)\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level -> true: {true_label}, \"\n",
    "              f\"pred: {pred_label}, acc: {acc_subj:.4f}\")\n",
    "        subj_accs.append(acc_subj)\n",
    "\n",
    "    subj_accs = np.array(subj_accs)\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Average SUBJECT-level (LOSO, SSL+SVM):\",\n",
    "          subj_accs.mean())\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# main\n",
    "# --------------------------------\n",
    "def main():\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline()\n",
    "    seg_X, seg_y, seg_subjects = make_segments(X, y, subjects, sfreq)\n",
    "\n",
    "    print(\"Pretraining SimCLR-style SSL on all segments...\")\n",
    "    encoder = pretrain_simclr(seg_X,\n",
    "                              num_epochs=20,   # برای تست سریع می‌تونی 10 بذاری\n",
    "                              batch_size=128,\n",
    "                              feat_dim=128)\n",
    "\n",
    "    print(\"Evaluating LOSO using frozen encoder + SVM...\")\n",
    "    evaluate_ssl_loso(encoder, seg_X, seg_y, seg_subjects)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa215d",
   "metadata": {
    "papermill": {
     "duration": 0.048831,
     "end_time": "2025-12-12T09:40:33.068627",
     "exception": false,
     "start_time": "2025-12-12T09:40:33.019796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "thst\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96fdc120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:40:33.166319Z",
     "iopub.status.busy": "2025-12-12T09:40:33.166076Z",
     "iopub.status.idle": "2025-12-12T09:52:50.346453Z",
     "shell.execute_reply": "2025-12-12T09:52:50.345612Z"
    },
    "papermill": {
     "duration": 737.230877,
     "end_time": "2025-12-12T09:52:50.347649",
     "exception": false,
     "start_time": "2025-12-12T09:40:33.116772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA version: 12.4\n",
      "GPU name: Tesla P100-PCIE-16GB\n",
      "Loading Subject00_1.edf (rest) and Subject00_2.edf (task)...\n",
      "Loading Subject01_1.edf (rest) and Subject01_2.edf (task)...\n",
      "Loading Subject02_1.edf (rest) and Subject02_2.edf (task)...\n",
      "Loading Subject03_1.edf (rest) and Subject03_2.edf (task)...\n",
      "Loading Subject04_1.edf (rest) and Subject04_2.edf (task)...\n",
      "Loading Subject05_1.edf (rest) and Subject05_2.edf (task)...\n",
      "Loading Subject06_1.edf (rest) and Subject06_2.edf (task)...\n",
      "Loading Subject07_1.edf (rest) and Subject07_2.edf (task)...\n",
      "Loading Subject08_1.edf (rest) and Subject08_2.edf (task)...\n",
      "Loading Subject09_1.edf (rest) and Subject09_2.edf (task)...\n",
      "Loading Subject10_1.edf (rest) and Subject10_2.edf (task)...\n",
      "Loading Subject11_1.edf (rest) and Subject11_2.edf (task)...\n",
      "Loading Subject12_1.edf (rest) and Subject12_2.edf (task)...\n",
      "Loading Subject13_1.edf (rest) and Subject13_2.edf (task)...\n",
      "Loading Subject14_1.edf (rest) and Subject14_2.edf (task)...\n",
      "Loading Subject15_1.edf (rest) and Subject15_2.edf (task)...\n",
      "Loading Subject16_1.edf (rest) and Subject16_2.edf (task)...\n",
      "Loading Subject17_1.edf (rest) and Subject17_2.edf (task)...\n",
      "Loading Subject18_1.edf (rest) and Subject18_2.edf (task)...\n",
      "Loading Subject19_1.edf (rest) and Subject19_2.edf (task)...\n",
      "Loading Subject20_1.edf (rest) and Subject20_2.edf (task)...\n",
      "Loading Subject21_1.edf (rest) and Subject21_2.edf (task)...\n",
      "Loading Subject22_1.edf (rest) and Subject22_2.edf (task)...\n",
      "Loading Subject23_1.edf (rest) and Subject23_2.edf (task)...\n",
      "Loading Subject24_1.edf (rest) and Subject24_2.edf (task)...\n",
      "Loading Subject25_1.edf (rest) and Subject25_2.edf (task)...\n",
      "Loading Subject26_1.edf (rest) and Subject26_2.edf (task)...\n",
      "Loading Subject27_1.edf (rest) and Subject27_2.edf (task)...\n",
      "Loading Subject28_1.edf (rest) and Subject28_2.edf (task)...\n",
      "Loading Subject29_1.edf (rest) and Subject29_2.edf (task)...\n",
      "Loading Subject30_1.edf (rest) and Subject30_2.edf (task)...\n",
      "Loading Subject31_1.edf (rest) and Subject31_2.edf (task)...\n",
      "Loading Subject32_1.edf (rest) and Subject32_2.edf (task)...\n",
      "Loading Subject33_1.edf (rest) and Subject33_2.edf (task)...\n",
      "Loading Subject34_1.edf (rest) and Subject34_2.edf (task)...\n",
      "Loading Subject35_1.edf (rest) and Subject35_2.edf (task)...\n",
      "Final tensor X shape (N, C, T): (36, 21, 7936)\n",
      "Labels y shape: (36,)\n",
      "Segmented data shape: (4356, 21, 256)\n",
      "Segmented data shape: (4356, 21, 256)\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject00\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 726 2662] -> weights: [2.3333333 0.6363636]\n",
      "Epoch 1/10 | train_loss=0.4587 | val_acc=0.3022, val_f1=0.4084\n",
      "Epoch 2/10 | train_loss=0.1083 | val_acc=0.3424, val_f1=0.4093\n",
      "Epoch 3/10 | train_loss=0.0380 | val_acc=0.4416, val_f1=0.3865\n",
      "Epoch 4/10 | train_loss=0.0480 | val_acc=0.3837, val_f1=0.4717\n",
      "Epoch 5/10 | train_loss=0.0430 | val_acc=0.3223, val_f1=0.4753\n",
      "Epoch 6/10 | train_loss=0.0299 | val_acc=0.4120, val_f1=0.5780\n",
      "Epoch 7/10 | train_loss=0.0215 | val_acc=0.4959, val_f1=0.3421\n",
      "Epoch 8/10 | train_loss=0.0197 | val_acc=0.3813, val_f1=0.4903\n",
      "Epoch 9/10 | train_loss=0.0076 | val_acc=0.4144, val_f1=0.4678\n",
      "Epoch 10/10 | train_loss=0.0052 | val_acc=0.3554, val_f1=0.4780\n",
      "Segment-level metrics -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject01\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5551 | val_acc=0.6257, val_f1=0.7661\n",
      "Epoch 2/10 | train_loss=0.1458 | val_acc=0.3140, val_f1=0.3636\n",
      "Epoch 3/10 | train_loss=0.0638 | val_acc=0.3825, val_f1=0.5144\n",
      "Epoch 4/10 | train_loss=0.0598 | val_acc=0.6057, val_f1=0.7485\n",
      "Epoch 5/10 | train_loss=0.0208 | val_acc=0.6234, val_f1=0.7610\n",
      "Epoch 6/10 | train_loss=0.0218 | val_acc=0.6777, val_f1=0.8079\n",
      "Epoch 7/10 | train_loss=0.0291 | val_acc=0.5832, val_f1=0.7324\n",
      "Epoch 8/10 | train_loss=0.0344 | val_acc=0.5525, val_f1=0.7041\n",
      "Epoch 9/10 | train_loss=0.0139 | val_acc=0.6659, val_f1=0.7989\n",
      "Epoch 10/10 | train_loss=0.0059 | val_acc=0.6765, val_f1=0.8057\n",
      "Segment-level metrics -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject02\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5686 | val_acc=0.5478, val_f1=0.6943\n",
      "Epoch 2/10 | train_loss=0.1659 | val_acc=0.5738, val_f1=0.7246\n",
      "Epoch 3/10 | train_loss=0.0812 | val_acc=0.5643, val_f1=0.7211\n",
      "Epoch 4/10 | train_loss=0.0380 | val_acc=0.5065, val_f1=0.4367\n",
      "Epoch 5/10 | train_loss=0.0412 | val_acc=0.5608, val_f1=0.7182\n",
      "Epoch 6/10 | train_loss=0.0400 | val_acc=0.6198, val_f1=0.6477\n",
      "Epoch 7/10 | train_loss=0.0258 | val_acc=0.4557, val_f1=0.5494\n",
      "Epoch 8/10 | train_loss=0.0105 | val_acc=0.5726, val_f1=0.7278\n",
      "Epoch 9/10 | train_loss=0.0153 | val_acc=0.5620, val_f1=0.7192\n",
      "Epoch 10/10 | train_loss=0.0133 | val_acc=0.5643, val_f1=0.7211\n",
      "Segment-level metrics -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject03\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5353 | val_acc=0.5643, val_f1=0.7207\n",
      "Epoch 2/10 | train_loss=0.1186 | val_acc=0.5195, val_f1=0.6548\n",
      "Epoch 3/10 | train_loss=0.0813 | val_acc=0.5443, val_f1=0.6907\n",
      "Epoch 4/10 | train_loss=0.0386 | val_acc=0.5348, val_f1=0.6843\n",
      "Epoch 5/10 | train_loss=0.0237 | val_acc=0.3766, val_f1=0.3282\n",
      "Epoch 6/10 | train_loss=0.0340 | val_acc=0.5679, val_f1=0.7244\n",
      "Epoch 7/10 | train_loss=0.0272 | val_acc=0.4970, val_f1=0.6011\n",
      "Epoch 8/10 | train_loss=0.0220 | val_acc=0.5124, val_f1=0.6590\n",
      "Epoch 9/10 | train_loss=0.0086 | val_acc=0.4911, val_f1=0.6399\n",
      "Epoch 10/10 | train_loss=0.0110 | val_acc=0.5348, val_f1=0.6068\n",
      "Segment-level metrics -> acc: 0.9339, prec: 1.0000, rec: 0.9339, f1: 0.9658\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject04\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5279 | val_acc=0.8005, val_f1=0.8890\n",
      "Epoch 2/10 | train_loss=0.1662 | val_acc=0.4569, val_f1=0.5446\n",
      "Epoch 3/10 | train_loss=0.0766 | val_acc=0.7119, val_f1=0.8274\n",
      "Epoch 4/10 | train_loss=0.0269 | val_acc=0.7780, val_f1=0.8742\n",
      "Epoch 5/10 | train_loss=0.0278 | val_acc=0.6671, val_f1=0.7962\n",
      "Epoch 6/10 | train_loss=0.0449 | val_acc=0.8040, val_f1=0.8912\n",
      "Epoch 7/10 | train_loss=0.0418 | val_acc=0.6706, val_f1=0.7869\n",
      "Epoch 8/10 | train_loss=0.0320 | val_acc=0.5053, val_f1=0.6058\n",
      "Epoch 9/10 | train_loss=0.0320 | val_acc=0.7450, val_f1=0.8502\n",
      "Epoch 10/10 | train_loss=0.0283 | val_acc=0.5514, val_f1=0.6527\n",
      "Segment-level metrics -> acc: 0.2975, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject05\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1089 2299] -> weights: [1.5555556 0.7368421]\n",
      "Epoch 1/10 | train_loss=0.5588 | val_acc=0.5762, val_f1=0.7050\n",
      "Epoch 2/10 | train_loss=0.1900 | val_acc=0.7497, val_f1=0.8564\n",
      "Epoch 3/10 | train_loss=0.0905 | val_acc=0.4321, val_f1=0.5326\n",
      "Epoch 4/10 | train_loss=0.0338 | val_acc=0.3813, val_f1=0.4530\n",
      "Epoch 5/10 | train_loss=0.0254 | val_acc=0.5348, val_f1=0.6418\n",
      "Epoch 6/10 | train_loss=0.0194 | val_acc=0.3825, val_f1=0.4558\n",
      "Epoch 7/10 | train_loss=0.0283 | val_acc=0.8158, val_f1=0.8983\n",
      "Epoch 8/10 | train_loss=0.0257 | val_acc=0.6730, val_f1=0.7900\n",
      "Epoch 9/10 | train_loss=0.0216 | val_acc=0.5325, val_f1=0.6360\n",
      "Epoch 10/10 | train_loss=0.0206 | val_acc=0.7355, val_f1=0.8328\n",
      "Segment-level metrics -> acc: 0.9091, prec: 1.0000, rec: 0.9091, f1: 0.9524\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject06\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5056 | val_acc=0.6671, val_f1=0.7989\n",
      "Epoch 2/10 | train_loss=0.1526 | val_acc=0.6860, val_f1=0.8124\n",
      "Epoch 3/10 | train_loss=0.0502 | val_acc=0.7048, val_f1=0.8254\n",
      "Epoch 4/10 | train_loss=0.0599 | val_acc=0.5679, val_f1=0.7202\n",
      "Epoch 5/10 | train_loss=0.0453 | val_acc=0.5691, val_f1=0.7212\n",
      "Epoch 6/10 | train_loss=0.0423 | val_acc=0.4817, val_f1=0.6034\n",
      "Epoch 7/10 | train_loss=0.0194 | val_acc=0.5915, val_f1=0.7347\n",
      "Epoch 8/10 | train_loss=0.0202 | val_acc=0.5927, val_f1=0.7416\n",
      "Epoch 9/10 | train_loss=0.0159 | val_acc=0.6340, val_f1=0.7724\n",
      "Epoch 10/10 | train_loss=0.0174 | val_acc=0.6978, val_f1=0.8220\n",
      "Segment-level metrics -> acc: 0.0083, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject07\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.4996 | val_acc=0.4168, val_f1=0.3601\n",
      "Epoch 2/10 | train_loss=0.1379 | val_acc=0.5277, val_f1=0.6063\n",
      "Epoch 3/10 | train_loss=0.0743 | val_acc=0.4664, val_f1=0.5378\n",
      "Epoch 4/10 | train_loss=0.0434 | val_acc=0.4864, val_f1=0.6140\n",
      "Epoch 5/10 | train_loss=0.0306 | val_acc=0.4876, val_f1=0.5843\n",
      "Epoch 6/10 | train_loss=0.0407 | val_acc=0.5100, val_f1=0.5135\n",
      "Epoch 7/10 | train_loss=0.0260 | val_acc=0.4345, val_f1=0.6038\n",
      "Epoch 8/10 | train_loss=0.0155 | val_acc=0.4687, val_f1=0.6094\n",
      "Epoch 9/10 | train_loss=0.0394 | val_acc=0.5100, val_f1=0.6750\n",
      "Epoch 10/10 | train_loss=0.0442 | val_acc=0.4888, val_f1=0.5965\n",
      "Segment-level metrics -> acc: 0.5785, prec: 1.0000, rec: 0.5785, f1: 0.7330\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject08\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5813 | val_acc=0.6470, val_f1=0.7793\n",
      "Epoch 2/10 | train_loss=0.2128 | val_acc=0.7155, val_f1=0.8240\n",
      "Epoch 3/10 | train_loss=0.0670 | val_acc=0.7048, val_f1=0.7668\n",
      "Epoch 4/10 | train_loss=0.0804 | val_acc=0.6635, val_f1=0.7558\n",
      "Epoch 5/10 | train_loss=0.0492 | val_acc=0.7178, val_f1=0.8239\n",
      "Epoch 6/10 | train_loss=0.0302 | val_acc=0.7178, val_f1=0.7956\n",
      "Epoch 7/10 | train_loss=0.0231 | val_acc=0.7166, val_f1=0.7581\n",
      "Epoch 8/10 | train_loss=0.0416 | val_acc=0.6659, val_f1=0.7425\n",
      "Epoch 9/10 | train_loss=0.0293 | val_acc=0.7403, val_f1=0.7928\n",
      "Epoch 10/10 | train_loss=0.0084 | val_acc=0.7226, val_f1=0.7694\n",
      "Segment-level metrics -> acc: 0.8017, prec: 1.0000, rec: 0.8017, f1: 0.8899\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject09\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1089 2299] -> weights: [1.5555556 0.7368421]\n",
      "Epoch 1/10 | train_loss=0.5208 | val_acc=0.4144, val_f1=0.5860\n",
      "Epoch 2/10 | train_loss=0.1664 | val_acc=0.9894, val_f1=0.9947\n",
      "Epoch 3/10 | train_loss=0.0626 | val_acc=0.9044, val_f1=0.9498\n",
      "Epoch 4/10 | train_loss=0.0394 | val_acc=0.9587, val_f1=0.9789\n",
      "Epoch 5/10 | train_loss=0.0384 | val_acc=0.9823, val_f1=0.9911\n",
      "Epoch 6/10 | train_loss=0.0367 | val_acc=0.4604, val_f1=0.6306\n",
      "Epoch 7/10 | train_loss=0.0301 | val_acc=0.6517, val_f1=0.7891\n",
      "Epoch 8/10 | train_loss=0.0505 | val_acc=0.7214, val_f1=0.8381\n",
      "Epoch 9/10 | train_loss=0.0315 | val_acc=0.8524, val_f1=0.9203\n",
      "Epoch 10/10 | train_loss=0.0186 | val_acc=0.6092, val_f1=0.7572\n",
      "Segment-level metrics -> acc: 0.0248, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject10\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5454 | val_acc=0.6753, val_f1=0.8043\n",
      "Epoch 2/10 | train_loss=0.1749 | val_acc=0.5183, val_f1=0.5426\n",
      "Epoch 3/10 | train_loss=0.0903 | val_acc=0.6682, val_f1=0.7524\n",
      "Epoch 4/10 | train_loss=0.0573 | val_acc=0.5691, val_f1=0.6761\n",
      "Epoch 5/10 | train_loss=0.0413 | val_acc=0.6210, val_f1=0.6819\n",
      "Epoch 6/10 | train_loss=0.0298 | val_acc=0.6234, val_f1=0.7552\n",
      "Epoch 7/10 | train_loss=0.0254 | val_acc=0.6505, val_f1=0.7877\n",
      "Epoch 8/10 | train_loss=0.0344 | val_acc=0.7025, val_f1=0.8248\n",
      "Epoch 9/10 | train_loss=0.0129 | val_acc=0.7072, val_f1=0.8280\n",
      "Epoch 10/10 | train_loss=0.0255 | val_acc=0.7107, val_f1=0.8176\n",
      "Segment-level metrics -> acc: 0.0000, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject11\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1210 2178] -> weights: [1.4       0.7777778]\n",
      "Epoch 1/10 | train_loss=0.5592 | val_acc=0.7143, val_f1=0.8333\n",
      "Epoch 2/10 | train_loss=0.1454 | val_acc=0.7084, val_f1=0.8293\n",
      "Epoch 3/10 | train_loss=0.0853 | val_acc=0.6068, val_f1=0.7553\n",
      "Epoch 4/10 | train_loss=0.0400 | val_acc=0.3447, val_f1=0.5127\n",
      "Epoch 5/10 | train_loss=0.0738 | val_acc=0.4947, val_f1=0.6619\n",
      "Epoch 6/10 | train_loss=0.0484 | val_acc=0.7662, val_f1=0.8676\n",
      "Epoch 7/10 | train_loss=0.0152 | val_acc=0.6505, val_f1=0.7883\n",
      "Epoch 8/10 | train_loss=0.0123 | val_acc=0.4994, val_f1=0.6661\n",
      "Epoch 9/10 | train_loss=0.0217 | val_acc=0.5289, val_f1=0.6919\n",
      "Epoch 10/10 | train_loss=0.0357 | val_acc=0.7521, val_f1=0.8585\n",
      "Segment-level metrics -> acc: 0.6033, prec: 1.0000, rec: 0.6033, f1: 0.7526\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject12\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5443 | val_acc=0.7166, val_f1=0.8329\n",
      "Epoch 2/10 | train_loss=0.1416 | val_acc=0.6871, val_f1=0.8106\n",
      "Epoch 3/10 | train_loss=0.0572 | val_acc=0.5384, val_f1=0.5791\n",
      "Epoch 4/10 | train_loss=0.0486 | val_acc=0.4522, val_f1=0.6140\n",
      "Epoch 5/10 | train_loss=0.0268 | val_acc=0.7131, val_f1=0.8314\n",
      "Epoch 6/10 | train_loss=0.0285 | val_acc=0.4368, val_f1=0.5196\n",
      "Epoch 7/10 | train_loss=0.0307 | val_acc=0.7107, val_f1=0.8309\n",
      "Epoch 8/10 | train_loss=0.0261 | val_acc=0.5880, val_f1=0.7280\n",
      "Epoch 9/10 | train_loss=0.0129 | val_acc=0.6954, val_f1=0.8191\n",
      "Epoch 10/10 | train_loss=0.0404 | val_acc=0.6942, val_f1=0.7943\n",
      "Segment-level metrics -> acc: 0.3388, prec: 1.0000, rec: 0.3388, f1: 0.5062\n",
      "Subject-level prediction -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject13\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 726 2662] -> weights: [2.3333333 0.6363636]\n",
      "Epoch 1/10 | train_loss=0.5507 | val_acc=0.4392, val_f1=0.6018\n",
      "Epoch 2/10 | train_loss=0.1216 | val_acc=0.4522, val_f1=0.5923\n",
      "Epoch 3/10 | train_loss=0.1156 | val_acc=0.4876, val_f1=0.5068\n",
      "Epoch 4/10 | train_loss=0.0391 | val_acc=0.5053, val_f1=0.6152\n",
      "Epoch 5/10 | train_loss=0.0264 | val_acc=0.4238, val_f1=0.5836\n",
      "Epoch 6/10 | train_loss=0.0262 | val_acc=0.5348, val_f1=0.6392\n",
      "Epoch 7/10 | train_loss=0.0416 | val_acc=0.4970, val_f1=0.6011\n",
      "Epoch 8/10 | train_loss=0.0230 | val_acc=0.4286, val_f1=0.5784\n",
      "Epoch 9/10 | train_loss=0.0063 | val_acc=0.4758, val_f1=0.5779\n",
      "Epoch 10/10 | train_loss=0.0087 | val_acc=0.4274, val_f1=0.5982\n",
      "Segment-level metrics -> acc: 0.5785, prec: 1.0000, rec: 0.5785, f1: 0.7330\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject14\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5470 | val_acc=0.5974, val_f1=0.7151\n",
      "Epoch 2/10 | train_loss=0.1728 | val_acc=0.5089, val_f1=0.6383\n",
      "Epoch 3/10 | train_loss=0.0622 | val_acc=0.7745, val_f1=0.8700\n",
      "Epoch 4/10 | train_loss=0.0551 | val_acc=0.2609, val_f1=0.2421\n",
      "Epoch 5/10 | train_loss=0.0327 | val_acc=0.5702, val_f1=0.6962\n",
      "Epoch 6/10 | train_loss=0.0207 | val_acc=0.2751, val_f1=0.2725\n",
      "Epoch 7/10 | train_loss=0.0373 | val_acc=0.4557, val_f1=0.5422\n",
      "Epoch 8/10 | train_loss=0.0226 | val_acc=0.5809, val_f1=0.6861\n",
      "Epoch 9/10 | train_loss=0.0250 | val_acc=0.3719, val_f1=0.4217\n",
      "Epoch 10/10 | train_loss=0.0263 | val_acc=0.5089, val_f1=0.6031\n",
      "Segment-level metrics -> acc: 0.9008, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject15\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 726 2662] -> weights: [2.3333333 0.6363636]\n",
      "Epoch 1/10 | train_loss=0.5582 | val_acc=0.6198, val_f1=0.6477\n",
      "Epoch 2/10 | train_loss=0.1406 | val_acc=0.5384, val_f1=0.3362\n",
      "Epoch 3/10 | train_loss=0.0648 | val_acc=0.5549, val_f1=0.0258\n",
      "Epoch 4/10 | train_loss=0.0824 | val_acc=0.5868, val_f1=0.6673\n",
      "Epoch 5/10 | train_loss=0.0288 | val_acc=0.6375, val_f1=0.6475\n",
      "Epoch 6/10 | train_loss=0.0117 | val_acc=0.5490, val_f1=0.6450\n",
      "Epoch 7/10 | train_loss=0.0182 | val_acc=0.6470, val_f1=0.6519\n",
      "Epoch 8/10 | train_loss=0.0132 | val_acc=0.6128, val_f1=0.5591\n",
      "Epoch 9/10 | train_loss=0.0319 | val_acc=0.5254, val_f1=0.2583\n",
      "Epoch 10/10 | train_loss=0.0262 | val_acc=0.5124, val_f1=0.6303\n",
      "Segment-level metrics -> acc: 0.8017, prec: 1.0000, rec: 0.8017, f1: 0.8899\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject16\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1089 2299] -> weights: [1.5555556 0.7368421]\n",
      "Epoch 1/10 | train_loss=0.5232 | val_acc=0.7839, val_f1=0.8789\n",
      "Epoch 2/10 | train_loss=0.1530 | val_acc=0.6234, val_f1=0.7677\n",
      "Epoch 3/10 | train_loss=0.0759 | val_acc=0.8453, val_f1=0.9162\n",
      "Epoch 4/10 | train_loss=0.0685 | val_acc=0.4522, val_f1=0.6228\n",
      "Epoch 5/10 | train_loss=0.0245 | val_acc=0.6375, val_f1=0.7783\n",
      "Epoch 6/10 | train_loss=0.0266 | val_acc=0.1736, val_f1=0.2901\n",
      "Epoch 7/10 | train_loss=0.0921 | val_acc=0.6340, val_f1=0.7757\n",
      "Epoch 8/10 | train_loss=0.0167 | val_acc=0.5254, val_f1=0.6879\n",
      "Epoch 9/10 | train_loss=0.0175 | val_acc=0.7296, val_f1=0.8437\n",
      "Epoch 10/10 | train_loss=0.0162 | val_acc=0.6021, val_f1=0.7517\n",
      "Segment-level metrics -> acc: 0.9752, prec: 1.0000, rec: 0.9752, f1: 0.9874\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject17\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1089 2299] -> weights: [1.5555556 0.7368421]\n",
      "Epoch 1/10 | train_loss=0.5922 | val_acc=0.8607, val_f1=0.9231\n",
      "Epoch 2/10 | train_loss=0.1989 | val_acc=0.8548, val_f1=0.9197\n",
      "Epoch 3/10 | train_loss=0.0975 | val_acc=0.5396, val_f1=0.6609\n",
      "Epoch 4/10 | train_loss=0.0526 | val_acc=0.6741, val_f1=0.7857\n",
      "Epoch 5/10 | train_loss=0.0320 | val_acc=0.5797, val_f1=0.6988\n",
      "Epoch 6/10 | train_loss=0.0184 | val_acc=0.7816, val_f1=0.8696\n",
      "Epoch 7/10 | train_loss=0.0220 | val_acc=0.5608, val_f1=0.6905\n",
      "Epoch 8/10 | train_loss=0.0567 | val_acc=0.8158, val_f1=0.8883\n",
      "Epoch 9/10 | train_loss=0.0293 | val_acc=0.6482, val_f1=0.7627\n",
      "Epoch 10/10 | train_loss=0.0271 | val_acc=0.8418, val_f1=0.9124\n",
      "Segment-level metrics -> acc: 0.9587, prec: 1.0000, rec: 0.9587, f1: 0.9789\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject18\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.4983 | val_acc=0.5762, val_f1=0.7278\n",
      "Epoch 2/10 | train_loss=0.1500 | val_acc=0.3920, val_f1=0.5062\n",
      "Epoch 3/10 | train_loss=0.0686 | val_acc=0.5608, val_f1=0.7169\n",
      "Epoch 4/10 | train_loss=0.0579 | val_acc=0.4451, val_f1=0.3614\n",
      "Epoch 5/10 | train_loss=0.0401 | val_acc=0.4451, val_f1=0.6070\n",
      "Epoch 6/10 | train_loss=0.0172 | val_acc=0.5584, val_f1=0.7149\n",
      "Epoch 7/10 | train_loss=0.0105 | val_acc=0.4439, val_f1=0.6052\n",
      "Epoch 8/10 | train_loss=0.0224 | val_acc=0.5041, val_f1=0.6563\n",
      "Epoch 9/10 | train_loss=0.0591 | val_acc=0.4203, val_f1=0.5588\n",
      "Epoch 10/10 | train_loss=0.0205 | val_acc=0.5384, val_f1=0.6971\n",
      "Segment-level metrics -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject19\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5799 | val_acc=0.6612, val_f1=0.7837\n",
      "Epoch 2/10 | train_loss=0.1813 | val_acc=0.7261, val_f1=0.8378\n",
      "Epoch 3/10 | train_loss=0.0863 | val_acc=0.6328, val_f1=0.7362\n",
      "Epoch 4/10 | train_loss=0.0609 | val_acc=0.6954, val_f1=0.7969\n",
      "Epoch 5/10 | train_loss=0.0684 | val_acc=0.7473, val_f1=0.8484\n",
      "Epoch 6/10 | train_loss=0.0231 | val_acc=0.7379, val_f1=0.8268\n",
      "Epoch 7/10 | train_loss=0.0101 | val_acc=0.7414, val_f1=0.8457\n",
      "Epoch 8/10 | train_loss=0.0234 | val_acc=0.7710, val_f1=0.8496\n",
      "Epoch 9/10 | train_loss=0.0156 | val_acc=0.6966, val_f1=0.8015\n",
      "Epoch 10/10 | train_loss=0.0142 | val_acc=0.4782, val_f1=0.5632\n",
      "Segment-level metrics -> acc: 0.9917, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject20\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5744 | val_acc=0.6919, val_f1=0.8148\n",
      "Epoch 2/10 | train_loss=0.1658 | val_acc=0.6812, val_f1=0.8046\n",
      "Epoch 3/10 | train_loss=0.0699 | val_acc=0.5962, val_f1=0.6851\n",
      "Epoch 4/10 | train_loss=0.0488 | val_acc=0.6175, val_f1=0.7523\n",
      "Epoch 5/10 | train_loss=0.0313 | val_acc=0.7143, val_f1=0.8301\n",
      "Epoch 6/10 | train_loss=0.0158 | val_acc=0.5384, val_f1=0.6390\n",
      "Epoch 7/10 | train_loss=0.0215 | val_acc=0.5620, val_f1=0.7053\n",
      "Epoch 8/10 | train_loss=0.0160 | val_acc=0.7178, val_f1=0.8348\n",
      "Epoch 9/10 | train_loss=0.0182 | val_acc=0.6175, val_f1=0.7568\n",
      "Epoch 10/10 | train_loss=0.0421 | val_acc=0.5431, val_f1=0.6602\n",
      "Segment-level metrics -> acc: 0.9835, prec: 1.0000, rec: 0.9835, f1: 0.9917\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject21\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1089 2299] -> weights: [1.5555556 0.7368421]\n",
      "Epoch 1/10 | train_loss=0.5737 | val_acc=0.8453, val_f1=0.9162\n",
      "Epoch 2/10 | train_loss=0.1441 | val_acc=0.9197, val_f1=0.9582\n",
      "Epoch 3/10 | train_loss=0.0803 | val_acc=0.4038, val_f1=0.5753\n",
      "Epoch 4/10 | train_loss=0.0307 | val_acc=0.6151, val_f1=0.7617\n",
      "Epoch 5/10 | train_loss=0.0330 | val_acc=0.8560, val_f1=0.9224\n",
      "Epoch 6/10 | train_loss=0.0368 | val_acc=0.7993, val_f1=0.8885\n",
      "Epoch 7/10 | train_loss=0.0287 | val_acc=0.7048, val_f1=0.8269\n",
      "Epoch 8/10 | train_loss=0.0202 | val_acc=0.7816, val_f1=0.8774\n",
      "Epoch 9/10 | train_loss=0.0127 | val_acc=0.1948, val_f1=0.3261\n",
      "Epoch 10/10 | train_loss=0.0358 | val_acc=0.7957, val_f1=0.8863\n",
      "Segment-level metrics -> acc: 0.1322, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject22\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1089 2299] -> weights: [1.5555556 0.7368421]\n",
      "Epoch 1/10 | train_loss=0.5812 | val_acc=0.9693, val_f1=0.9844\n",
      "Epoch 2/10 | train_loss=0.1971 | val_acc=0.9150, val_f1=0.9556\n",
      "Epoch 3/10 | train_loss=0.0605 | val_acc=0.9646, val_f1=0.9820\n",
      "Epoch 4/10 | train_loss=0.0337 | val_acc=0.9693, val_f1=0.9844\n",
      "Epoch 5/10 | train_loss=0.0665 | val_acc=0.2184, val_f1=0.3585\n",
      "Epoch 6/10 | train_loss=0.0482 | val_acc=0.8701, val_f1=0.9306\n",
      "Epoch 7/10 | train_loss=0.0285 | val_acc=0.6375, val_f1=0.7787\n",
      "Epoch 8/10 | train_loss=0.0142 | val_acc=0.7946, val_f1=0.8855\n",
      "Epoch 9/10 | train_loss=0.0506 | val_acc=0.6375, val_f1=0.7787\n",
      "Epoch 10/10 | train_loss=0.0298 | val_acc=0.9268, val_f1=0.9620\n",
      "Segment-level metrics -> acc: 0.6777, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 0, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject23\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5756 | val_acc=0.6222, val_f1=0.7260\n",
      "Epoch 2/10 | train_loss=0.1761 | val_acc=0.7037, val_f1=0.8156\n",
      "Epoch 3/10 | train_loss=0.0763 | val_acc=0.7037, val_f1=0.8236\n",
      "Epoch 4/10 | train_loss=0.0623 | val_acc=0.6494, val_f1=0.7080\n",
      "Epoch 5/10 | train_loss=0.0244 | val_acc=0.7485, val_f1=0.8337\n",
      "Epoch 6/10 | train_loss=0.0359 | val_acc=0.4427, val_f1=0.4055\n",
      "Epoch 7/10 | train_loss=0.0167 | val_acc=0.4215, val_f1=0.3414\n",
      "Epoch 8/10 | train_loss=0.0144 | val_acc=0.6505, val_f1=0.7362\n",
      "Epoch 9/10 | train_loss=0.0085 | val_acc=0.3270, val_f1=0.1337\n",
      "Epoch 10/10 | train_loss=0.0483 | val_acc=0.7261, val_f1=0.8348\n",
      "Segment-level metrics -> acc: 0.9752, prec: 1.0000, rec: 0.9752, f1: 0.9874\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject24\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1210 2178] -> weights: [1.4       0.7777778]\n",
      "Epoch 1/10 | train_loss=0.5635 | val_acc=0.5832, val_f1=0.7368\n",
      "Epoch 2/10 | train_loss=0.1652 | val_acc=0.3589, val_f1=0.5282\n",
      "Epoch 3/10 | train_loss=0.0987 | val_acc=0.2125, val_f1=0.3505\n",
      "Epoch 4/10 | train_loss=0.0616 | val_acc=0.2456, val_f1=0.3943\n",
      "Epoch 5/10 | train_loss=0.0243 | val_acc=0.4534, val_f1=0.6239\n",
      "Epoch 6/10 | train_loss=0.0275 | val_acc=0.7403, val_f1=0.8507\n",
      "Epoch 7/10 | train_loss=0.0269 | val_acc=0.6741, val_f1=0.8054\n",
      "Epoch 8/10 | train_loss=0.0266 | val_acc=0.9055, val_f1=0.9504\n",
      "Epoch 9/10 | train_loss=0.0205 | val_acc=0.8182, val_f1=0.9000\n",
      "Epoch 10/10 | train_loss=0.0549 | val_acc=0.6635, val_f1=0.7977\n",
      "Segment-level metrics -> acc: 0.9091, prec: 1.0000, rec: 0.9091, f1: 0.9524\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject25\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 726 2662] -> weights: [2.3333333 0.6363636]\n",
      "Epoch 1/10 | train_loss=0.5169 | val_acc=0.4321, val_f1=0.6015\n",
      "Epoch 2/10 | train_loss=0.1309 | val_acc=0.5065, val_f1=0.6221\n",
      "Epoch 3/10 | train_loss=0.0651 | val_acc=0.4687, val_f1=0.6160\n",
      "Epoch 4/10 | train_loss=0.0375 | val_acc=0.4793, val_f1=0.6202\n",
      "Epoch 5/10 | train_loss=0.0241 | val_acc=0.5561, val_f1=0.6132\n",
      "Epoch 6/10 | train_loss=0.0267 | val_acc=0.6033, val_f1=0.6529\n",
      "Epoch 7/10 | train_loss=0.0307 | val_acc=0.5667, val_f1=0.6165\n",
      "Epoch 8/10 | train_loss=0.0429 | val_acc=0.6057, val_f1=0.4893\n",
      "Epoch 9/10 | train_loss=0.0107 | val_acc=0.5159, val_f1=0.6352\n",
      "Epoch 10/10 | train_loss=0.0096 | val_acc=0.5431, val_f1=0.6359\n",
      "Segment-level metrics -> acc: 0.5868, prec: 1.0000, rec: 0.5868, f1: 0.7396\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject26\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5824 | val_acc=0.7426, val_f1=0.8467\n",
      "Epoch 2/10 | train_loss=0.1639 | val_acc=0.5962, val_f1=0.6885\n",
      "Epoch 3/10 | train_loss=0.0831 | val_acc=0.7143, val_f1=0.8276\n",
      "Epoch 4/10 | train_loss=0.0366 | val_acc=0.7037, val_f1=0.8206\n",
      "Epoch 5/10 | train_loss=0.0234 | val_acc=0.7462, val_f1=0.8434\n",
      "Epoch 6/10 | train_loss=0.0261 | val_acc=0.6387, val_f1=0.7398\n",
      "Epoch 7/10 | train_loss=0.0233 | val_acc=0.6753, val_f1=0.8000\n",
      "Epoch 8/10 | train_loss=0.0279 | val_acc=0.5714, val_f1=0.6546\n",
      "Epoch 9/10 | train_loss=0.0258 | val_acc=0.6954, val_f1=0.8045\n",
      "Epoch 10/10 | train_loss=0.0247 | val_acc=0.6765, val_f1=0.8009\n",
      "Segment-level metrics -> acc: 0.9256, prec: 1.0000, rec: 0.9256, f1: 0.9614\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject27\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5086 | val_acc=0.4699, val_f1=0.4857\n",
      "Epoch 2/10 | train_loss=0.1338 | val_acc=0.3837, val_f1=0.5237\n",
      "Epoch 3/10 | train_loss=0.0716 | val_acc=0.3979, val_f1=0.4890\n",
      "Epoch 4/10 | train_loss=0.0604 | val_acc=0.4120, val_f1=0.5146\n",
      "Epoch 5/10 | train_loss=0.0240 | val_acc=0.4238, val_f1=0.5572\n",
      "Epoch 6/10 | train_loss=0.0361 | val_acc=0.4510, val_f1=0.5289\n",
      "Epoch 7/10 | train_loss=0.0417 | val_acc=0.4522, val_f1=0.5256\n",
      "Epoch 8/10 | train_loss=0.0255 | val_acc=0.5691, val_f1=0.5302\n",
      "Epoch 9/10 | train_loss=0.0299 | val_acc=0.4463, val_f1=0.5333\n",
      "Epoch 10/10 | train_loss=0.0290 | val_acc=0.3790, val_f1=0.5157\n",
      "Segment-level metrics -> acc: 0.7438, prec: 1.0000, rec: 0.7438, f1: 0.8531\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject28\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1089 2299] -> weights: [1.5555556 0.7368421]\n",
      "Epoch 1/10 | train_loss=0.5392 | val_acc=0.6919, val_f1=0.8176\n",
      "Epoch 2/10 | train_loss=0.1686 | val_acc=0.8182, val_f1=0.8995\n",
      "Epoch 3/10 | train_loss=0.0783 | val_acc=0.5254, val_f1=0.6721\n",
      "Epoch 4/10 | train_loss=0.0380 | val_acc=0.6151, val_f1=0.7301\n",
      "Epoch 5/10 | train_loss=0.0348 | val_acc=0.7037, val_f1=0.8114\n",
      "Epoch 6/10 | train_loss=0.0414 | val_acc=0.3813, val_f1=0.4576\n",
      "Epoch 7/10 | train_loss=0.0305 | val_acc=0.4510, val_f1=0.5730\n",
      "Epoch 8/10 | train_loss=0.0175 | val_acc=0.7568, val_f1=0.8479\n",
      "Epoch 9/10 | train_loss=0.0157 | val_acc=0.4652, val_f1=0.5863\n",
      "Epoch 10/10 | train_loss=0.0287 | val_acc=0.3046, val_f1=0.3345\n",
      "Segment-level metrics -> acc: 0.3223, prec: 1.0000, rec: 0.3223, f1: 0.4875\n",
      "Subject-level prediction -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject29\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5850 | val_acc=0.5785, val_f1=0.7293\n",
      "Epoch 2/10 | train_loss=0.1797 | val_acc=0.6458, val_f1=0.7623\n",
      "Epoch 3/10 | train_loss=0.0769 | val_acc=0.6883, val_f1=0.7724\n",
      "Epoch 4/10 | train_loss=0.0621 | val_acc=0.7686, val_f1=0.8024\n",
      "Epoch 5/10 | train_loss=0.0411 | val_acc=0.7568, val_f1=0.8060\n",
      "Epoch 6/10 | train_loss=0.0358 | val_acc=0.6151, val_f1=0.7457\n",
      "Epoch 7/10 | train_loss=0.0265 | val_acc=0.6364, val_f1=0.7567\n",
      "Epoch 8/10 | train_loss=0.0359 | val_acc=0.7710, val_f1=0.8072\n",
      "Epoch 9/10 | train_loss=0.0294 | val_acc=0.7072, val_f1=0.7940\n",
      "Epoch 10/10 | train_loss=0.0086 | val_acc=0.7131, val_f1=0.7980\n",
      "Segment-level metrics -> acc: 1.0000, prec: 1.0000, rec: 1.0000, f1: 1.0000\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject30\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 726 2662] -> weights: [2.3333333 0.6363636]\n",
      "Epoch 1/10 | train_loss=0.5024 | val_acc=0.4510, val_f1=0.6192\n",
      "Epoch 2/10 | train_loss=0.1095 | val_acc=0.4876, val_f1=0.6233\n",
      "Epoch 3/10 | train_loss=0.0921 | val_acc=0.5183, val_f1=0.6471\n",
      "Epoch 4/10 | train_loss=0.0414 | val_acc=0.4959, val_f1=0.5364\n",
      "Epoch 5/10 | train_loss=0.0214 | val_acc=0.4829, val_f1=0.6427\n",
      "Epoch 6/10 | train_loss=0.0336 | val_acc=0.5148, val_f1=0.6059\n",
      "Epoch 7/10 | train_loss=0.0170 | val_acc=0.4888, val_f1=0.6218\n",
      "Epoch 8/10 | train_loss=0.0106 | val_acc=0.4793, val_f1=0.6388\n",
      "Epoch 9/10 | train_loss=0.0110 | val_acc=0.5077, val_f1=0.6199\n",
      "Epoch 10/10 | train_loss=0.0208 | val_acc=0.4959, val_f1=0.6503\n",
      "Segment-level metrics -> acc: 0.0496, prec: 0.0000, rec: 0.0000, f1: 0.0000\n",
      "Subject-level prediction -> true: 0, pred: 1, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject31\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5055 | val_acc=0.7084, val_f1=0.8286\n",
      "Epoch 2/10 | train_loss=0.1073 | val_acc=0.5962, val_f1=0.7425\n",
      "Epoch 3/10 | train_loss=0.0499 | val_acc=0.5785, val_f1=0.7247\n",
      "Epoch 4/10 | train_loss=0.0340 | val_acc=0.6954, val_f1=0.8198\n",
      "Epoch 5/10 | train_loss=0.0432 | val_acc=0.5195, val_f1=0.6757\n",
      "Epoch 6/10 | train_loss=0.0318 | val_acc=0.5124, val_f1=0.6509\n",
      "Epoch 7/10 | train_loss=0.0196 | val_acc=0.4534, val_f1=0.5956\n",
      "Epoch 8/10 | train_loss=0.0162 | val_acc=0.3506, val_f1=0.4174\n",
      "Epoch 9/10 | train_loss=0.0115 | val_acc=0.5301, val_f1=0.6900\n",
      "Epoch 10/10 | train_loss=0.0194 | val_acc=0.4191, val_f1=0.5376\n",
      "Segment-level metrics -> acc: 0.6529, prec: 1.0000, rec: 0.6529, f1: 0.7900\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject32\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 968 2420] -> weights: [1.75 0.7 ]\n",
      "Epoch 1/10 | train_loss=0.5452 | val_acc=0.6919, val_f1=0.8074\n",
      "Epoch 2/10 | train_loss=0.1504 | val_acc=0.4545, val_f1=0.4726\n",
      "Epoch 3/10 | train_loss=0.0618 | val_acc=0.7202, val_f1=0.8040\n",
      "Epoch 4/10 | train_loss=0.0435 | val_acc=0.7651, val_f1=0.8549\n",
      "Epoch 5/10 | train_loss=0.0314 | val_acc=0.7887, val_f1=0.8630\n",
      "Epoch 6/10 | train_loss=0.0366 | val_acc=0.7851, val_f1=0.8662\n",
      "Epoch 7/10 | train_loss=0.0435 | val_acc=0.7379, val_f1=0.8198\n",
      "Epoch 8/10 | train_loss=0.0297 | val_acc=0.7839, val_f1=0.8593\n",
      "Epoch 9/10 | train_loss=0.0195 | val_acc=0.7072, val_f1=0.7930\n",
      "Epoch 10/10 | train_loss=0.0285 | val_acc=0.7603, val_f1=0.8463\n",
      "Segment-level metrics -> acc: 0.6860, prec: 1.0000, rec: 0.6860, f1: 0.8137\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject33\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.6074 | val_acc=0.5962, val_f1=0.7385\n",
      "Epoch 2/10 | train_loss=0.2696 | val_acc=0.6257, val_f1=0.7365\n",
      "Epoch 3/10 | train_loss=0.0884 | val_acc=0.4545, val_f1=0.3905\n",
      "Epoch 4/10 | train_loss=0.0820 | val_acc=0.5396, val_f1=0.4413\n",
      "Epoch 5/10 | train_loss=0.0678 | val_acc=0.5986, val_f1=0.7267\n",
      "Epoch 6/10 | train_loss=0.0220 | val_acc=0.5490, val_f1=0.5708\n",
      "Epoch 7/10 | train_loss=0.0163 | val_acc=0.6375, val_f1=0.7558\n",
      "Epoch 8/10 | train_loss=0.0339 | val_acc=0.5679, val_f1=0.6280\n",
      "Epoch 9/10 | train_loss=0.0409 | val_acc=0.5750, val_f1=0.6226\n",
      "Epoch 10/10 | train_loss=0.0197 | val_acc=0.5384, val_f1=0.5990\n",
      "Segment-level metrics -> acc: 0.9835, prec: 1.0000, rec: 0.9835, f1: 0.9917\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject34\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [ 847 2541] -> weights: [2.        0.6666667]\n",
      "Epoch 1/10 | train_loss=0.5665 | val_acc=0.6187, val_f1=0.6439\n",
      "Epoch 2/10 | train_loss=0.1497 | val_acc=0.6765, val_f1=0.7472\n",
      "Epoch 3/10 | train_loss=0.0650 | val_acc=0.6541, val_f1=0.7025\n",
      "Epoch 4/10 | train_loss=0.0327 | val_acc=0.5773, val_f1=0.7242\n",
      "Epoch 5/10 | train_loss=0.0396 | val_acc=0.5726, val_f1=0.7278\n",
      "Epoch 6/10 | train_loss=0.0377 | val_acc=0.6198, val_f1=0.6728\n",
      "Epoch 7/10 | train_loss=0.0322 | val_acc=0.6033, val_f1=0.6364\n",
      "Epoch 8/10 | train_loss=0.0329 | val_acc=0.5679, val_f1=0.5537\n",
      "Epoch 9/10 | train_loss=0.0183 | val_acc=0.5915, val_f1=0.7334\n",
      "Epoch 10/10 | train_loss=0.0125 | val_acc=0.5927, val_f1=0.7074\n",
      "Segment-level metrics -> acc: 0.5289, prec: 1.0000, rec: 0.5289, f1: 0.6919\n",
      "Subject-level prediction -> true: 1, pred: 1, acc: 1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject35\n",
      "Train segments: 3388 | Val segments: 847 | Test segments: 121\n",
      "Class counts (train): [1210 2178] -> weights: [1.4       0.7777778]\n",
      "Epoch 1/10 | train_loss=0.6021 | val_acc=0.8855, val_f1=0.9393\n",
      "Epoch 2/10 | train_loss=0.2252 | val_acc=0.8182, val_f1=0.9000\n",
      "Epoch 3/10 | train_loss=0.0820 | val_acc=0.9847, val_f1=0.9923\n",
      "Epoch 4/10 | train_loss=0.0615 | val_acc=0.9516, val_f1=0.9752\n",
      "Epoch 5/10 | train_loss=0.0610 | val_acc=0.6871, val_f1=0.8146\n",
      "Epoch 6/10 | train_loss=0.0602 | val_acc=0.7273, val_f1=0.8421\n",
      "Epoch 7/10 | train_loss=0.0308 | val_acc=0.8548, val_f1=0.9217\n",
      "Epoch 8/10 | train_loss=0.0222 | val_acc=0.6529, val_f1=0.7900\n",
      "Epoch 9/10 | train_loss=0.0142 | val_acc=0.8418, val_f1=0.9141\n",
      "Epoch 10/10 | train_loss=0.0325 | val_acc=0.4439, val_f1=0.6149\n",
      "Segment-level metrics -> acc: 0.3306, prec: 1.0000, rec: 0.3306, f1: 0.4969\n",
      "Subject-level prediction -> true: 1, pred: 0, acc: 0.0000\n",
      "\n",
      "============================================================\n",
      "Average SEGMENT-level (LOSO):\n",
      "Accuracy : 0.6442\n",
      "Precision: 0.7222\n",
      "Recall   : 0.5585\n",
      "F1-score : 0.6152\n",
      "\n",
      "Average SUBJECT-level (LOSO, majority vote):\n",
      "Accuracy : 0.7222\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#   Dual-Path CNN (Temporal + Channel Branch)\n",
    "#   LOSO روی EEGMAT با class-weight و val سوژه‌ای\n",
    "# ============================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# -----------------------------\n",
    "# تنظیمات دیتاست و مدل\n",
    "# -----------------------------\n",
    "DATA_FOLDER = \"/kaggle/input/ahmadi-dataset\"    # مسیر دیتاست EEGMAT\n",
    "INFO_CSV = f\"{DATA_FOLDER}/subject-info.csv\"\n",
    "\n",
    "RESAMPLE_TO = 128         # Hz\n",
    "WINDOW_SEC = 2.0          # طول سگمنت (ثانیه)\n",
    "OVERLAP_RATIO = 0.75      # درصد overlap بین سگمنت‌ها\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10           # می‌تونی بعداً بیشترش کنی (مثلاً 20)\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "if DEVICE.type == \"cuda\":\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# -----------------------------\n",
    "# ۱) لود EEG + baseline از rest\n",
    "# -----------------------------\n",
    "def load_task_edf_with_baseline(folder_path=DATA_FOLDER,\n",
    "                                info_csv_path=INFO_CSV,\n",
    "                                resample_to=RESAMPLE_TO,\n",
    "                                use_baseline=True):\n",
    "    folder = Path(folder_path)\n",
    "    info_df = pd.read_csv(info_csv_path)\n",
    "    label_map = dict(zip(info_df[\"Subject\"], info_df[\"Count quality\"]))\n",
    "\n",
    "    X_list, y_list, subjects = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for subj_name in info_df[\"Subject\"]:\n",
    "        task_file = folder / f\"{subj_name}_2.edf\"\n",
    "        rest_file = folder / f\"{subj_name}_1.edf\"\n",
    "\n",
    "        if not task_file.is_file():\n",
    "            print(f\"Task file not found for {subj_name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if subj_name not in label_map:\n",
    "            print(f\"{subj_name} not in subject-info, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Loading {subj_name}_1.edf (rest) and {subj_name}_2.edf (task)...\")\n",
    "        raw_task = mne.io.read_raw_edf(task_file, preload=True, verbose=False)\n",
    "\n",
    "        raw_rest = None\n",
    "        if use_baseline and rest_file.is_file():\n",
    "            raw_rest = mne.io.read_raw_edf(rest_file, preload=True, verbose=False)\n",
    "\n",
    "        if resample_to is not None:\n",
    "            raw_task.resample(resample_to)\n",
    "            if raw_rest is not None:\n",
    "                raw_rest.resample(resample_to)\n",
    "\n",
    "        if sfreq is None:\n",
    "            sfreq = raw_task.info[\"sfreq\"]\n",
    "\n",
    "        task_data = raw_task.get_data()  # (C, T)\n",
    "\n",
    "        if use_baseline and raw_rest is not None:\n",
    "            rest_data = raw_rest.get_data()\n",
    "            baseline = rest_data.mean(axis=1, keepdims=True)  # (C,1)\n",
    "            task_data = task_data - baseline\n",
    "\n",
    "        X_list.append(task_data)\n",
    "        y_list.append(int(label_map[subj_name]))\n",
    "        subjects.append(subj_name)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No task files loaded.\")\n",
    "\n",
    "    lengths = [d.shape[1] for d in X_list]\n",
    "    min_len = min(lengths)\n",
    "    X = np.stack([d[:, :min_len] for d in X_list], axis=0)  # (N, C, T)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    subjects = np.array(subjects)\n",
    "\n",
    "    print(\"Final tensor X shape (N, C, T):\", X.shape)\n",
    "    print(\"Labels y shape:\", y.shape)\n",
    "\n",
    "    return X, y, subjects, sfreq\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ۲) سگمنت کردن سیگنال‌ها\n",
    "# -----------------------------\n",
    "def make_segments(X, y, subjects, sfreq,\n",
    "                  window_sec=WINDOW_SEC,\n",
    "                  overlap_ratio=OVERLAP_RATIO):\n",
    "    N, C, T = X.shape\n",
    "    win_size = int(window_sec * sfreq)\n",
    "    step_sec = window_sec * (1.0 - overlap_ratio)\n",
    "    step = max(1, int(step_sec * sfreq))\n",
    "\n",
    "    seg_X_list, seg_y_list, seg_subj_list = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        data = X[i]\n",
    "        subj_label = y[i]\n",
    "        subj_id = subjects[i]\n",
    "\n",
    "        start = 0\n",
    "        while start + win_size <= T:\n",
    "            seg = data[:, start:start+win_size]     # (C, win_size)\n",
    "            seg_X_list.append(seg)\n",
    "            seg_y_list.append(subj_label)\n",
    "            seg_subj_list.append(subj_id)\n",
    "            start += step\n",
    "\n",
    "    seg_X = np.stack(seg_X_list, axis=0)       # (N_seg, C, win_size)\n",
    "    seg_y = np.array(seg_y_list, dtype=int)\n",
    "    seg_subj = np.array(seg_subj_list)\n",
    "\n",
    "    print(\"Segmented data shape:\", seg_X.shape)\n",
    "    return seg_X, seg_y, seg_subj\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ۳) نرمال‌سازی بر اساس train\n",
    "# -----------------------------\n",
    "def standardize_train_val_test(X_train, X_val, X_test):\n",
    "    mean = X_train.mean()\n",
    "    std = X_train.std()\n",
    "    if std == 0:\n",
    "        std = 1.0\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm = (X_val - mean) / std\n",
    "    X_test_norm = (X_test - mean) / std\n",
    "    return (X_train_norm.astype(\"float32\"),\n",
    "            X_val_norm.astype(\"float32\"),\n",
    "            X_test_norm.astype(\"float32\"))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ۴) Dataset برای PyTorch\n",
    "# -----------------------------\n",
    "class EEGSegDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ۵) Dual-Path CNN مدل\n",
    "# -----------------------------\n",
    "class DualPathEEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    شاخه اول: روی (C, T) → فیچرهای زمانی (Temporal)\n",
    "    شاخه دوم: روی (T, C) → Conv روی Channel → فیچرهای فضایی/چنلی\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels, n_timepoints,\n",
    "                 temporal_feat_dim=128, spatial_feat_dim=128,\n",
    "                 hidden_dim=128, n_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- Temporal Branch (B, C, T) ---\n",
    "        self.temporal_branch = nn.Sequential(\n",
    "            nn.Conv1d(n_channels, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(128, temporal_feat_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(temporal_feat_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)  # → (B, temporal_feat_dim, 1)\n",
    "        )\n",
    "\n",
    "        # --- Spatial/Channel Branch ---\n",
    "        # x: (B, C, T) → (B, T, C) → (B*T, 1, C)\n",
    "        self.spatial_conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "\n",
    "            nn.Conv1d(64, spatial_feat_dim, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(spatial_feat_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)  # → (B*T, spatial_feat_dim, 1)\n",
    "        )\n",
    "\n",
    "        fused_dim = temporal_feat_dim + spatial_feat_dim\n",
    "        self.fusion_dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fused_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, T)\n",
    "        \"\"\"\n",
    "        B, C, T = x.shape\n",
    "\n",
    "        # --- Temporal branch ---\n",
    "        t_feat = self.temporal_branch(x)          # (B, temporal_feat_dim, 1)\n",
    "        t_feat = t_feat.squeeze(-1)               # (B, temporal_feat_dim)\n",
    "\n",
    "        # --- Spatial branch ---\n",
    "        x_tc = x.transpose(1, 2)                  # (B, T, C)\n",
    "        x_tc_flat = x_tc.reshape(B * T, 1, C)     # (B*T, 1, C)\n",
    "        s_feat = self.spatial_conv(x_tc_flat)     # (B*T, spatial_feat_dim, 1)\n",
    "        s_feat = s_feat.squeeze(-1)               # (B*T, spatial_feat_dim)\n",
    "        s_feat = s_feat.reshape(B, T, -1)         # (B, T, spatial_feat_dim)\n",
    "        s_feat = s_feat.mean(dim=1)               # (B, spatial_feat_dim)\n",
    "\n",
    "        fused = torch.cat([t_feat, s_feat], dim=1)  # (B, fused_dim)\n",
    "        fused = self.fusion_dropout(fused)\n",
    "        logits = self.classifier(fused)           # (B, n_classes)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ۶) train و evaluate روی یک fold\n",
    "# -----------------------------\n",
    "def train_one_fold(model, train_loader, val_loader,\n",
    "                   num_epochs=NUM_EPOCHS,\n",
    "                   lr=LR, weight_decay=WEIGHT_DECAY,\n",
    "                   device=DEVICE,\n",
    "                   class_weights=None):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr,\n",
    "                                 weight_decay=weight_decay)\n",
    "\n",
    "    if class_weights is not None:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ----- train -----\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # ----- validation -----\n",
    "        model.eval()\n",
    "        all_y = []\n",
    "        all_pred = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "\n",
    "                logits = model(xb)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "                all_y.append(yb.cpu().numpy())\n",
    "                all_pred.append(preds.cpu().numpy())\n",
    "\n",
    "        all_y = np.concatenate(all_y)\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "\n",
    "        acc = accuracy_score(all_y, all_pred)\n",
    "        prec = precision_score(all_y, all_pred, zero_division=0)\n",
    "        rec = recall_score(all_y, all_pred, zero_division=0)\n",
    "        f1 = f1_score(all_y, all_pred, zero_division=0)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"train_loss={avg_loss:.4f} | \"\n",
    "              f\"val_acc={acc:.4f}, val_f1={f1:.4f}\")\n",
    "\n",
    "        if f1 > best_val_f1:\n",
    "            best_val_f1 = f1\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_on_segments(model, loader, device=DEVICE):\n",
    "    model.eval()\n",
    "    all_y, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_y.append(yb.cpu().numpy())\n",
    "            all_pred.append(preds.cpu().numpy())\n",
    "\n",
    "    all_y = np.concatenate(all_y)\n",
    "    all_pred = np.concatenate(all_pred)\n",
    "\n",
    "    acc = accuracy_score(all_y, all_pred)\n",
    "    prec = precision_score(all_y, all_pred, zero_division=0)\n",
    "    rec = recall_score(all_y, all_pred, zero_division=0)\n",
    "    f1 = f1_score(all_y, all_pred, zero_division=0)\n",
    "    return acc, prec, rec, f1, all_y, all_pred\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ۷) LOSO evaluation با val سوژه‌ای\n",
    "# -----------------------------\n",
    "def loso_dualpath(X_seg, y_seg, subj_seg):\n",
    "    unique_subjects = np.unique(subj_seg)\n",
    "    results_seg = []\n",
    "    results_subj = []\n",
    "\n",
    "    N_seg, C, T = X_seg.shape\n",
    "    print(\"Segmented data shape:\", X_seg.shape)\n",
    "\n",
    "    for fold_idx, test_subj in enumerate(unique_subjects):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Test subject:\", test_subj)\n",
    "\n",
    "        is_test = (subj_seg == test_subj)\n",
    "        is_train_all = ~is_test\n",
    "\n",
    "        # سوژه‌های train\n",
    "        train_subjects = np.unique(subj_seg[is_train_all])\n",
    "\n",
    "        # سوژه‌های val (20% از train subjects)\n",
    "        rng = np.random.RandomState(RANDOM_STATE + fold_idx)\n",
    "        perm_subj = rng.permutation(train_subjects)\n",
    "        n_val_subj = max(1, int(0.2 * len(train_subjects)))\n",
    "        val_subj = perm_subj[:n_val_subj]\n",
    "        real_train_subj = perm_subj[n_val_subj:]\n",
    "\n",
    "        is_val = np.isin(subj_seg, val_subj) & is_train_all\n",
    "        is_train = np.isin(subj_seg, real_train_subj)\n",
    "\n",
    "        X_train = X_seg[is_train]\n",
    "        y_train = y_seg[is_train]\n",
    "        X_val = X_seg[is_val]\n",
    "        y_val = y_seg[is_val]\n",
    "        X_test = X_seg[is_test]\n",
    "        y_test = y_seg[is_test]\n",
    "\n",
    "        print(f\"Train segments: {X_train.shape[0]} | \"\n",
    "              f\"Val segments: {X_val.shape[0]} | \"\n",
    "              f\"Test segments: {X_test.shape[0]}\")\n",
    "\n",
    "        # نرمال‌سازی\n",
    "        X_train_norm, X_val_norm, X_test_norm = standardize_train_val_test(\n",
    "            X_train, X_val, X_test\n",
    "        )\n",
    "\n",
    "        # class weights از روی y_train\n",
    "        class_counts = np.bincount(y_train, minlength=2)\n",
    "        class_counts[class_counts == 0] = 1\n",
    "        total = class_counts.sum()\n",
    "        num_classes = len(class_counts)\n",
    "        weights_np = total / (num_classes * class_counts.astype(np.float32))\n",
    "        class_weights = torch.tensor(weights_np, dtype=torch.float32).to(DEVICE)\n",
    "        print(\"Class counts (train):\", class_counts, \"-> weights:\", weights_np)\n",
    "\n",
    "        train_ds = EEGSegDataset(X_train_norm, y_train)\n",
    "        val_ds = EEGSegDataset(X_val_norm, y_val)\n",
    "        test_ds = EEGSegDataset(X_test_norm, y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                                  shuffle=True, drop_last=False)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE,\n",
    "                                shuffle=False, drop_last=False)\n",
    "        test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False, drop_last=False)\n",
    "\n",
    "        model = DualPathEEGNet(\n",
    "            n_channels=C,\n",
    "            n_timepoints=T,\n",
    "            temporal_feat_dim=128,\n",
    "            spatial_feat_dim=128,\n",
    "            hidden_dim=128,\n",
    "            n_classes=2\n",
    "        )\n",
    "\n",
    "        model = train_one_fold(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            lr=LR,\n",
    "            weight_decay=WEIGHT_DECAY,\n",
    "            device=DEVICE,\n",
    "            class_weights=class_weights\n",
    "        )\n",
    "\n",
    "        acc_s, prec_s, rec_s, f1_s, y_true_seg, y_pred_seg = evaluate_on_segments(\n",
    "            model, test_loader, device=DEVICE\n",
    "        )\n",
    "\n",
    "        print(f\"Segment-level metrics -> acc: {acc_s:.4f}, \"\n",
    "              f\"prec: {prec_s:.4f}, rec: {rec_s:.4f}, f1: {f1_s:.4f}\")\n",
    "        results_seg.append([acc_s, prec_s, rec_s, f1_s])\n",
    "\n",
    "        # subject-level majority vote\n",
    "        true_label = int(y_test[0])\n",
    "        counts = np.bincount(y_pred_seg)\n",
    "        pred_label = int(np.argmax(counts))\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level prediction -> true: {true_label}, \"\n",
    "              f\"pred: {pred_label}, acc: {acc_subj:.4f}\")\n",
    "        results_subj.append(acc_subj)\n",
    "\n",
    "    results_seg = np.array(results_seg)\n",
    "    subj_accs = np.array(results_subj)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Average SEGMENT-level (LOSO):\")\n",
    "    print(f\"Accuracy : {results_seg[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {results_seg[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {results_seg[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {results_seg[:,3].mean():.4f}\")\n",
    "\n",
    "    print(\"\\nAverage SUBJECT-level (LOSO, majority vote):\")\n",
    "    print(f\"Accuracy : {subj_accs.mean():.4f}\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# ۸) main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline()\n",
    "    X_seg, y_seg, subj_seg = make_segments(X, y, subjects, sfreq)\n",
    "    loso_dualpath(X_seg, y_seg, subj_seg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379b8af",
   "metadata": {
    "papermill": {
     "duration": 0.063019,
     "end_time": "2025-12-12T09:52:50.475773",
     "exception": false,
     "start_time": "2025-12-12T09:52:50.412754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "bi lstm\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c9ceac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:52:50.602838Z",
     "iopub.status.busy": "2025-12-12T09:52:50.602347Z",
     "iopub.status.idle": "2025-12-12T09:58:55.315642Z",
     "shell.execute_reply": "2025-12-12T09:58:55.314556Z"
    },
    "papermill": {
     "duration": 364.778999,
     "end_time": "2025-12-12T09:58:55.317258",
     "exception": false,
     "start_time": "2025-12-12T09:52:50.538259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "X: (36, 21, 7936) y: (36,) sfreq: 128.0\n",
      "Segments: (4356, 21, 256)\n",
      "Unique subjects: 36\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject00\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3623 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0354 | val_f1=0.4084\n",
      "Segment-level -> acc=0.0165, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject01\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4089 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0714 | val_f1=0.2044\n",
      "  Epoch 10 | train_loss=0.0214 | val_f1=0.2188\n",
      "Segment-level -> acc=0.9008, prec=1.0000, rec=0.9008, f1=0.9478\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject02\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4044 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1025 | val_f1=0.3007\n",
      "Segment-level -> acc=0.9835, prec=1.0000, rec=0.9835, f1=0.9917\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject03\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.3981 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1373 | val_f1=0.2461\n",
      "Segment-level -> acc=0.8926, prec=1.0000, rec=0.8926, f1=0.9432\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject04\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3699 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0721 | val_f1=0.2878\n",
      "  Epoch 10 | train_loss=0.0178 | val_f1=0.2686\n",
      "Segment-level -> acc=0.0826, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject05\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4064 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0781 | val_f1=0.2509\n",
      "  Epoch 10 | train_loss=0.0156 | val_f1=0.2721\n",
      "Segment-level -> acc=0.8430, prec=1.0000, rec=0.8430, f1=0.9148\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject06\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3569 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0986 | val_f1=0.2509\n",
      "  Epoch 10 | train_loss=0.0195 | val_f1=0.2876\n",
      "Segment-level -> acc=0.4959, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject07\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4064 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1110 | val_f1=0.2048\n",
      "  Epoch 10 | train_loss=0.0175 | val_f1=0.2469\n",
      "Segment-level -> acc=0.8430, prec=1.0000, rec=0.8430, f1=0.9148\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject08\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.3998 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1150 | val_f1=0.1328\n",
      "  Epoch 10 | train_loss=0.0158 | val_f1=0.2176\n",
      "Segment-level -> acc=0.9752, prec=1.0000, rec=0.9752, f1=0.9874\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject09\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3582 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0827 | val_f1=0.1371\n",
      "  Epoch 10 | train_loss=0.0137 | val_f1=0.3639\n",
      "Segment-level -> acc=0.0413, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject10\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3591 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0628 | val_f1=0.5838\n",
      "  Epoch 10 | train_loss=0.0187 | val_f1=0.6438\n",
      "  Epoch 15 | train_loss=0.0076 | val_f1=0.5839\n",
      "Segment-level -> acc=0.1901, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject11\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4064 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0888 | val_f1=0.1910\n",
      "Segment-level -> acc=0.9835, prec=1.0000, rec=0.9835, f1=0.9917\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject12\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4004 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0983 | val_f1=0.2877\n",
      "  Epoch 10 | train_loss=0.0324 | val_f1=0.2163\n",
      "  Epoch 15 | train_loss=0.0163 | val_f1=0.4485\n",
      "  Epoch 20 | train_loss=0.0056 | val_f1=0.3240\n",
      "Segment-level -> acc=0.8264, prec=1.0000, rec=0.8264, f1=0.9050\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject13\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.3990 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0696 | val_f1=0.2594\n",
      "Segment-level -> acc=0.3967, prec=1.0000, rec=0.3967, f1=0.5680\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject14\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3994 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0755 | val_f1=0.3144\n",
      "  Epoch 10 | train_loss=0.0132 | val_f1=0.5301\n",
      "  Epoch 15 | train_loss=0.0163 | val_f1=0.5480\n",
      "Segment-level -> acc=0.3306, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject15\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4361 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0941 | val_f1=0.3501\n",
      "Segment-level -> acc=0.4545, prec=1.0000, rec=0.4545, f1=0.6250\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject16\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4440 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0963 | val_f1=0.4831\n",
      "  Epoch 10 | train_loss=0.0158 | val_f1=0.6077\n",
      "Segment-level -> acc=0.6446, prec=1.0000, rec=0.6446, f1=0.7839\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject17\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4226 | val_f1=0.0754\n",
      "  Epoch 05 | train_loss=0.0965 | val_f1=0.4516\n",
      "  Epoch 10 | train_loss=0.0337 | val_f1=0.5300\n",
      "  Epoch 15 | train_loss=0.0157 | val_f1=0.4564\n",
      "Segment-level -> acc=0.8264, prec=1.0000, rec=0.8264, f1=0.9050\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject18\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4444 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1180 | val_f1=0.4455\n",
      "  Epoch 10 | train_loss=0.0231 | val_f1=0.6185\n",
      "  Epoch 15 | train_loss=0.0184 | val_f1=0.5362\n",
      "Segment-level -> acc=0.3967, prec=1.0000, rec=0.3967, f1=0.5680\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject19\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3959 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0731 | val_f1=0.6314\n",
      "  Epoch 10 | train_loss=0.0312 | val_f1=0.6023\n",
      "Segment-level -> acc=0.0083, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject20\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4414 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0984 | val_f1=0.4139\n",
      "  Epoch 10 | train_loss=0.0346 | val_f1=0.5700\n",
      "  Epoch 15 | train_loss=0.0127 | val_f1=0.5605\n",
      "Segment-level -> acc=0.9752, prec=1.0000, rec=0.9752, f1=0.9874\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject21\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.4110 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1109 | val_f1=0.4217\n",
      "  Epoch 10 | train_loss=0.0441 | val_f1=0.4662\n",
      "  Epoch 15 | train_loss=0.0076 | val_f1=0.5582\n",
      "Segment-level -> acc=0.5702, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=0, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject22\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3991 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1130 | val_f1=0.5468\n",
      "  Epoch 10 | train_loss=0.0232 | val_f1=0.5790\n",
      "  Epoch 15 | train_loss=0.0124 | val_f1=0.5976\n",
      "Segment-level -> acc=0.3306, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject23\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4318 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0983 | val_f1=0.5154\n",
      "  Epoch 10 | train_loss=0.0381 | val_f1=0.4955\n",
      "Segment-level -> acc=0.9669, prec=1.0000, rec=0.9669, f1=0.9832\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject24\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4462 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1152 | val_f1=0.4388\n",
      "Segment-level -> acc=0.8595, prec=1.0000, rec=0.8595, f1=0.9244\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject25\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4291 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0967 | val_f1=0.6329\n",
      "  Epoch 10 | train_loss=0.0309 | val_f1=0.6316\n",
      "  Epoch 15 | train_loss=0.0316 | val_f1=0.6690\n",
      "  Epoch 20 | train_loss=0.0096 | val_f1=0.7435\n",
      "  Epoch 25 | train_loss=0.0090 | val_f1=0.7131\n",
      "Segment-level -> acc=0.4876, prec=1.0000, rec=0.4876, f1=0.6556\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject26\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4373 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0856 | val_f1=0.6083\n",
      "  Epoch 10 | train_loss=0.0189 | val_f1=0.5852\n",
      "Segment-level -> acc=0.8347, prec=1.0000, rec=0.8347, f1=0.9099\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject27\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4354 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1513 | val_f1=0.7714\n",
      "  Epoch 10 | train_loss=0.0208 | val_f1=0.8065\n",
      "  Epoch 15 | train_loss=0.0190 | val_f1=0.7937\n",
      "Segment-level -> acc=0.1240, prec=1.0000, rec=0.1240, f1=0.2206\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject28\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4312 | val_f1=0.0041\n",
      "  Epoch 05 | train_loss=0.1204 | val_f1=0.7070\n",
      "  Epoch 10 | train_loss=0.0573 | val_f1=0.6702\n",
      "  Epoch 15 | train_loss=0.0153 | val_f1=0.7541\n",
      "Segment-level -> acc=0.7769, prec=1.0000, rec=0.7769, f1=0.8744\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject29\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4412 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1276 | val_f1=0.7755\n",
      "  Epoch 10 | train_loss=0.0444 | val_f1=0.6576\n",
      "  Epoch 15 | train_loss=0.0140 | val_f1=0.7815\n",
      "Segment-level -> acc=0.9008, prec=1.0000, rec=0.9008, f1=0.9478\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject30\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Epoch 01 | train_loss=0.3982 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1131 | val_f1=0.6887\n",
      "  Epoch 10 | train_loss=0.0374 | val_f1=0.7042\n",
      "  Epoch 15 | train_loss=0.0179 | val_f1=0.8112\n",
      "  Epoch 20 | train_loss=0.0157 | val_f1=0.7779\n",
      "  Epoch 25 | train_loss=0.0078 | val_f1=0.7366\n",
      "Segment-level -> acc=0.2975, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject31\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4251 | val_f1=0.3488\n",
      "  Epoch 05 | train_loss=0.1097 | val_f1=0.5951\n",
      "  Epoch 10 | train_loss=0.0432 | val_f1=0.6454\n",
      "  Epoch 15 | train_loss=0.0153 | val_f1=0.7001\n",
      "Segment-level -> acc=0.7686, prec=1.0000, rec=0.7686, f1=0.8692\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject32\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4350 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1425 | val_f1=0.6597\n",
      "  Epoch 10 | train_loss=0.0410 | val_f1=0.7541\n",
      "  Epoch 15 | train_loss=0.0123 | val_f1=0.8290\n",
      "  Epoch 20 | train_loss=0.0185 | val_f1=0.8480\n",
      "  Epoch 25 | train_loss=0.0084 | val_f1=0.8303\n",
      "Segment-level -> acc=0.8760, prec=1.0000, rec=0.8760, f1=0.9339\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject33\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4355 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1103 | val_f1=0.6700\n",
      "  Epoch 10 | train_loss=0.0567 | val_f1=0.7001\n",
      "  Epoch 15 | train_loss=0.0152 | val_f1=0.7446\n",
      "  Epoch 20 | train_loss=0.0054 | val_f1=0.8197\n",
      "  Epoch 25 | train_loss=0.0048 | val_f1=0.7786\n",
      "Segment-level -> acc=0.9752, prec=1.0000, rec=0.9752, f1=0.9874\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject34\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4318 | val_f1=0.0164\n",
      "  Epoch 05 | train_loss=0.1281 | val_f1=0.6919\n",
      "  Epoch 10 | train_loss=0.0426 | val_f1=0.6836\n",
      "Segment-level -> acc=0.8430, prec=1.0000, rec=0.8430, f1=0.9148\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject35\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Epoch 01 | train_loss=0.4446 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1767 | val_f1=0.5743\n",
      "  Epoch 10 | train_loss=0.0625 | val_f1=0.7908\n",
      "  Epoch 15 | train_loss=0.0147 | val_f1=0.7086\n",
      "  Epoch 20 | train_loss=0.0051 | val_f1=0.8033\n",
      "Segment-level -> acc=0.8926, prec=1.0000, rec=0.8926, f1=0.9432\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Average SEGMENT-level (LOSO):\n",
      "Accuracy : 0.6281\n",
      "Precision: 0.7222\n",
      "Recall   : 0.5624\n",
      "F1-score : 0.6166\n",
      "\n",
      "============================================================\n",
      "Average SUBJECT-level (LOSO, majority vote):\n",
      "Accuracy : 0.6111\n",
      "Precision: 0.6111\n",
      "Recall   : 0.6111\n",
      "F1-score : 0.6111\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ======================\n",
    "# تنظیمات کلی\n",
    "# ======================\n",
    "DATA_FOLDER = \"/kaggle/input/ahmadi-dataset\"\n",
    "INFO_CSV = f\"{DATA_FOLDER}/subject-info.csv\"\n",
    "\n",
    "RESAMPLE_TO = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "WINDOW_SEC = 2.0\n",
    "OVERLAP_RATIO = 0.75\n",
    "\n",
    "USE_BASELINE = True\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "LR = 1e-3\n",
    "PATIENCE = 6\n",
    "\n",
    "# BiLSTM\n",
    "HIDDEN = 64\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# ======================\n",
    "# Seed\n",
    "# ======================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# لود داده + baseline correction\n",
    "# ======================\n",
    "def load_task_edf_with_baseline(folder_path, info_csv_path, resample_to=None,\n",
    "                                use_baseline=True):\n",
    "    folder = Path(folder_path)\n",
    "    if not folder.is_dir():\n",
    "        raise NotADirectoryError(f\"{folder_path} is not a valid directory\")\n",
    "\n",
    "    info_df = pd.read_csv(info_csv_path)\n",
    "    label_map = dict(zip(info_df[\"Subject\"], info_df[\"Count quality\"]))\n",
    "\n",
    "    X_list, y_list, subjects = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for subj_name in info_df[\"Subject\"]:\n",
    "        task_file = folder / f\"{subj_name}_2.edf\"\n",
    "        rest_file = folder / f\"{subj_name}_1.edf\"\n",
    "\n",
    "        if not task_file.is_file():\n",
    "            print(f\"Task file not found for {subj_name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if subj_name not in label_map:\n",
    "            print(f\"{subj_name} not in subject-info, skipping.\")\n",
    "            continue\n",
    "\n",
    "        raw_task = mne.io.read_raw_edf(task_file, preload=True, verbose=False)\n",
    "\n",
    "        raw_rest = None\n",
    "        if use_baseline and rest_file.is_file():\n",
    "            raw_rest = mne.io.read_raw_edf(rest_file, preload=True, verbose=False)\n",
    "\n",
    "        if resample_to is not None:\n",
    "            raw_task.resample(resample_to)\n",
    "            if raw_rest is not None:\n",
    "                raw_rest.resample(resample_to)\n",
    "\n",
    "        if sfreq is None:\n",
    "            sfreq = raw_task.info[\"sfreq\"]\n",
    "\n",
    "        task_data = raw_task.get_data()  # (C, T_task)\n",
    "\n",
    "        if use_baseline and raw_rest is not None:\n",
    "            rest_data = raw_rest.get_data()  # (C, T_rest)\n",
    "            baseline = rest_data.mean(axis=1, keepdims=True)\n",
    "            task_data = task_data - baseline\n",
    "\n",
    "        X_list.append(task_data)\n",
    "        y_list.append(int(label_map[subj_name]))\n",
    "        subjects.append(subj_name)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No files loaded. Check paths/names.\")\n",
    "\n",
    "    lengths = [d.shape[1] for d in X_list]\n",
    "    min_len = min(lengths)\n",
    "\n",
    "    X = np.stack([d[:, :min_len] for d in X_list], axis=0)  # (N, C, T)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    subjects = np.array(subjects)\n",
    "\n",
    "    print(\"X:\", X.shape, \"y:\", y.shape, \"sfreq:\", sfreq)\n",
    "    return X, y, subjects, sfreq\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Segment با overlap 75%\n",
    "# ======================\n",
    "def make_segments(X, y, subjects, sfreq, window_sec=2.0, overlap_ratio=0.75):\n",
    "    N, C, T = X.shape\n",
    "    win_size = int(window_sec * sfreq)          # 2s * 128 = 256\n",
    "    step_sec = window_sec * (1.0 - overlap_ratio)\n",
    "    step = max(1, int(step_sec * sfreq))        # 0.5s * 128 = 64\n",
    "\n",
    "    seg_X, seg_y, seg_subj = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        data = X[i]  # (C, T)\n",
    "        lab = y[i]\n",
    "        sid = subjects[i]\n",
    "\n",
    "        start = 0\n",
    "        while start + win_size <= T:\n",
    "            seg = data[:, start:start+win_size]  # (C, win)\n",
    "            seg_X.append(seg)\n",
    "            seg_y.append(lab)\n",
    "            seg_subj.append(sid)\n",
    "            start += step\n",
    "\n",
    "    seg_X = np.stack(seg_X, axis=0)  # (Nseg, C, win)\n",
    "    seg_y = np.array(seg_y, dtype=int)\n",
    "    seg_subj = np.array(seg_subj)\n",
    "\n",
    "    print(\"Segments:\", seg_X.shape)\n",
    "    return seg_X, seg_y, seg_subj\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Dataset + Augmentation (فقط train)\n",
    "# ======================\n",
    "class EEGSegDataset(Dataset):\n",
    "    def __init__(self, X_seq, y, augment=False):\n",
    "        \"\"\"\n",
    "        X_seq: (N, T, C) float32\n",
    "        y: (N,) int\n",
    "        \"\"\"\n",
    "        self.X = X_seq.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def _augment(self, x):\n",
    "        # x: (T, C)\n",
    "        # 1) noise\n",
    "        if np.random.rand() < 0.5:\n",
    "            noise = np.random.normal(0, 0.02, size=x.shape).astype(np.float32)\n",
    "            x = x + noise\n",
    "        # 2) channel-wise scale\n",
    "        if np.random.rand() < 0.5:\n",
    "            scale = (1.0 + np.random.normal(0, 0.05, size=(1, x.shape[1]))).astype(np.float32)\n",
    "            x = x * scale\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        if self.augment:\n",
    "            x = self._augment(x.copy())\n",
    "        y = self.y[idx]\n",
    "        return torch.from_numpy(x), torch.tensor(y)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# BiLSTM Model\n",
    "# ======================\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, n_channels, hidden=64, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_channels,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden * 2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        out, _ = self.lstm(x)       # (B, T, 2H)\n",
    "        out = out.mean(dim=1)       # mean pooling over time -> (B, 2H)\n",
    "        out = self.norm(out)\n",
    "        logits = self.fc(out).squeeze(1)  # (B,)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Utilities: normalization without leakage\n",
    "# ======================\n",
    "def compute_train_norm_stats(X_train_seq):\n",
    "    # X_train_seq: (N, T, C)\n",
    "    flat = X_train_seq.reshape(-1, X_train_seq.shape[-1])  # (N*T, C)\n",
    "    mean = flat.mean(axis=0, keepdims=True)\n",
    "    std = flat.std(axis=0, keepdims=True) + 1e-6\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def apply_norm(X_seq, mean, std):\n",
    "    return ((X_seq - mean) / std).astype(np.float32)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Train/Val split by SUBJECT (برای LOSO بهتر)\n",
    "# ======================\n",
    "def make_subject_val_split(train_subjects, val_ratio=0.15):\n",
    "    uniq = np.unique(train_subjects)\n",
    "    rng = np.random.RandomState(RANDOM_STATE)\n",
    "    rng.shuffle(uniq)\n",
    "    n_val = max(1, int(len(uniq) * val_ratio))\n",
    "    val_subj = set(uniq[:n_val])\n",
    "    val_mask = np.array([s in val_subj for s in train_subjects])\n",
    "    return val_mask\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Training loop with early stopping\n",
    "# ======================\n",
    "def train_one_fold(X_train, y_train, subj_train, n_channels):\n",
    "    # val split by subject\n",
    "    val_mask = make_subject_val_split(subj_train, val_ratio=0.15)\n",
    "    tr_mask = ~val_mask\n",
    "\n",
    "    X_tr, y_tr = X_train[tr_mask], y_train[tr_mask]\n",
    "    X_val, y_val = X_train[val_mask], y_train[val_mask]\n",
    "\n",
    "    # class imbalance handling\n",
    "    n_pos = (y_tr == 1).sum()\n",
    "    n_neg = (y_tr == 0).sum()\n",
    "    pos_weight = torch.tensor([n_neg / max(1, n_pos)], device=device, dtype=torch.float32)\n",
    "\n",
    "    # sampler (optional) - کمک می‌کند batchها متعادل‌تر شوند\n",
    "    weights = np.where(y_tr == 1, n_neg / max(1, n_pos), 1.0).astype(np.float32)\n",
    "    sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "    ds_tr = EEGSegDataset(X_tr, y_tr, augment=True)\n",
    "    ds_val = EEGSegDataset(X_val, y_val, augment=False)\n",
    "\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = BiLSTMClassifier(n_channels=n_channels, hidden=HIDDEN, num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_state = None\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        tr_losses = []\n",
    "\n",
    "        for xb, yb in dl_tr:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            tr_losses.append(loss.item())\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        all_pred, all_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_val:\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "                prob = torch.sigmoid(logits).cpu().numpy()\n",
    "                pred = (prob >= 0.5).astype(int)\n",
    "                all_pred.append(pred)\n",
    "                all_true.append(yb.numpy().astype(int))\n",
    "\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "        all_true = np.concatenate(all_true)\n",
    "\n",
    "        f1 = f1_score(all_true, all_pred, zero_division=0)\n",
    "        avg_loss = float(np.mean(tr_losses))\n",
    "\n",
    "        # print short progress\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f\"  Epoch {epoch:02d} | train_loss={avg_loss:.4f} | val_f1={f1:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    # load best\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# ======================\n",
    "# LOSO Evaluation\n",
    "# ======================\n",
    "def evaluate_loso_bilstm(seg_X, seg_y, seg_subjects):\n",
    "    # تبدیل به (N, T, C)\n",
    "    X_seq = np.transpose(seg_X, (0, 2, 1)).astype(np.float32)  # (Nseg, 256, 21)\n",
    "    y = seg_y.astype(int)\n",
    "    subjects = seg_subjects\n",
    "\n",
    "    uniq_subj = np.unique(subjects)\n",
    "    print(\"Unique subjects:\", len(uniq_subj))\n",
    "\n",
    "    seg_metrics = []\n",
    "    subj_metrics = []\n",
    "\n",
    "    for test_subj in uniq_subj:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Test subject:\", test_subj)\n",
    "\n",
    "        test_mask = (subjects == test_subj)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        X_train_raw = X_seq[train_mask]\n",
    "        y_train = y[train_mask]\n",
    "        subj_train = subjects[train_mask]\n",
    "\n",
    "        X_test_raw = X_seq[test_mask]\n",
    "        y_test = y[test_mask]\n",
    "\n",
    "        # normalization from TRAIN only (NO leakage)\n",
    "        mean, std = compute_train_norm_stats(X_train_raw)\n",
    "        X_train = apply_norm(X_train_raw, mean, std)\n",
    "        X_test  = apply_norm(X_test_raw,  mean, std)\n",
    "\n",
    "        print(\"Train seg:\", X_train.shape[0], \"| Test seg:\", X_test.shape[0],\n",
    "              \"| Train dist:\", np.bincount(y_train))\n",
    "\n",
    "        # train\n",
    "        model = train_one_fold(X_train, y_train, subj_train, n_channels=X_train.shape[-1])\n",
    "\n",
    "        # predict test\n",
    "        with torch.no_grad():\n",
    "            xb = torch.from_numpy(X_test).to(device)\n",
    "            logits = model(xb).cpu().numpy()\n",
    "            prob = 1.0 / (1.0 + np.exp(-logits))\n",
    "            y_pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "        # segment-level metrics (برای باینری)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        print(f\"Segment-level -> acc={acc:.4f}, prec={prec:.4f}, rec={rec:.4f}, f1={f1:.4f}\")\n",
    "        seg_metrics.append([acc, prec, rec, f1])\n",
    "\n",
    "        # subject-level majority vote\n",
    "        true_label = int(y_test[0])\n",
    "        pred_label = int(np.argmax(np.bincount(y_pred)))\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level -> true={true_label}, pred={pred_label}, acc={acc_subj:.4f}\")\n",
    "        subj_metrics.append([acc_subj, acc_subj, acc_subj, acc_subj])\n",
    "\n",
    "    seg_metrics = np.array(seg_metrics)\n",
    "    subj_metrics = np.array(subj_metrics)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Average SEGMENT-level (LOSO):\")\n",
    "    print(f\"Accuracy : {seg_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {seg_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {seg_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {seg_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Average SUBJECT-level (LOSO, majority vote):\")\n",
    "    print(f\"Accuracy : {subj_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {subj_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {subj_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {subj_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# main\n",
    "# ======================\n",
    "def main():\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline(\n",
    "        DATA_FOLDER, INFO_CSV,\n",
    "        resample_to=RESAMPLE_TO,\n",
    "        use_baseline=USE_BASELINE\n",
    "    )\n",
    "\n",
    "    seg_X, seg_y, seg_subjects = make_segments(\n",
    "        X, y, subjects, sfreq,\n",
    "        window_sec=WINDOW_SEC,\n",
    "        overlap_ratio=OVERLAP_RATIO\n",
    "    )\n",
    "\n",
    "    evaluate_loso_bilstm(seg_X, seg_y, seg_subjects)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "280d7a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T09:58:55.466375Z",
     "iopub.status.busy": "2025-12-12T09:58:55.465802Z",
     "iopub.status.idle": "2025-12-12T10:07:00.859514Z",
     "shell.execute_reply": "2025-12-12T10:07:00.858656Z"
    },
    "papermill": {
     "duration": 485.469341,
     "end_time": "2025-12-12T10:07:00.860752",
     "exception": false,
     "start_time": "2025-12-12T09:58:55.391411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "X: (36, 21, 7936) y: (36,) sfreq: 128.0\n",
      "Segments: (4356, 21, 256)\n",
      "Unique subjects: 36\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject00\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject23', 'Subject25'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4109 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1372 | val_f1=0.8692\n",
      "Segment-level -> acc=0.0496, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject01\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject15', 'Subject20'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4500 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1340 | val_f1=0.8108\n",
      "  Epoch 10 | train_loss=0.0377 | val_f1=0.7809\n",
      "Segment-level -> acc=0.9587, prec=1.0000, rec=0.9587, f1=0.9789\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject02\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject29', 'Subject32'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4457 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1443 | val_f1=0.6848\n",
      "Segment-level -> acc=1.0000, prec=1.0000, rec=1.0000, f1=1.0000\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject03\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject12'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4457 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1586 | val_f1=0.8195\n",
      "  Epoch 10 | train_loss=0.0458 | val_f1=0.8504\n",
      "  Epoch 15 | train_loss=0.0510 | val_f1=0.7621\n",
      "Segment-level -> acc=0.9752, prec=1.0000, rec=0.9752, f1=0.9874\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject04\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject16', 'Subject27'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4093 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0989 | val_f1=0.0717\n",
      "Segment-level -> acc=0.2149, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject05\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject09', 'Subject13'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4041 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1329 | val_f1=0.4106\n",
      "  Epoch 10 | train_loss=0.0315 | val_f1=0.5732\n",
      "  Epoch 15 | train_loss=0.0177 | val_f1=0.5697\n",
      "Segment-level -> acc=0.8430, prec=1.0000, rec=0.8430, f1=0.9148\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject06\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject15', 'Subject21'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.3739 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1068 | val_f1=0.3059\n",
      "  Epoch 10 | train_loss=0.0284 | val_f1=0.3950\n",
      "  Epoch 15 | train_loss=0.0082 | val_f1=0.5643\n",
      "  Epoch 20 | train_loss=0.0108 | val_f1=0.6007\n",
      "  Epoch 25 | train_loss=0.0128 | val_f1=0.5000\n",
      "Segment-level -> acc=0.2562, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject07\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject10', 'Subject24'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4079 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1014 | val_f1=0.5904\n",
      "Segment-level -> acc=0.4215, prec=1.0000, rec=0.4215, f1=0.5930\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject08\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject12', 'Subject32'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4436 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1087 | val_f1=0.6092\n",
      "Segment-level -> acc=0.5124, prec=1.0000, rec=0.5124, f1=0.6776\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject09\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject07', 'Subject10'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.3828 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1299 | val_f1=0.4075\n",
      "  Epoch 10 | train_loss=0.0372 | val_f1=0.6286\n",
      "  Epoch 15 | train_loss=0.0108 | val_f1=0.6199\n",
      "Segment-level -> acc=0.0496, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject10\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject08', 'Subject16'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4130 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0894 | val_f1=0.9455\n",
      "  Epoch 10 | train_loss=0.0513 | val_f1=0.9896\n",
      "  Epoch 15 | train_loss=0.0298 | val_f1=0.9316\n",
      "  Epoch 20 | train_loss=0.0179 | val_f1=0.9268\n",
      "  Epoch 25 | train_loss=0.0021 | val_f1=0.9702\n",
      "Segment-level -> acc=0.0165, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject11\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject35'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4476 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1405 | val_f1=0.9702\n",
      "  Epoch 10 | train_loss=0.0530 | val_f1=0.9099\n",
      "  Epoch 15 | train_loss=0.0192 | val_f1=0.8665\n",
      "Segment-level -> acc=0.9587, prec=1.0000, rec=0.9587, f1=0.9789\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject12\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject08', 'Subject22'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4035 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1026 | val_f1=0.7863\n",
      "  Epoch 10 | train_loss=0.0444 | val_f1=0.7747\n",
      "  Epoch 15 | train_loss=0.0143 | val_f1=0.7681\n",
      "Segment-level -> acc=0.3388, prec=1.0000, rec=0.3388, f1=0.5062\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject13\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject21', 'Subject26'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4075 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1008 | val_f1=0.6111\n",
      "  Epoch 10 | train_loss=0.0326 | val_f1=0.7448\n",
      "  Epoch 15 | train_loss=0.0162 | val_f1=0.8066\n",
      "Segment-level -> acc=0.5868, prec=1.0000, rec=0.5868, f1=0.7396\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject14\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject12', 'Subject32'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4102 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0959 | val_f1=0.6328\n",
      "  Epoch 10 | train_loss=0.0398 | val_f1=0.1736\n",
      "Segment-level -> acc=0.4711, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject15\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject14', 'Subject23'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4091 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1474 | val_f1=0.6971\n",
      "  Epoch 10 | train_loss=0.0288 | val_f1=0.7893\n",
      "  Epoch 15 | train_loss=0.0139 | val_f1=0.8061\n",
      "Segment-level -> acc=0.5868, prec=1.0000, rec=0.5868, f1=0.7396\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject16\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject18'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4415 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1490 | val_f1=0.6919\n",
      "  Epoch 10 | train_loss=0.0430 | val_f1=0.7230\n",
      "Segment-level -> acc=0.9421, prec=1.0000, rec=0.9421, f1=0.9702\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject17\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject03', 'Subject04'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4000 | val_f1=0.1611\n",
      "  Epoch 05 | train_loss=0.1429 | val_f1=0.7692\n",
      "Segment-level -> acc=0.1157, prec=1.0000, rec=0.1157, f1=0.2074\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject18\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject03', 'Subject22'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4147 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1298 | val_f1=0.8015\n",
      "Segment-level -> acc=0.1322, prec=1.0000, rec=0.1322, f1=0.2336\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject19\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject03', 'Subject26'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4100 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1077 | val_f1=0.9316\n",
      "  Epoch 10 | train_loss=0.0186 | val_f1=0.8796\n",
      "Segment-level -> acc=0.1322, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject20\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject08', 'Subject29'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4358 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1285 | val_f1=0.9268\n",
      "  Epoch 10 | train_loss=0.0463 | val_f1=0.9789\n",
      "  Epoch 15 | train_loss=0.0552 | val_f1=0.9938\n",
      "  Epoch 20 | train_loss=0.0120 | val_f1=0.9874\n",
      "Segment-level -> acc=1.0000, prec=1.0000, rec=1.0000, f1=1.0000\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject21\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject15', 'Subject27'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4017 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0981 | val_f1=0.4286\n",
      "  Epoch 10 | train_loss=0.0410 | val_f1=0.5848\n",
      "  Epoch 15 | train_loss=0.0119 | val_f1=0.6132\n",
      "Segment-level -> acc=0.5785, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=0, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject22\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject17', 'Subject21'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.3762 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1522 | val_f1=0.5698\n",
      "  Epoch 10 | train_loss=0.0299 | val_f1=0.7055\n",
      "  Epoch 15 | train_loss=0.0066 | val_f1=0.7128\n",
      "  Epoch 20 | train_loss=0.0180 | val_f1=0.7517\n",
      "  Epoch 25 | train_loss=0.0051 | val_f1=0.6558\n",
      "Segment-level -> acc=0.5207, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=0, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject23\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject33'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4565 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1666 | val_f1=0.9614\n",
      "  Epoch 10 | train_loss=0.0699 | val_f1=0.9767\n",
      "Segment-level -> acc=0.9669, prec=1.0000, rec=0.9669, f1=0.9832\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject24\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject31', 'Subject35'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4433 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1259 | val_f1=0.7297\n",
      "  Epoch 10 | train_loss=0.0610 | val_f1=0.9148\n",
      "  Epoch 15 | train_loss=0.0128 | val_f1=0.8638\n",
      "Segment-level -> acc=0.9091, prec=1.0000, rec=0.9091, f1=0.9524\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject25\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject32', 'Subject33'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4376 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1145 | val_f1=0.5765\n",
      "  Epoch 10 | train_loss=0.0485 | val_f1=0.8638\n",
      "  Epoch 15 | train_loss=0.0130 | val_f1=0.8899\n",
      "  Epoch 20 | train_loss=0.0219 | val_f1=0.9196\n",
      "Segment-level -> acc=0.5620, prec=1.0000, rec=0.5620, f1=0.7196\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject26\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject05', 'Subject17'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4319 | val_f1=0.0082\n",
      "  Epoch 05 | train_loss=0.1151 | val_f1=0.7461\n",
      "  Epoch 10 | train_loss=0.0391 | val_f1=0.8796\n",
      "  Epoch 15 | train_loss=0.0136 | val_f1=0.8950\n",
      "Segment-level -> acc=0.8843, prec=1.0000, rec=0.8843, f1=0.9386\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject27\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject03', 'Subject15'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4472 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0973 | val_f1=0.9292\n",
      "  Epoch 10 | train_loss=0.0310 | val_f1=0.9591\n",
      "  Epoch 15 | train_loss=0.0285 | val_f1=0.9244\n",
      "  Epoch 20 | train_loss=0.0091 | val_f1=0.9268\n",
      "Segment-level -> acc=0.0331, prec=1.0000, rec=0.0331, f1=0.0640\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject28\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject17', 'Subject26'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4417 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1309 | val_f1=0.9099\n",
      "  Epoch 10 | train_loss=0.0382 | val_f1=0.9680\n",
      "  Epoch 15 | train_loss=0.0151 | val_f1=0.9025\n",
      "Segment-level -> acc=0.9835, prec=1.0000, rec=0.9835, f1=0.9917\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject29\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject04', 'Subject22'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.3777 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1054 | val_f1=0.0000\n",
      "Segment-level -> acc=0.0000, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject30\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject09', 'Subject12'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.3632 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0964 | val_f1=0.4952\n",
      "  Epoch 10 | train_loss=0.0323 | val_f1=0.3472\n",
      "  Epoch 15 | train_loss=0.0232 | val_f1=0.4306\n",
      "Segment-level -> acc=0.0661, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject31\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject29', 'Subject33'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4447 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1259 | val_f1=0.9124\n",
      "  Epoch 10 | train_loss=0.0379 | val_f1=0.9546\n",
      "  Epoch 15 | train_loss=0.0345 | val_f1=0.9074\n",
      "  Epoch 20 | train_loss=0.0141 | val_f1=0.9546\n",
      "Segment-level -> acc=0.8099, prec=1.0000, rec=0.8099, f1=0.8950\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject32\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject06', 'Subject13'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4101 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1137 | val_f1=0.4601\n",
      "  Epoch 10 | train_loss=0.0370 | val_f1=0.5935\n",
      "Segment-level -> acc=0.9008, prec=1.0000, rec=0.9008, f1=0.9478\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject33\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject20', 'Subject35'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4477 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1770 | val_f1=0.8449\n",
      "  Epoch 10 | train_loss=0.1255 | val_f1=0.9099\n",
      "  Epoch 15 | train_loss=0.0192 | val_f1=0.9316\n",
      "Segment-level -> acc=0.9917, prec=1.0000, rec=0.9917, f1=0.9959\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject34\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject20', 'Subject32'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4465 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1246 | val_f1=0.8692\n",
      "  Epoch 10 | train_loss=0.0463 | val_f1=0.8665\n",
      "Segment-level -> acc=0.6612, prec=1.0000, rec=0.6612, f1=0.7960\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject35\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject33'] | noisy_val=True\n",
      "  Epoch 01 | train_loss=0.4423 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1342 | val_f1=0.8848\n",
      "  Epoch 10 | train_loss=0.0445 | val_f1=0.9636\n",
      "  Epoch 15 | train_loss=0.0201 | val_f1=0.9832\n",
      "  Epoch 20 | train_loss=0.0217 | val_f1=0.9148\n",
      "Segment-level -> acc=0.9091, prec=1.0000, rec=0.9091, f1=0.9524\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Average SEGMENT-level (LOSO):\n",
      "Accuracy : 0.5650\n",
      "Precision: 0.6944\n",
      "Recall   : 0.4995\n",
      "F1-score : 0.5490\n",
      "\n",
      "============================================================\n",
      "Average SUBJECT-level (LOSO, majority vote):\n",
      "Accuracy : 0.6111\n",
      "Precision: 0.6111\n",
      "Recall   : 0.6111\n",
      "F1-score : 0.6111\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ======================\n",
    "# تنظیمات کلی\n",
    "# ======================\n",
    "DATA_FOLDER = \"/kaggle/input/ahmadi-dataset\"\n",
    "INFO_CSV = f\"{DATA_FOLDER}/subject-info.csv\"\n",
    "\n",
    "RESAMPLE_TO = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "WINDOW_SEC = 2.0\n",
    "OVERLAP_RATIO = 0.75\n",
    "\n",
    "USE_BASELINE = True\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "LR = 1e-3\n",
    "PATIENCE = 6\n",
    "\n",
    "# BiLSTM\n",
    "HIDDEN = 64\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# --- Validation by SUBJECT\n",
    "VAL_SUBJECT_COUNT = 2          # دقیقاً 2 سابجکت برای ولید (از trainها)\n",
    "NOISY_VALIDATION = True       # حالت 2: ولید نویزی\n",
    "VAL_NOISE_STD = 0.05           # شدت نویز برای ولید (اگر NOISY_VALIDATION=True)\n",
    "VAL_SCALE_STD = 0.08           # شدت scale-jitter برای ولید نویزی (اختیاری)\n",
    "\n",
    "# ======================\n",
    "# Seed\n",
    "# ======================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# لود داده + baseline correction\n",
    "# ======================\n",
    "def load_task_edf_with_baseline(folder_path, info_csv_path, resample_to=None,\n",
    "                                use_baseline=True):\n",
    "    folder = Path(folder_path)\n",
    "    if not folder.is_dir():\n",
    "        raise NotADirectoryError(f\"{folder_path} is not a valid directory\")\n",
    "\n",
    "    info_df = pd.read_csv(info_csv_path)\n",
    "    label_map = dict(zip(info_df[\"Subject\"], info_df[\"Count quality\"]))\n",
    "\n",
    "    X_list, y_list, subjects = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for subj_name in info_df[\"Subject\"]:\n",
    "        task_file = folder / f\"{subj_name}_2.edf\"\n",
    "        rest_file = folder / f\"{subj_name}_1.edf\"\n",
    "\n",
    "        if not task_file.is_file():\n",
    "            print(f\"Task file not found for {subj_name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        raw_task = mne.io.read_raw_edf(task_file, preload=True, verbose=False)\n",
    "\n",
    "        raw_rest = None\n",
    "        if use_baseline and rest_file.is_file():\n",
    "            raw_rest = mne.io.read_raw_edf(rest_file, preload=True, verbose=False)\n",
    "\n",
    "        if resample_to is not None:\n",
    "            raw_task.resample(resample_to)\n",
    "            if raw_rest is not None:\n",
    "                raw_rest.resample(resample_to)\n",
    "\n",
    "        if sfreq is None:\n",
    "            sfreq = raw_task.info[\"sfreq\"]\n",
    "\n",
    "        task_data = raw_task.get_data()  # (C, T_task)\n",
    "\n",
    "        if use_baseline and raw_rest is not None:\n",
    "            rest_data = raw_rest.get_data()  # (C, T_rest)\n",
    "            baseline = rest_data.mean(axis=1, keepdims=True)\n",
    "            task_data = task_data - baseline\n",
    "\n",
    "        X_list.append(task_data)\n",
    "        y_list.append(int(label_map[subj_name]))\n",
    "        subjects.append(subj_name)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No files loaded. Check paths/names.\")\n",
    "\n",
    "    lengths = [d.shape[1] for d in X_list]\n",
    "    min_len = min(lengths)\n",
    "\n",
    "    X = np.stack([d[:, :min_len] for d in X_list], axis=0)  # (N, C, T)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    subjects = np.array(subjects)\n",
    "\n",
    "    print(\"X:\", X.shape, \"y:\", y.shape, \"sfreq:\", sfreq)\n",
    "    return X, y, subjects, sfreq\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Segment با overlap 75%\n",
    "# ======================\n",
    "def make_segments(X, y, subjects, sfreq, window_sec=2.0, overlap_ratio=0.75):\n",
    "    N, C, T = X.shape\n",
    "    win_size = int(window_sec * sfreq)          # 256\n",
    "    step_sec = window_sec * (1.0 - overlap_ratio)\n",
    "    step = max(1, int(step_sec * sfreq))        # 64\n",
    "\n",
    "    seg_X, seg_y, seg_subj = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        data = X[i]  # (C, T)\n",
    "        lab = y[i]\n",
    "        sid = subjects[i]\n",
    "\n",
    "        start = 0\n",
    "        while start + win_size <= T:\n",
    "            seg = data[:, start:start+win_size]  # (C, win)\n",
    "            seg_X.append(seg)\n",
    "            seg_y.append(lab)\n",
    "            seg_subj.append(sid)\n",
    "            start += step\n",
    "\n",
    "    seg_X = np.stack(seg_X, axis=0)  # (Nseg, C, win)\n",
    "    seg_y = np.array(seg_y, dtype=int)\n",
    "    seg_subj = np.array(seg_subj)\n",
    "\n",
    "    print(\"Segments:\", seg_X.shape)\n",
    "    return seg_X, seg_y, seg_subj\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Dataset + Augmentation\n",
    "# ======================\n",
    "class EEGSegDataset(Dataset):\n",
    "    def __init__(self, X_seq, y, do_noise=False, do_scale=False,\n",
    "                 noise_std=0.02, scale_std=0.05):\n",
    "        \"\"\"\n",
    "        X_seq: (N, T, C) float32\n",
    "        y: (N,) int/float\n",
    "        \"\"\"\n",
    "        self.X = X_seq.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "\n",
    "        self.do_noise = do_noise\n",
    "        self.do_scale = do_scale\n",
    "        self.noise_std = float(noise_std)\n",
    "        self.scale_std = float(scale_std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def _augment(self, x):\n",
    "        # x: (T, C)\n",
    "        if self.do_noise:\n",
    "            noise = np.random.normal(0, self.noise_std, size=x.shape).astype(np.float32)\n",
    "            x = x + noise\n",
    "        if self.do_scale:\n",
    "            scale = (1.0 + np.random.normal(0, self.scale_std, size=(1, x.shape[1]))).astype(np.float32)\n",
    "            x = x * scale\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        if self.do_noise or self.do_scale:\n",
    "            x = self._augment(x.copy())\n",
    "        y = self.y[idx]\n",
    "        return torch.from_numpy(x), torch.tensor(y)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# BiLSTM Model\n",
    "# ======================\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, n_channels, hidden=64, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_channels,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden * 2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        out, _ = self.lstm(x)       # (B, T, 2H)\n",
    "        out = out.mean(dim=1)       # mean pooling over time -> (B, 2H)\n",
    "        out = self.norm(out)\n",
    "        logits = self.fc(out).squeeze(1)  # (B,)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Normalization without leakage\n",
    "# ======================\n",
    "def compute_train_norm_stats(X_train_seq):\n",
    "    flat = X_train_seq.reshape(-1, X_train_seq.shape[-1])  # (N*T, C)\n",
    "    mean = flat.mean(axis=0, keepdims=True)\n",
    "    std = flat.std(axis=0, keepdims=True) + 1e-6\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def apply_norm(X_seq, mean, std):\n",
    "    return ((X_seq - mean) / std).astype(np.float32)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Val split: دقیقاً K سابجکت رندوم از train\n",
    "# ======================\n",
    "def make_subject_val_split_exact_k(train_subjects, k=2, seed=42):\n",
    "    uniq = np.unique(train_subjects)\n",
    "    if len(uniq) <= k:\n",
    "        # اگر تعداد سابجکت‌های train کم بود، مجبوریم 1 تا ولید کنیم\n",
    "        k = max(1, len(uniq) - 1)\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    rng.shuffle(uniq)\n",
    "    val_subj = set(uniq[:k])\n",
    "    val_mask = np.array([s in val_subj for s in train_subjects])\n",
    "    return val_mask, val_subj\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Train with early stopping\n",
    "# ======================\n",
    "def train_one_fold(X_train, y_train, subj_train, n_channels, fold_seed,\n",
    "                   noisy_validation=False):\n",
    "    # validation: 2 subject random\n",
    "    val_mask, val_subj = make_subject_val_split_exact_k(\n",
    "        subj_train, k=VAL_SUBJECT_COUNT, seed=fold_seed\n",
    "    )\n",
    "    tr_mask = ~val_mask\n",
    "\n",
    "    X_tr, y_tr = X_train[tr_mask], y_train[tr_mask]\n",
    "    X_val, y_val = X_train[val_mask], y_train[val_mask]\n",
    "\n",
    "    # class imbalance\n",
    "    n_pos = int((y_tr == 1).sum())\n",
    "    n_neg = int((y_tr == 0).sum())\n",
    "    pos_weight = torch.tensor([n_neg / max(1, n_pos)], device=device, dtype=torch.float32)\n",
    "\n",
    "    # sampler (balanced batches)\n",
    "    weights = np.where(y_tr == 1, n_neg / max(1, n_pos), 1.0).astype(np.float32)\n",
    "    sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "    # Train augmentation (معمولاً مفید برای LOSO)\n",
    "    ds_tr = EEGSegDataset(\n",
    "        X_tr, y_tr,\n",
    "        do_noise=True, do_scale=True,\n",
    "        noise_std=0.02, scale_std=0.05\n",
    "    )\n",
    "\n",
    "    # Validation:\n",
    "    # - حالت معمول: بدون augmentation\n",
    "    # - حالت نویزی: عمداً ولید را نویزی می‌کنیم\n",
    "    if noisy_validation:\n",
    "        ds_val = EEGSegDataset(\n",
    "            X_val, y_val,\n",
    "            do_noise=True, do_scale=True,\n",
    "            noise_std=VAL_NOISE_STD, scale_std=VAL_SCALE_STD\n",
    "        )\n",
    "    else:\n",
    "        ds_val = EEGSegDataset(X_val, y_val, do_noise=False, do_scale=False)\n",
    "\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = BiLSTMClassifier(\n",
    "        n_channels=n_channels, hidden=HIDDEN, num_layers=NUM_LAYERS, dropout=DROPOUT\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_state = None\n",
    "    patience = 0\n",
    "\n",
    "    print(f\"  Validation subjects: {sorted(list(val_subj))} | noisy_val={noisy_validation}\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        tr_losses = []\n",
    "\n",
    "        for xb, yb in dl_tr:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            tr_losses.append(loss.item())\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        all_pred, all_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_val:\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "                prob = torch.sigmoid(logits).cpu().numpy()\n",
    "                pred = (prob >= 0.5).astype(int)\n",
    "                all_pred.append(pred)\n",
    "                all_true.append(yb.numpy().astype(int))\n",
    "\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "        all_true = np.concatenate(all_true)\n",
    "\n",
    "        f1 = f1_score(all_true, all_pred, zero_division=0)\n",
    "        avg_loss = float(np.mean(tr_losses))\n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f\"  Epoch {epoch:02d} | train_loss={avg_loss:.4f} | val_f1={f1:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# ======================\n",
    "# LOSO Evaluation\n",
    "# ======================\n",
    "def evaluate_loso_bilstm(seg_X, seg_y, seg_subjects, noisy_validation=False):\n",
    "    # (N, C, T) -> (N, T, C)\n",
    "    X_seq = np.transpose(seg_X, (0, 2, 1)).astype(np.float32)  # (Nseg, 256, 21)\n",
    "    y = seg_y.astype(int)\n",
    "    subjects = seg_subjects\n",
    "\n",
    "    uniq_subj = np.unique(subjects)\n",
    "    print(\"Unique subjects:\", len(uniq_subj))\n",
    "\n",
    "    seg_metrics = []\n",
    "    subj_metrics = []\n",
    "\n",
    "    for test_subj in uniq_subj:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Test subject:\", test_subj)\n",
    "\n",
    "        test_mask = (subjects == test_subj)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        X_train_raw = X_seq[train_mask]\n",
    "        y_train = y[train_mask]\n",
    "        subj_train = subjects[train_mask]\n",
    "\n",
    "        X_test_raw = X_seq[test_mask]\n",
    "        y_test = y[test_mask]\n",
    "\n",
    "        # normalization from TRAIN only\n",
    "        mean, std = compute_train_norm_stats(X_train_raw)\n",
    "        X_train = apply_norm(X_train_raw, mean, std)\n",
    "        X_test  = apply_norm(X_test_raw,  mean, std)\n",
    "\n",
    "        print(\"Train seg:\", X_train.shape[0], \"| Test seg:\", X_test.shape[0],\n",
    "              \"| Train dist:\", np.bincount(y_train))\n",
    "\n",
    "        # fold-specific seed (برای اینکه انتخاب 2 سابجکت ولید هر fold رندوم ولی reproducible باشد)\n",
    "        # SubjectXX -> XX\n",
    "        try:\n",
    "            sid_num = int(str(test_subj).replace(\"Subject\", \"\"))\n",
    "        except:\n",
    "            sid_num = 0\n",
    "        fold_seed = RANDOM_STATE + 1000 + sid_num\n",
    "\n",
    "        model = train_one_fold(\n",
    "            X_train, y_train, subj_train,\n",
    "            n_channels=X_train.shape[-1],\n",
    "            fold_seed=fold_seed,\n",
    "            noisy_validation=noisy_validation\n",
    "        )\n",
    "\n",
    "        # predict test\n",
    "        with torch.no_grad():\n",
    "            xb = torch.from_numpy(X_test).to(device)\n",
    "            logits = model(xb).cpu().numpy()\n",
    "            prob = 1.0 / (1.0 + np.exp(-logits))\n",
    "            y_pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "        # segment-level metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        print(f\"Segment-level -> acc={acc:.4f}, prec={prec:.4f}, rec={rec:.4f}, f1={f1:.4f}\")\n",
    "        seg_metrics.append([acc, prec, rec, f1])\n",
    "\n",
    "        # subject-level majority vote\n",
    "        true_label = int(y_test[0])\n",
    "        pred_label = int(np.argmax(np.bincount(y_pred)))\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level -> true={true_label}, pred={pred_label}, acc={acc_subj:.4f}\")\n",
    "        subj_metrics.append([acc_subj, acc_subj, acc_subj, acc_subj])\n",
    "\n",
    "    seg_metrics = np.array(seg_metrics)\n",
    "    subj_metrics = np.array(subj_metrics)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Average SEGMENT-level (LOSO):\")\n",
    "    print(f\"Accuracy : {seg_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {seg_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {seg_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {seg_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Average SUBJECT-level (LOSO, majority vote):\")\n",
    "    print(f\"Accuracy : {subj_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {subj_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {subj_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {subj_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# main\n",
    "# ======================\n",
    "def main():\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline(\n",
    "        DATA_FOLDER, INFO_CSV,\n",
    "        resample_to=RESAMPLE_TO,\n",
    "        use_baseline=USE_BASELINE\n",
    "    )\n",
    "\n",
    "    seg_X, seg_y, seg_subjects = make_segments(\n",
    "        X, y, subjects, sfreq,\n",
    "        window_sec=WINDOW_SEC,\n",
    "        overlap_ratio=OVERLAP_RATIO\n",
    "    )\n",
    "\n",
    "    evaluate_loso_bilstm(seg_X, seg_y, seg_subjects, noisy_validation=NOISY_VALIDATION)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107d3b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T10:07:01.043163Z",
     "iopub.status.busy": "2025-12-12T10:07:01.042660Z",
     "iopub.status.idle": "2025-12-12T10:14:29.766408Z",
     "shell.execute_reply": "2025-12-12T10:14:29.765407Z"
    },
    "papermill": {
     "duration": 448.820266,
     "end_time": "2025-12-12T10:14:29.767837",
     "exception": false,
     "start_time": "2025-12-12T10:07:00.947571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "X: (36, 21, 7936) y: (36,) sfreq: 128.0\n",
      "Segments: (4356, 21, 256)\n",
      "Unique subjects: 36\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject00\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject08', 'Subject16', 'Subject23', 'Subject25'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4301 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1073 | val_f1=0.8064\n",
      "  Epoch 10 | train_loss=0.0875 | val_f1=0.7461\n",
      "  Epoch 15 | train_loss=0.0081 | val_f1=0.8962\n",
      "Segment-level -> acc=0.0083, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject01\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject02', 'Subject15', 'Subject20', 'Subject23'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4752 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.2092 | val_f1=0.8705\n",
      "  Epoch 10 | train_loss=0.0519 | val_f1=0.8822\n",
      "Segment-level -> acc=0.9835, prec=1.0000, rec=0.9835, f1=0.9917\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject02\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject18', 'Subject27', 'Subject29', 'Subject32'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4704 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1299 | val_f1=0.5062\n",
      "Segment-level -> acc=0.9917, prec=1.0000, rec=0.9917, f1=0.9959\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject03\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject12', 'Subject20', 'Subject21'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4239 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1256 | val_f1=0.7564\n",
      "  Epoch 10 | train_loss=0.0550 | val_f1=0.8882\n",
      "  Epoch 15 | train_loss=0.0323 | val_f1=0.9135\n",
      "  Epoch 20 | train_loss=0.0086 | val_f1=0.9042\n",
      "Segment-level -> acc=0.9339, prec=1.0000, rec=0.9339, f1=0.9658\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject04\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject14', 'Subject16', 'Subject27', 'Subject31'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3839 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0661 | val_f1=0.1721\n",
      "  Epoch 10 | train_loss=0.0226 | val_f1=0.4538\n",
      "  Epoch 15 | train_loss=0.0083 | val_f1=0.3275\n",
      "Segment-level -> acc=0.0579, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject05\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject09', 'Subject13', 'Subject16', 'Subject17'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4256 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1711 | val_f1=0.7619\n",
      "  Epoch 10 | train_loss=0.0335 | val_f1=0.6533\n",
      "  Epoch 15 | train_loss=0.0124 | val_f1=0.7907\n",
      "Segment-level -> acc=0.9421, prec=1.0000, rec=0.9421, f1=0.9702\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject06\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject08', 'Subject15', 'Subject21', 'Subject22'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3465 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0932 | val_f1=0.4402\n",
      "  Epoch 10 | train_loss=0.0605 | val_f1=0.5638\n",
      "  Epoch 15 | train_loss=0.0150 | val_f1=0.6217\n",
      "Segment-level -> acc=0.1240, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject07\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject05', 'Subject06', 'Subject10', 'Subject24'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3880 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0889 | val_f1=0.6181\n",
      "  Epoch 10 | train_loss=0.0609 | val_f1=0.6705\n",
      "  Epoch 15 | train_loss=0.0184 | val_f1=0.6607\n",
      "Segment-level -> acc=0.7686, prec=1.0000, rec=0.7686, f1=0.8692\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject08\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject11', 'Subject12', 'Subject29', 'Subject32'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4733 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1182 | val_f1=0.7145\n",
      "Segment-level -> acc=0.0661, prec=1.0000, rec=0.0661, f1=0.1240\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject09\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject06', 'Subject07', 'Subject10', 'Subject18'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3389 | val_f1=0.0081\n",
      "  Epoch 05 | train_loss=0.0676 | val_f1=0.6494\n",
      "Segment-level -> acc=0.0992, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject10\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject08', 'Subject16', 'Subject17', 'Subject31'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4262 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0962 | val_f1=0.9478\n",
      "  Epoch 10 | train_loss=0.0246 | val_f1=0.9304\n",
      "Segment-level -> acc=0.0579, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject11\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject10', 'Subject26', 'Subject35'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4221 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0977 | val_f1=0.7899\n",
      "  Epoch 10 | train_loss=0.0337 | val_f1=0.7402\n",
      "  Epoch 15 | train_loss=0.0215 | val_f1=0.7663\n",
      "Segment-level -> acc=1.0000, prec=1.0000, rec=1.0000, f1=1.0000\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject12\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject08', 'Subject14', 'Subject22', 'Subject31'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3929 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1644 | val_f1=0.6038\n",
      "  Epoch 10 | train_loss=0.0398 | val_f1=0.6677\n",
      "Segment-level -> acc=0.4876, prec=1.0000, rec=0.4876, f1=0.6556\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject13\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject00', 'Subject17', 'Subject21', 'Subject26'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3875 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0989 | val_f1=0.6679\n",
      "  Epoch 10 | train_loss=0.0251 | val_f1=0.6198\n",
      "  Epoch 15 | train_loss=0.0091 | val_f1=0.6565\n",
      "Segment-level -> acc=0.6694, prec=1.0000, rec=0.6694, f1=0.8020\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject14\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject09', 'Subject12', 'Subject29', 'Subject32'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3977 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1353 | val_f1=0.4182\n",
      "  Epoch 10 | train_loss=0.0355 | val_f1=0.6451\n",
      "Segment-level -> acc=0.1736, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject15\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject14', 'Subject22', 'Subject23', 'Subject33'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3855 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1060 | val_f1=0.6852\n",
      "  Epoch 10 | train_loss=0.0418 | val_f1=0.7307\n",
      "  Epoch 15 | train_loss=0.0085 | val_f1=0.7663\n",
      "  Epoch 20 | train_loss=0.0103 | val_f1=0.7179\n",
      "Segment-level -> acc=0.7851, prec=1.0000, rec=0.7851, f1=0.8796\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject16\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject15', 'Subject18', 'Subject30'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4318 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0954 | val_f1=0.5307\n",
      "  Epoch 10 | train_loss=0.0588 | val_f1=0.7430\n",
      "  Epoch 15 | train_loss=0.0249 | val_f1=0.6677\n",
      "Segment-level -> acc=0.9669, prec=1.0000, rec=0.9669, f1=0.9832\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject17\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject03', 'Subject04', 'Subject24', 'Subject29'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4318 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1630 | val_f1=0.8810\n",
      "  Epoch 10 | train_loss=0.0293 | val_f1=0.8707\n",
      "  Epoch 15 | train_loss=0.0182 | val_f1=0.8880\n",
      "Segment-level -> acc=0.9835, prec=1.0000, rec=0.9835, f1=0.9917\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject18\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject03', 'Subject07', 'Subject19', 'Subject22'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3864 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0973 | val_f1=0.5593\n",
      "  Epoch 10 | train_loss=0.0446 | val_f1=0.6767\n",
      "  Epoch 15 | train_loss=0.0139 | val_f1=0.6842\n",
      "Segment-level -> acc=0.7851, prec=1.0000, rec=0.7851, f1=0.8796\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject19\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject03', 'Subject20', 'Subject26', 'Subject29'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4384 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1318 | val_f1=0.9669\n",
      "  Epoch 10 | train_loss=0.0366 | val_f1=0.9444\n",
      "Segment-level -> acc=0.0000, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject20\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject05', 'Subject08', 'Subject10', 'Subject29'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4274 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1119 | val_f1=0.7696\n",
      "  Epoch 10 | train_loss=0.0365 | val_f1=0.7620\n",
      "Segment-level -> acc=0.9835, prec=1.0000, rec=0.9835, f1=0.9917\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject21\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject02', 'Subject06', 'Subject15', 'Subject27'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3863 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0897 | val_f1=0.6140\n",
      "  Epoch 10 | train_loss=0.0488 | val_f1=0.5979\n",
      "  Epoch 15 | train_loss=0.0087 | val_f1=0.6826\n",
      "  Epoch 20 | train_loss=0.0113 | val_f1=0.7166\n",
      "  Epoch 25 | train_loss=0.0005 | val_f1=0.6360\n",
      "Segment-level -> acc=0.1405, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject22\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject05', 'Subject06', 'Subject17', 'Subject21'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3493 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1120 | val_f1=0.4913\n",
      "  Epoch 10 | train_loss=0.0196 | val_f1=0.6501\n",
      "  Epoch 15 | train_loss=0.0090 | val_f1=0.6566\n",
      "Segment-level -> acc=0.2562, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject23\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject21', 'Subject33', 'Subject35'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4312 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1525 | val_f1=0.8830\n",
      "  Epoch 10 | train_loss=0.0257 | val_f1=0.8395\n",
      "  Epoch 15 | train_loss=0.0152 | val_f1=0.9272\n",
      "  Epoch 20 | train_loss=0.0039 | val_f1=0.8672\n",
      "Segment-level -> acc=0.9504, prec=1.0000, rec=0.9504, f1=0.9746\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject24\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject00', 'Subject09', 'Subject31', 'Subject35'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3834 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0837 | val_f1=0.5261\n",
      "Segment-level -> acc=0.9421, prec=1.0000, rec=0.9421, f1=0.9702\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject25\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject05', 'Subject29', 'Subject32', 'Subject33'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4641 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1562 | val_f1=0.7412\n",
      "  Epoch 10 | train_loss=0.0580 | val_f1=0.7945\n",
      "  Epoch 15 | train_loss=0.0201 | val_f1=0.8295\n",
      "Segment-level -> acc=0.2479, prec=1.0000, rec=0.2479, f1=0.3974\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject26\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject05', 'Subject07', 'Subject16', 'Subject17'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4745 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1274 | val_f1=0.8692\n",
      "  Epoch 10 | train_loss=0.0481 | val_f1=0.7621\n",
      "Segment-level -> acc=0.9008, prec=1.0000, rec=0.9008, f1=0.9478\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject27\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject00', 'Subject03', 'Subject09', 'Subject15'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3930 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0847 | val_f1=0.6390\n",
      "Segment-level -> acc=0.0331, prec=1.0000, rec=0.0331, f1=0.0640\n",
      "Subject-level -> true=1, pred=0, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject28\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject09', 'Subject17', 'Subject20', 'Subject26'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4204 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1529 | val_f1=0.7159\n",
      "  Epoch 10 | train_loss=0.0384 | val_f1=0.7692\n",
      "Segment-level -> acc=0.8512, prec=1.0000, rec=0.8512, f1=0.9196\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject29\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject04', 'Subject07', 'Subject08', 'Subject22'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3994 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1119 | val_f1=0.6437\n",
      "  Epoch 10 | train_loss=0.0273 | val_f1=0.6688\n",
      "  Epoch 15 | train_loss=0.0091 | val_f1=0.7004\n",
      "  Epoch 20 | train_loss=0.0142 | val_f1=0.6959\n",
      "  Epoch 25 | train_loss=0.0039 | val_f1=0.6837\n",
      "Segment-level -> acc=0.9174, prec=1.0000, rec=0.9174, f1=0.9569\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject30\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1089 3146]\n",
      "  Validation subjects: ['Subject04', 'Subject09', 'Subject12', 'Subject16'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3515 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0819 | val_f1=0.5305\n",
      "  Epoch 10 | train_loss=0.0173 | val_f1=0.4807\n",
      "Segment-level -> acc=0.1653, prec=0.0000, rec=0.0000, f1=0.0000\n",
      "Subject-level -> true=0, pred=1, acc=0.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject31\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject24', 'Subject27', 'Subject29', 'Subject33'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4615 | val_f1=0.0041\n",
      "  Epoch 05 | train_loss=0.1176 | val_f1=0.8490\n",
      "  Epoch 10 | train_loss=0.0873 | val_f1=0.8975\n",
      "  Epoch 15 | train_loss=0.0770 | val_f1=0.8476\n",
      "Segment-level -> acc=0.8512, prec=1.0000, rec=0.8512, f1=0.9196\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject32\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject06', 'Subject13', 'Subject19', 'Subject34'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.3854 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.0723 | val_f1=0.5887\n",
      "  Epoch 10 | train_loss=0.0228 | val_f1=0.6537\n",
      "  Epoch 15 | train_loss=0.0039 | val_f1=0.6341\n",
      "Segment-level -> acc=0.9339, prec=1.0000, rec=0.9339, f1=0.9658\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject33\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject20', 'Subject22', 'Subject34', 'Subject35'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4275 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1467 | val_f1=0.8314\n",
      "  Epoch 10 | train_loss=0.0376 | val_f1=0.8196\n",
      "Segment-level -> acc=0.8512, prec=1.0000, rec=0.8512, f1=0.9196\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject34\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject03', 'Subject20', 'Subject32', 'Subject33'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4667 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1428 | val_f1=0.8692\n",
      "  Epoch 10 | train_loss=0.0747 | val_f1=0.8848\n",
      "Segment-level -> acc=0.8926, prec=1.0000, rec=0.8926, f1=0.9432\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Test subject: Subject35\n",
      "Train seg: 4235 | Test seg: 121 | Train dist: [1210 3025]\n",
      "  Validation subjects: ['Subject01', 'Subject02', 'Subject13', 'Subject33'] | noisy_val=False\n",
      "  Epoch 01 | train_loss=0.4764 | val_f1=0.0000\n",
      "  Epoch 05 | train_loss=0.1537 | val_f1=0.8504\n",
      "  Epoch 10 | train_loss=0.0367 | val_f1=0.8638\n",
      "Segment-level -> acc=0.9256, prec=1.0000, rec=0.9256, f1=0.9614\n",
      "Subject-level -> true=1, pred=1, acc=1.0000\n",
      "\n",
      "============================================================\n",
      "Average SEGMENT-level (LOSO):\n",
      "Accuracy : 0.6035\n",
      "Precision: 0.7222\n",
      "Recall   : 0.5735\n",
      "F1-score : 0.6122\n",
      "\n",
      "============================================================\n",
      "Average SUBJECT-level (LOSO, majority vote):\n",
      "Accuracy : 0.6111\n",
      "Precision: 0.6111\n",
      "Recall   : 0.6111\n",
      "F1-score : 0.6111\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ======================\n",
    "# تنظیمات کلی\n",
    "# ======================\n",
    "DATA_FOLDER = \"/kaggle/input/ahmadi-dataset\"\n",
    "INFO_CSV = f\"{DATA_FOLDER}/subject-info.csv\"\n",
    "\n",
    "RESAMPLE_TO = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "WINDOW_SEC = 2.0\n",
    "OVERLAP_RATIO = 0.75\n",
    "\n",
    "USE_BASELINE = True\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "LR = 1e-3\n",
    "PATIENCE = 6\n",
    "\n",
    "# BiLSTM\n",
    "HIDDEN = 64\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# --- Validation by SUBJECT\n",
    "VAL_SUBJECT_COUNT = 4          # دقیقاً 2 سابجکت برای ولید (از trainها)\n",
    "NOISY_VALIDATION = False       # حالت 2: ولید نویزی\n",
    "VAL_NOISE_STD = 0.05           # شدت نویز برای ولید (اگر NOISY_VALIDATION=True)\n",
    "VAL_SCALE_STD = 0.08           # شدت scale-jitter برای ولید نویزی (اختیاری)\n",
    "\n",
    "# ======================\n",
    "# Seed\n",
    "# ======================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# لود داده + baseline correction\n",
    "# ======================\n",
    "def load_task_edf_with_baseline(folder_path, info_csv_path, resample_to=None,\n",
    "                                use_baseline=True):\n",
    "    folder = Path(folder_path)\n",
    "    if not folder.is_dir():\n",
    "        raise NotADirectoryError(f\"{folder_path} is not a valid directory\")\n",
    "\n",
    "    info_df = pd.read_csv(info_csv_path)\n",
    "    label_map = dict(zip(info_df[\"Subject\"], info_df[\"Count quality\"]))\n",
    "\n",
    "    X_list, y_list, subjects = [], [], []\n",
    "    sfreq = None\n",
    "\n",
    "    for subj_name in info_df[\"Subject\"]:\n",
    "        task_file = folder / f\"{subj_name}_2.edf\"\n",
    "        rest_file = folder / f\"{subj_name}_1.edf\"\n",
    "\n",
    "        if not task_file.is_file():\n",
    "            print(f\"Task file not found for {subj_name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        raw_task = mne.io.read_raw_edf(task_file, preload=True, verbose=False)\n",
    "\n",
    "        raw_rest = None\n",
    "        if use_baseline and rest_file.is_file():\n",
    "            raw_rest = mne.io.read_raw_edf(rest_file, preload=True, verbose=False)\n",
    "\n",
    "        if resample_to is not None:\n",
    "            raw_task.resample(resample_to)\n",
    "            if raw_rest is not None:\n",
    "                raw_rest.resample(resample_to)\n",
    "\n",
    "        if sfreq is None:\n",
    "            sfreq = raw_task.info[\"sfreq\"]\n",
    "\n",
    "        task_data = raw_task.get_data()  # (C, T_task)\n",
    "\n",
    "        if use_baseline and raw_rest is not None:\n",
    "            rest_data = raw_rest.get_data()  # (C, T_rest)\n",
    "            baseline = rest_data.mean(axis=1, keepdims=True)\n",
    "            task_data = task_data - baseline\n",
    "\n",
    "        X_list.append(task_data)\n",
    "        y_list.append(int(label_map[subj_name]))\n",
    "        subjects.append(subj_name)\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No files loaded. Check paths/names.\")\n",
    "\n",
    "    lengths = [d.shape[1] for d in X_list]\n",
    "    min_len = min(lengths)\n",
    "\n",
    "    X = np.stack([d[:, :min_len] for d in X_list], axis=0)  # (N, C, T)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    subjects = np.array(subjects)\n",
    "\n",
    "    print(\"X:\", X.shape, \"y:\", y.shape, \"sfreq:\", sfreq)\n",
    "    return X, y, subjects, sfreq\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Segment با overlap 75%\n",
    "# ======================\n",
    "def make_segments(X, y, subjects, sfreq, window_sec=2.0, overlap_ratio=0.75):\n",
    "    N, C, T = X.shape\n",
    "    win_size = int(window_sec * sfreq)          # 256\n",
    "    step_sec = window_sec * (1.0 - overlap_ratio)\n",
    "    step = max(1, int(step_sec * sfreq))        # 64\n",
    "\n",
    "    seg_X, seg_y, seg_subj = [], [], []\n",
    "\n",
    "    for i in range(N):\n",
    "        data = X[i]  # (C, T)\n",
    "        lab = y[i]\n",
    "        sid = subjects[i]\n",
    "\n",
    "        start = 0\n",
    "        while start + win_size <= T:\n",
    "            seg = data[:, start:start+win_size]  # (C, win)\n",
    "            seg_X.append(seg)\n",
    "            seg_y.append(lab)\n",
    "            seg_subj.append(sid)\n",
    "            start += step\n",
    "\n",
    "    seg_X = np.stack(seg_X, axis=0)  # (Nseg, C, win)\n",
    "    seg_y = np.array(seg_y, dtype=int)\n",
    "    seg_subj = np.array(seg_subj)\n",
    "\n",
    "    print(\"Segments:\", seg_X.shape)\n",
    "    return seg_X, seg_y, seg_subj\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Dataset + Augmentation\n",
    "# ======================\n",
    "class EEGSegDataset(Dataset):\n",
    "    def __init__(self, X_seq, y, do_noise=False, do_scale=False,\n",
    "                 noise_std=0.02, scale_std=0.05):\n",
    "        \"\"\"\n",
    "        X_seq: (N, T, C) float32\n",
    "        y: (N,) int/float\n",
    "        \"\"\"\n",
    "        self.X = X_seq.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "\n",
    "        self.do_noise = do_noise\n",
    "        self.do_scale = do_scale\n",
    "        self.noise_std = float(noise_std)\n",
    "        self.scale_std = float(scale_std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def _augment(self, x):\n",
    "        # x: (T, C)\n",
    "        if self.do_noise:\n",
    "            noise = np.random.normal(0, self.noise_std, size=x.shape).astype(np.float32)\n",
    "            x = x + noise\n",
    "        if self.do_scale:\n",
    "            scale = (1.0 + np.random.normal(0, self.scale_std, size=(1, x.shape[1]))).astype(np.float32)\n",
    "            x = x * scale\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        if self.do_noise or self.do_scale:\n",
    "            x = self._augment(x.copy())\n",
    "        y = self.y[idx]\n",
    "        return torch.from_numpy(x), torch.tensor(y)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# BiLSTM Model\n",
    "# ======================\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, n_channels, hidden=64, num_layers=2, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_channels,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden * 2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        out, _ = self.lstm(x)       # (B, T, 2H)\n",
    "        out = out.mean(dim=1)       # mean pooling over time -> (B, 2H)\n",
    "        out = self.norm(out)\n",
    "        logits = self.fc(out).squeeze(1)  # (B,)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Normalization without leakage\n",
    "# ======================\n",
    "def compute_train_norm_stats(X_train_seq):\n",
    "    flat = X_train_seq.reshape(-1, X_train_seq.shape[-1])  # (N*T, C)\n",
    "    mean = flat.mean(axis=0, keepdims=True)\n",
    "    std = flat.std(axis=0, keepdims=True) + 1e-6\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def apply_norm(X_seq, mean, std):\n",
    "    return ((X_seq - mean) / std).astype(np.float32)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Val split: دقیقاً K سابجکت رندوم از train\n",
    "# ======================\n",
    "def make_subject_val_split_exact_k(train_subjects, k=2, seed=42):\n",
    "    uniq = np.unique(train_subjects)\n",
    "    if len(uniq) <= k:\n",
    "        # اگر تعداد سابجکت‌های train کم بود، مجبوریم 1 تا ولید کنیم\n",
    "        k = max(1, len(uniq) - 1)\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    rng.shuffle(uniq)\n",
    "    val_subj = set(uniq[:k])\n",
    "    val_mask = np.array([s in val_subj for s in train_subjects])\n",
    "    return val_mask, val_subj\n",
    "\n",
    "\n",
    "# ======================\n",
    "# Train with early stopping\n",
    "# ======================\n",
    "def train_one_fold(X_train, y_train, subj_train, n_channels, fold_seed,\n",
    "                   noisy_validation=False):\n",
    "    # validation: 2 subject random\n",
    "    val_mask, val_subj = make_subject_val_split_exact_k(\n",
    "        subj_train, k=VAL_SUBJECT_COUNT, seed=fold_seed\n",
    "    )\n",
    "    tr_mask = ~val_mask\n",
    "\n",
    "    X_tr, y_tr = X_train[tr_mask], y_train[tr_mask]\n",
    "    X_val, y_val = X_train[val_mask], y_train[val_mask]\n",
    "\n",
    "    # class imbalance\n",
    "    n_pos = int((y_tr == 1).sum())\n",
    "    n_neg = int((y_tr == 0).sum())\n",
    "    pos_weight = torch.tensor([n_neg / max(1, n_pos)], device=device, dtype=torch.float32)\n",
    "\n",
    "    # sampler (balanced batches)\n",
    "    weights = np.where(y_tr == 1, n_neg / max(1, n_pos), 1.0).astype(np.float32)\n",
    "    sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "    # Train augmentation (معمولاً مفید برای LOSO)\n",
    "    ds_tr = EEGSegDataset(\n",
    "        X_tr, y_tr,\n",
    "        do_noise=True, do_scale=True,\n",
    "        noise_std=0.02, scale_std=0.05\n",
    "    )\n",
    "\n",
    "    # Validation:\n",
    "    # - حالت معمول: بدون augmentation\n",
    "    # - حالت نویزی: عمداً ولید را نویزی می‌کنیم\n",
    "    if noisy_validation:\n",
    "        ds_val = EEGSegDataset(\n",
    "            X_val, y_val,\n",
    "            do_noise=True, do_scale=True,\n",
    "            noise_std=VAL_NOISE_STD, scale_std=VAL_SCALE_STD\n",
    "        )\n",
    "    else:\n",
    "        ds_val = EEGSegDataset(X_val, y_val, do_noise=False, do_scale=False)\n",
    "\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "    dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = BiLSTMClassifier(\n",
    "        n_channels=n_channels, hidden=HIDDEN, num_layers=NUM_LAYERS, dropout=DROPOUT\n",
    "    ).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    best_f1 = -1\n",
    "    best_state = None\n",
    "    patience = 0\n",
    "\n",
    "    print(f\"  Validation subjects: {sorted(list(val_subj))} | noisy_val={noisy_validation}\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        tr_losses = []\n",
    "\n",
    "        for xb, yb in dl_tr:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            tr_losses.append(loss.item())\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        all_pred, all_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_val:\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "                prob = torch.sigmoid(logits).cpu().numpy()\n",
    "                pred = (prob >= 0.5).astype(int)\n",
    "                all_pred.append(pred)\n",
    "                all_true.append(yb.numpy().astype(int))\n",
    "\n",
    "        all_pred = np.concatenate(all_pred)\n",
    "        all_true = np.concatenate(all_true)\n",
    "\n",
    "        f1 = f1_score(all_true, all_pred, zero_division=0)\n",
    "        avg_loss = float(np.mean(tr_losses))\n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print(f\"  Epoch {epoch:02d} | train_loss={avg_loss:.4f} | val_f1={f1:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= PATIENCE:\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# ======================\n",
    "# LOSO Evaluation\n",
    "# ======================\n",
    "def evaluate_loso_bilstm(seg_X, seg_y, seg_subjects, noisy_validation=False):\n",
    "    # (N, C, T) -> (N, T, C)\n",
    "    X_seq = np.transpose(seg_X, (0, 2, 1)).astype(np.float32)  # (Nseg, 256, 21)\n",
    "    y = seg_y.astype(int)\n",
    "    subjects = seg_subjects\n",
    "\n",
    "    uniq_subj = np.unique(subjects)\n",
    "    print(\"Unique subjects:\", len(uniq_subj))\n",
    "\n",
    "    seg_metrics = []\n",
    "    subj_metrics = []\n",
    "\n",
    "    for test_subj in uniq_subj:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Test subject:\", test_subj)\n",
    "\n",
    "        test_mask = (subjects == test_subj)\n",
    "        train_mask = ~test_mask\n",
    "\n",
    "        X_train_raw = X_seq[train_mask]\n",
    "        y_train = y[train_mask]\n",
    "        subj_train = subjects[train_mask]\n",
    "\n",
    "        X_test_raw = X_seq[test_mask]\n",
    "        y_test = y[test_mask]\n",
    "\n",
    "        # normalization from TRAIN only\n",
    "        mean, std = compute_train_norm_stats(X_train_raw)\n",
    "        X_train = apply_norm(X_train_raw, mean, std)\n",
    "        X_test  = apply_norm(X_test_raw,  mean, std)\n",
    "\n",
    "        print(\"Train seg:\", X_train.shape[0], \"| Test seg:\", X_test.shape[0],\n",
    "              \"| Train dist:\", np.bincount(y_train))\n",
    "\n",
    "        # fold-specific seed (برای اینکه انتخاب 2 سابجکت ولید هر fold رندوم ولی reproducible باشد)\n",
    "        # SubjectXX -> XX\n",
    "        try:\n",
    "            sid_num = int(str(test_subj).replace(\"Subject\", \"\"))\n",
    "        except:\n",
    "            sid_num = 0\n",
    "        fold_seed = RANDOM_STATE + 1000 + sid_num\n",
    "\n",
    "        model = train_one_fold(\n",
    "            X_train, y_train, subj_train,\n",
    "            n_channels=X_train.shape[-1],\n",
    "            fold_seed=fold_seed,\n",
    "            noisy_validation=noisy_validation\n",
    "        )\n",
    "\n",
    "        # predict test\n",
    "        with torch.no_grad():\n",
    "            xb = torch.from_numpy(X_test).to(device)\n",
    "            logits = model(xb).cpu().numpy()\n",
    "            prob = 1.0 / (1.0 + np.exp(-logits))\n",
    "            y_pred = (prob >= 0.5).astype(int)\n",
    "\n",
    "        # segment-level metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        print(f\"Segment-level -> acc={acc:.4f}, prec={prec:.4f}, rec={rec:.4f}, f1={f1:.4f}\")\n",
    "        seg_metrics.append([acc, prec, rec, f1])\n",
    "\n",
    "        # subject-level majority vote\n",
    "        true_label = int(y_test[0])\n",
    "        pred_label = int(np.argmax(np.bincount(y_pred)))\n",
    "        acc_subj = 1.0 if pred_label == true_label else 0.0\n",
    "        print(f\"Subject-level -> true={true_label}, pred={pred_label}, acc={acc_subj:.4f}\")\n",
    "        subj_metrics.append([acc_subj, acc_subj, acc_subj, acc_subj])\n",
    "\n",
    "    seg_metrics = np.array(seg_metrics)\n",
    "    subj_metrics = np.array(subj_metrics)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Average SEGMENT-level (LOSO):\")\n",
    "    print(f\"Accuracy : {seg_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {seg_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {seg_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {seg_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Average SUBJECT-level (LOSO, majority vote):\")\n",
    "    print(f\"Accuracy : {subj_metrics[:,0].mean():.4f}\")\n",
    "    print(f\"Precision: {subj_metrics[:,1].mean():.4f}\")\n",
    "    print(f\"Recall   : {subj_metrics[:,2].mean():.4f}\")\n",
    "    print(f\"F1-score : {subj_metrics[:,3].mean():.4f}\")\n",
    "\n",
    "\n",
    "# ======================\n",
    "# main\n",
    "# ======================\n",
    "def main():\n",
    "    X, y, subjects, sfreq = load_task_edf_with_baseline(\n",
    "        DATA_FOLDER, INFO_CSV,\n",
    "        resample_to=RESAMPLE_TO,\n",
    "        use_baseline=USE_BASELINE\n",
    "    )\n",
    "\n",
    "    seg_X, seg_y, seg_subjects = make_segments(\n",
    "        X, y, subjects, sfreq,\n",
    "        window_sec=WINDOW_SEC,\n",
    "        overlap_ratio=OVERLAP_RATIO\n",
    "    )\n",
    "\n",
    "    evaluate_loso_bilstm(seg_X, seg_y, seg_subjects, noisy_validation=NOISY_VALIDATION)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8971208,
     "sourceId": 14089447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3054.216633,
   "end_time": "2025-12-12T10:14:32.572575",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T09:23:38.355942",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
